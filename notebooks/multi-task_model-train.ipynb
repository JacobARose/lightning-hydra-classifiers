{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa766388",
   "metadata": {
    "tags": []
   },
   "source": [
    "# multi-task_model-train\n",
    "\n",
    "`multi-task_model-train.ipynb`\n",
    "\n",
    "End of August attempts to create good model training workflows for multi-task experiments\n",
    "\n",
    "Author: Jacob A Rose  \n",
    "Created on: Monday August 29th, 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bd2d440",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fc103b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports & definitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9a29990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb6311eac90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "# pretty print all cell's output and not just the last one\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import os\n",
    "\n",
    "if 'TOY_DATA_DIR' not in os.environ: \n",
    "    os.environ['TOY_DATA_DIR'] = \"/media/data_cifs/projects/prj_fossils/data/toy_data\"\n",
    "default_root_dir = os.environ['TOY_DATA_DIR']\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "# from lightning_hydra_classifiers.data.utils import make_catalogs\n",
    "# import torchdata\n",
    "\n",
    "# import albumentations as A\n",
    "import pytorch_lightning as pl\n",
    "import timm\n",
    "from rich import print as pp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from munch import Munch\n",
    "\n",
    "from lightning_hydra_classifiers.data.utils.make_catalogs import *\n",
    "\n",
    "from lightning_hydra_classifiers.utils.metric_utils import get_per_class_metrics, get_scalar_metrics\n",
    "from lightning_hydra_classifiers.utils.logging_utils import get_wandb_logger\n",
    "import wandb\n",
    "\n",
    "torch.manual_seed(17)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829655c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Datasets & DataModules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea7be81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning_hydra_classifiers.experiments.transfer_experiment import TransferExperiment\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class PlantDataModule(pl.LightningDataModule):\n",
    "#     valid_tasks = (0, 1)\n",
    "    \n",
    "    def __init__(self, \n",
    "                 batch_size,\n",
    "                 task_id: int=0,\n",
    "                 image_size: int=224,\n",
    "                 image_buffer_size: int=32,\n",
    "                 num_workers: int=4,\n",
    "                 pin_memory: bool=True):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.pin_memory = pin_memory\n",
    "        \n",
    "        \n",
    "        self.experiment = TransferExperiment()\n",
    "        self.set_task(task_id)        \n",
    "        \n",
    "        self.image_size = image_size\n",
    "        self.image_buffer_size = image_buffer_size\n",
    "        self.mean = [0.485, 0.456, 0.406]\n",
    "        self.std = [0.229, 0.224, 0.225]\n",
    "        # Train augmentation policy\n",
    "        \n",
    "        self.__init_transforms()\n",
    "                \n",
    "        self.tasks = self.experiment.get_multitask_datasets(train_transform=self.train_transform,\n",
    "                                                            val_transform=self.val_transform)\n",
    "\n",
    "\n",
    "    def __init_transforms(self):\n",
    "        \n",
    "        self.train_transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(size=self.image_size,\n",
    "                                         scale=(0.25, 1.2),\n",
    "                                         ratio=(0.7, 1.3),\n",
    "                                         interpolation=2),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.Normalize(self.mean, self.std),\n",
    "            transforms.Grayscale(num_output_channels=3)\n",
    "        ])\n",
    "\n",
    "        self.val_transform = transforms.Compose([\n",
    "            transforms.Resize(self.image_size+self.image_buffer_size),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            transforms.CenterCrop(self.image_size),\n",
    "            transforms.Normalize(self.mean, self.std),\n",
    "            transforms.Grayscale(num_output_channels=3)            \n",
    "        ])\n",
    "\n",
    "    def set_task(self, task_id: int):\n",
    "        assert task_id in self.experiment.valid_tasks\n",
    "        self.task_id = task_id\n",
    "        \n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def current_task(self):\n",
    "        return self.tasks[self.task_id]\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        task = self.current_task\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == 'fit' or stage is None:\n",
    "            self.train_dataset = task['train']\n",
    "            self.val_dataset = task['val']\n",
    "            \n",
    "            self.classes = self.train_dataset.classes\n",
    "            self.num_classes = len(self.train_dataset.label_encoder)\n",
    "            \n",
    "        elif stage == 'test':\n",
    "            self.test_dataset = task['test']\n",
    "                        \n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.train_dataset,\n",
    "                          batch_size=self.batch_size,\n",
    "                          pin_memory=self.pin_memory,\n",
    "                          shuffle=True,\n",
    "                          num_workers=self.num_workers,\n",
    "                          drop_last=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.val_dataset,\n",
    "                          batch_size=self.batch_size,\n",
    "                          pin_memory=self.pin_memory,\n",
    "                          num_workers=self.num_workers)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.test_dataset,\n",
    "                          batch_size=self.batch_size,\n",
    "                          pin_memory=self.pin_memory,\n",
    "                          num_workers=self.num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4100b16f",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "## Model & LightningModules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83d66a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomResNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_classes: int,\n",
    "                 model_name='resnet18',\n",
    "                 pretrained=False):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        self.in_features = self.model.get_classifier().in_features\n",
    "        self.model.fc = nn.Linear(self.in_features, self.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "class LitMultiTaskModule(pl.LightningModule):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.lr = config['lr']\n",
    "        self.num_classes = config['num_classes']\n",
    "#         self.save_hyperparameters()\n",
    "        self._init_model(config)\n",
    "        self.metrics = self._init_metrics(stage='all')\n",
    "#         self.metric = pl.metrics.F1(num_classes=CONFIG['num_classes'])\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=self.config['t_max'], eta_min=self.config['min_lr'])\n",
    "\n",
    "        return {'optimizer': self.optimizer, 'lr_scheduler': self.scheduler}\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        image = batch[0]\n",
    "        target = batch[1]\n",
    "        output = self.model(image)\n",
    "        loss = self.criterion(output, target)\n",
    "#         scores = self.metrics_train(output.argmax(1), target)\n",
    "        scores = self.metrics_train(output, target)\n",
    "        self.log_dict({\"train_loss\": loss, 'lr': self.optimizer.param_groups[0]['lr']},\n",
    "                      on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log_dict(scores,\n",
    "                      on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        image = batch[0]\n",
    "        target = batch[1]\n",
    "        output = self.model(image)\n",
    "        loss = self.criterion(output, target)\n",
    "#         scores = self.metrics_val(output.argmax(1), target)\n",
    "        scores = self.metrics_val(output, target)\n",
    "        \n",
    "        self.log(\"val_loss\", loss,\n",
    "                  on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log_dict(scores,\n",
    "                      on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def _init_model(self, config):\n",
    "        self.model =  CustomResNet(config[\"num_classes\"],\n",
    "                                   model_name=config[\"model_name\"],\n",
    "                                   pretrained=config[\"pretrained\"])\n",
    "    \n",
    "    def _init_metrics(self, stage: str='train'):\n",
    "        \n",
    "        if stage in ['train', 'all']:\n",
    "            self.metrics_train = get_scalar_metrics(num_classes=self.num_classes, average='macro', prefix='train')\n",
    "#             self.metrics_train_per_class = get_per_class_metrics(num_classes=self.num_classes, prefix='train')\n",
    "            \n",
    "        if stage in ['val', 'all']:\n",
    "            self.metrics_val = get_scalar_metrics(num_classes=self.num_classes, average='macro', prefix='val')\n",
    "#             self.metrics_val_per_class = get_per_class_metrics(num_classes=self.num_classes, prefix='val')\n",
    "            \n",
    "        if stage in ['test', 'all']:\n",
    "            self.metrics_test = get_scalar_metrics(num_classes=self.num_classes, average='macro', prefix='test')\n",
    "#             self.metrics_test_per_class = get_per_class_metrics(num_classes=self.num_classes, prefix='test')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270b1816",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define & Run Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb6ba62",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe120bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#     \"model\":\n",
    "#         {\"backbone\":{\n",
    "#                  \"name\":'resnet50',\n",
    "#                  \"pretrained\":True},\n",
    "config = Munch({\n",
    "    \"seed\":42,\n",
    "    \"model_name\":'resnet50',\n",
    "    \"pretrained\":True,\n",
    "    \"image_size\": 224,\n",
    "    \"image_buffer_size\": 32, \n",
    "    \"num_classes\": None,\n",
    "    \"lr\": 5e-4,\n",
    "    \"min_lr\": 1e-6,\n",
    "    \"t_max\": 20,\n",
    "    \"num_epochs\": 10,\n",
    "    \"batch_size\": 32,\n",
    "#     accum = 1,\n",
    "    \"precision\": 16,\n",
    "    \"device\": torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    \"num_workers\": 4,\n",
    "    \"pin_memory\": True\n",
    "})\n",
    "\n",
    "\n",
    "# Seed everything\n",
    "pl.seed_everything(config['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dd2b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4fe5e39",
   "metadata": {
    "tags": []
   },
   "source": [
    "## DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f734c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Munch<span style=\"font-weight: bold\">({</span><span style=\"color: #008000; text-decoration-color: #008000\">'seed'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'resnet50'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'pretrained'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'image_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">224</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'image_buffer_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'num_classes'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">92</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'lr'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0005</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'min_lr'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-06</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'t_max'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'num_epochs'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'batch_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'precision'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'device'</span>: device<span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cuda'</span><span style=\"font-weight: bold\">)</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'num_workers'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'pin_memory'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">})</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Munch\u001b[1m(\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'seed'\u001b[0m: \u001b[1;36m42\u001b[0m, \u001b[32m'model_name'\u001b[0m: \u001b[32m'resnet50'\u001b[0m, \u001b[32m'pretrained'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'image_size'\u001b[0m: \u001b[1;36m224\u001b[0m, \n",
       "\u001b[32m'image_buffer_size'\u001b[0m: \u001b[1;36m32\u001b[0m, \u001b[32m'num_classes'\u001b[0m: \u001b[1;36m92\u001b[0m, \u001b[32m'lr'\u001b[0m: \u001b[1;36m0.0005\u001b[0m, \u001b[32m'min_lr'\u001b[0m: \u001b[1;36m1e-06\u001b[0m, \u001b[32m't_max'\u001b[0m: \u001b[1;36m20\u001b[0m, \n",
       "\u001b[32m'num_epochs'\u001b[0m: \u001b[1;36m10\u001b[0m, \u001b[32m'batch_size'\u001b[0m: \u001b[1;36m32\u001b[0m, \u001b[32m'precision'\u001b[0m: \u001b[1;36m16\u001b[0m, \u001b[32m'device'\u001b[0m: device\u001b[1m(\u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'cuda'\u001b[0m\u001b[1m)\u001b[0m, \n",
       "\u001b[32m'num_workers'\u001b[0m: \u001b[1;36m4\u001b[0m, \u001b[32m'pin_memory'\u001b[0m: \u001b[3;92mTrue\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datamodule = PlantDataModule(batch_size=config.batch_size,\n",
    "                             task_id=0,\n",
    "                             image_size=config.image_size,\n",
    "                             image_buffer_size=config.image_buffer_size,\n",
    "                             num_workers=config.num_workers,\n",
    "                             pin_memory=config.pin_memory)\n",
    "\n",
    "datamodule.setup(\"fit\")\n",
    "config.num_classes = datamodule.num_classes\n",
    "\n",
    "pp(config)\n",
    "model = LitMultiTaskModule(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67a1a1b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa84f9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(monitor='val_loss',\n",
    "                                      save_top_k=1,\n",
    "                                      save_last=True,\n",
    "                                      save_weights_only=True,\n",
    "                                      filename='checkpoint/{epoch:02d}-{val_loss:.4f}-{val_f1:.4f}',\n",
    "                                      verbose=True,\n",
    "                                      mode='min')\n",
    "earlystopping = pl.callbacks.EarlyStopping(monitor='val_loss', patience=3, mode='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e75e3a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4bd744b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_logger = pl.loggers.WandbLogger(entity = \"jrose\",\n",
    "                           project = \"image_classification_train\",\n",
    "                           job_type = \"train_supervised\",\n",
    "                           config=config,\n",
    "                           group='ResNet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd206fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc797742",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using native 16bit precision.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "lightning_hydra_classifiers.data.utils.make_catalogs.CSVDataset"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a trainer\n",
    "trainer = pl.Trainer(\n",
    "            limit_train_batches=0.1,\n",
    "            limit_val_batches=0.1,\n",
    "            max_epochs=config['num_epochs'],\n",
    "            gpus=1,\n",
    "#             accumulate_grad_batches=CONFIG['accum'],\n",
    "            precision=config['precision'],\n",
    "            callbacks=[earlystopping,\n",
    "                       checkpoint_callback],\n",
    "#                        ImagePredictionLogger(val_samples)],\n",
    "#             checkpoint_callback=checkpoint_callback,\n",
    "            logger=wandb_logger,\n",
    "            weights_summary='top')\n",
    "\n",
    "# datamodule.train_dataset[0]\n",
    "type(datamodule.val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eacdf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "# model_stats = summary(your_model, (1, 3, 28, 28), verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838c4372",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "866397da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjrose\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.1 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.26<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">scarlet-sun-127</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/jrose/image_classification_train\" target=\"_blank\">https://wandb.ai/jrose/image_classification_train</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/jrose/image_classification_train/runs/2xf9xp39\" target=\"_blank\">https://wandb.ai/jrose/image_classification_train/runs/2xf9xp39</a><br/>\n",
       "                Run data is saved locally in <code>/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/wandb/run-20210830_220529-2xf9xp39</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | model         | CustomResNet     | 23.7 M\n",
      "1 | metrics_train | MetricCollection | 0     \n",
      "2 | metrics_val   | MetricCollection | 0     \n",
      "3 | metrics_test  | MetricCollection | 0     \n",
      "4 | criterion     | CrossEntropyLoss | 0     \n",
      "---------------------------------------------------\n",
      "23.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.7 M    Total params\n",
      "94.786    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                             "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  80%|█████████████████████████████████████████████████████████████████▎                | 51/64 [00:33<00:08,  1.54it/s, loss=3.8, v_num=xp39, train_loss_step=3.930, lr_step=0.0005]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                                                     | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  83%|███████████████████████████████████████████████████████████████████▉              | 53/64 [00:35<00:07,  1.51it/s, loss=3.8, v_num=xp39, train_loss_step=3.930, lr_step=0.0005]\u001b[A\n",
      "Validating:  15%|█████████████████████▋                                                                                                                       | 2/13 [00:02<00:16,  1.48s/it]\u001b[A\n",
      "Epoch 0:  86%|██████████████████████████████████████████████████████████████████████▍           | 55/64 [00:36<00:05,  1.54it/s, loss=3.8, v_num=xp39, train_loss_step=3.930, lr_step=0.0005]\u001b[A\n",
      "Validating:  31%|███████████████████████████████████████████▍                                                                                                 | 4/13 [00:02<00:07,  1.14it/s]\u001b[A\n",
      "Epoch 0:  89%|█████████████████████████████████████████████████████████████████████████         | 57/64 [00:37<00:04,  1.57it/s, loss=3.8, v_num=xp39, train_loss_step=3.930, lr_step=0.0005]\u001b[A\n",
      "Validating:  46%|█████████████████████████████████████████████████████████████████                                                                            | 6/13 [00:03<00:04,  1.63it/s]\u001b[A\n",
      "Epoch 0:  92%|███████████████████████████████████████████████████████████████████████████▌      | 59/64 [00:37<00:03,  1.60it/s, loss=3.8, v_num=xp39, train_loss_step=3.930, lr_step=0.0005]\u001b[A\n",
      "Validating:  62%|██████████████████████████████████████████████████████████████████████████████████████▊                                                      | 8/13 [00:04<00:02,  2.27it/s]\u001b[A\n",
      "Epoch 0:  95%|██████████████████████████████████████████████████████████████████████████████▏   | 61/64 [00:38<00:01,  1.60it/s, loss=3.8, v_num=xp39, train_loss_step=3.930, lr_step=0.0005]\u001b[A\n",
      "Epoch 0:  98%|████████████████████████████████████████████████████████████████████████████████▋ | 63/64 [00:39<00:00,  1.64it/s, loss=3.8, v_num=xp39, train_loss_step=3.930, lr_step=0.0005]\u001b[A\n",
      "Validating:  92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏          | 12/13 [00:05<00:00,  2.80it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 64/64 [00:42<00:00,  1.54it/s, loss=3.8, v_num=xp39, train_loss_step=3.930, lr_step=0.0005, val_loss_step=4.910, val_loss_epoch=4.170, val/F1_top1=0.0162, val/acc_top1=0.02\u001b[A\n",
      "                                                                                                                                                                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: val_loss reached 4.17365 (best 4.17365), saving model to \"/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/image_classification_train/2xf9xp39/checkpoints/checkpoint/epoch=00-val_loss=4.1736-val_f1=0.0000.ckpt\" as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  81%|▊| 52/64 [00:33<00:07,  1.58it/s, loss=3.61, v_num=xp39, train_loss_step=3.180, lr_step=0.000497, val_loss_step=4.910, val_loss_epoch=4.170, val/F1_top1=0.0162, val/acc_top1=0\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                                                     | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  84%|▊| 54/64 [00:35<00:06,  1.56it/s, loss=3.61, v_num=xp39, train_loss_step=3.180, lr_step=0.000497, val_loss_step=4.910, val_loss_epoch=4.170, val/F1_top1=0.0162, val/acc_top1=0\u001b[A\n",
      "Epoch 1:  88%|▉| 56/64 [00:35<00:04,  1.61it/s, loss=3.61, v_num=xp39, train_loss_step=3.180, lr_step=0.000497, val_loss_step=4.910, val_loss_epoch=4.170, val/F1_top1=0.0162, val/acc_top1=0\u001b[A\n",
      "Validating:  38%|██████████████████████████████████████████████████████▏                                                                                      | 5/13 [00:03<00:08,  1.03s/it]\u001b[A\n",
      "Epoch 1:  91%|▉| 58/64 [00:36<00:03,  1.60it/s, loss=3.61, v_num=xp39, train_loss_step=3.180, lr_step=0.000497, val_loss_step=4.910, val_loss_epoch=4.170, val/F1_top1=0.0162, val/acc_top1=0\u001b[A\n",
      "Validating:  54%|███████████████████████████████████████████████████████████████████████████▉                                                                 | 7/13 [00:03<00:03,  1.54it/s]\u001b[A\n",
      "Epoch 1:  94%|▉| 60/64 [00:37<00:02,  1.62it/s, loss=3.61, v_num=xp39, train_loss_step=3.180, lr_step=0.000497, val_loss_step=4.910, val_loss_epoch=4.170, val/F1_top1=0.0162, val/acc_top1=0\u001b[A\n",
      "Validating:  69%|█████████████████████████████████████████████████████████████████████████████████████████████████▌                                           | 9/13 [00:04<00:02,  1.88it/s]\u001b[A\n",
      "Epoch 1:  97%|▉| 62/64 [00:38<00:01,  1.64it/s, loss=3.61, v_num=xp39, train_loss_step=3.180, lr_step=0.000497, val_loss_step=4.910, val_loss_epoch=4.170, val/F1_top1=0.0162, val/acc_top1=0\u001b[A\n",
      "Validating:  85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                     | 11/13 [00:05<00:00,  2.48it/s]\u001b[A\n",
      "Epoch 1: 100%|█| 64/64 [00:38<00:00,  1.67it/s, loss=3.61, v_num=xp39, train_loss_step=3.180, lr_step=0.000497, val_loss_step=4.910, val_loss_epoch=4.170, val/F1_top1=0.0162, val/acc_top1=0\u001b[A\n",
      "Epoch 1: 100%|█| 64/64 [00:41<00:00,  1.58it/s, loss=3.61, v_num=xp39, train_loss_step=3.180, lr_step=0.000497, val_loss_step=3.920, val_loss_epoch=3.750, val/F1_top1=0.0221, val/acc_top1=0\u001b[A\n",
      "                                                                                                                                                                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 101: val_loss reached 3.75095 (best 3.75095), saving model to \"/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/image_classification_train/2xf9xp39/checkpoints/checkpoint/epoch=01-val_loss=3.7510-val_f1=0.0000.ckpt\" as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  81%|▊| 52/64 [00:30<00:06,  1.72it/s, loss=3.36, v_num=xp39, train_loss_step=3.130, lr_step=0.000488, val_loss_step=3.920, val_loss_epoch=3.750, val/F1_top1=0.0221, val/acc_top1=0\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                                                     | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   8%|██████████▊                                                                                                                                  | 1/13 [00:01<00:23,  1.98s/it]\u001b[A\n",
      "Epoch 2:  84%|▊| 54/64 [00:33<00:06,  1.66it/s, loss=3.36, v_num=xp39, train_loss_step=3.130, lr_step=0.000488, val_loss_step=3.920, val_loss_epoch=3.750, val/F1_top1=0.0221, val/acc_top1=0\u001b[A\n",
      "Validating:  23%|████████████████████████████████▌                                                                                                            | 3/13 [00:02<00:11,  1.13s/it]\u001b[A\n",
      "Epoch 2:  88%|▉| 56/64 [00:33<00:04,  1.69it/s, loss=3.36, v_num=xp39, train_loss_step=3.130, lr_step=0.000488, val_loss_step=3.920, val_loss_epoch=3.750, val/F1_top1=0.0221, val/acc_top1=0\u001b[A\n",
      "Validating:  38%|██████████████████████████████████████████████████████▏                                                                                      | 5/13 [00:03<00:07,  1.13it/s]\u001b[A\n",
      "Epoch 2:  91%|▉| 58/64 [00:34<00:03,  1.69it/s, loss=3.36, v_num=xp39, train_loss_step=3.130, lr_step=0.000488, val_loss_step=3.920, val_loss_epoch=3.750, val/F1_top1=0.0221, val/acc_top1=0\u001b[A\n",
      "Validating:  54%|███████████████████████████████████████████████████████████████████████████▉                                                                 | 7/13 [00:04<00:03,  1.69it/s]\u001b[A\n",
      "Epoch 2:  94%|▉| 60/64 [00:35<00:02,  1.71it/s, loss=3.36, v_num=xp39, train_loss_step=3.130, lr_step=0.000488, val_loss_step=3.920, val_loss_epoch=3.750, val/F1_top1=0.0221, val/acc_top1=0\u001b[A\n",
      "Validating:  69%|█████████████████████████████████████████████████████████████████████████████████████████████████▌                                           | 9/13 [00:05<00:02,  1.96it/s]\u001b[A\n",
      "Epoch 2:  97%|▉| 62/64 [00:36<00:01,  1.73it/s, loss=3.36, v_num=xp39, train_loss_step=3.130, lr_step=0.000488, val_loss_step=3.920, val_loss_epoch=3.750, val/F1_top1=0.0221, val/acc_top1=0\u001b[A\n",
      "Validating:  85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                     | 11/13 [00:05<00:00,  2.47it/s]\u001b[A\n",
      "Epoch 2: 100%|█| 64/64 [00:37<00:00,  1.76it/s, loss=3.36, v_num=xp39, train_loss_step=3.130, lr_step=0.000488, val_loss_step=3.920, val_loss_epoch=3.750, val/F1_top1=0.0221, val/acc_top1=0\u001b[A\n",
      "Epoch 2: 100%|█| 64/64 [00:39<00:00,  1.64it/s, loss=3.36, v_num=xp39, train_loss_step=3.130, lr_step=0.000488, val_loss_step=3.130, val_loss_epoch=3.420, val/F1_top1=0.0238, val/acc_top1=0\u001b[A\n",
      "                                                                                                                                                                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 152: val_loss reached 3.41573 (best 3.41573), saving model to \"/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/image_classification_train/2xf9xp39/checkpoints/checkpoint/epoch=02-val_loss=3.4157-val_f1=0.0000.ckpt\" as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  81%|▊| 52/64 [00:30<00:06,  1.74it/s, loss=3.23, v_num=xp39, train_loss_step=3.310, lr_step=0.000473, val_loss_step=3.130, val_loss_epoch=3.420, val/F1_top1=0.0238, val/acc_top1=0\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                                                     | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   8%|██████████▊                                                                                                                                  | 1/13 [00:02<00:28,  2.39s/it]\u001b[A\n",
      "Epoch 3:  84%|▊| 54/64 [00:33<00:06,  1.65it/s, loss=3.23, v_num=xp39, train_loss_step=3.310, lr_step=0.000473, val_loss_step=3.130, val_loss_epoch=3.420, val/F1_top1=0.0238, val/acc_top1=0\u001b[A\n",
      "Validating:  23%|████████████████████████████████▌                                                                                                            | 3/13 [00:02<00:13,  1.32s/it]\u001b[A\n",
      "Epoch 3:  88%|▉| 56/64 [00:33<00:04,  1.68it/s, loss=3.23, v_num=xp39, train_loss_step=3.310, lr_step=0.000473, val_loss_step=3.130, val_loss_epoch=3.420, val/F1_top1=0.0238, val/acc_top1=0\u001b[A\n",
      "Validating:  38%|██████████████████████████████████████████████████████▏                                                                                      | 5/13 [00:04<00:07,  1.06it/s]\u001b[A\n",
      "Epoch 3:  91%|▉| 58/64 [00:34<00:03,  1.69it/s, loss=3.23, v_num=xp39, train_loss_step=3.310, lr_step=0.000473, val_loss_step=3.130, val_loss_epoch=3.420, val/F1_top1=0.0238, val/acc_top1=0\u001b[A\n",
      "Validating:  54%|███████████████████████████████████████████████████████████████████████████▉                                                                 | 7/13 [00:04<00:03,  1.60it/s]\u001b[A\n",
      "Epoch 3:  94%|▉| 60/64 [00:35<00:02,  1.72it/s, loss=3.23, v_num=xp39, train_loss_step=3.310, lr_step=0.000473, val_loss_step=3.130, val_loss_epoch=3.420, val/F1_top1=0.0238, val/acc_top1=0\u001b[A\n",
      "Validating:  69%|█████████████████████████████████████████████████████████████████████████████████████████████████▌                                           | 9/13 [00:05<00:02,  1.75it/s]\u001b[A\n",
      "Epoch 3:  97%|▉| 62/64 [00:36<00:01,  1.73it/s, loss=3.23, v_num=xp39, train_loss_step=3.310, lr_step=0.000473, val_loss_step=3.130, val_loss_epoch=3.420, val/F1_top1=0.0238, val/acc_top1=0\u001b[A\n",
      "Validating:  85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                     | 11/13 [00:06<00:00,  2.34it/s]\u001b[A\n",
      "Epoch 3: 100%|█| 64/64 [00:37<00:00,  1.75it/s, loss=3.23, v_num=xp39, train_loss_step=3.310, lr_step=0.000473, val_loss_step=3.130, val_loss_epoch=3.420, val/F1_top1=0.0238, val/acc_top1=0\u001b[A\n",
      "Epoch 3: 100%|█| 64/64 [00:39<00:00,  1.66it/s, loss=3.23, v_num=xp39, train_loss_step=3.310, lr_step=0.000473, val_loss_step=3.350, val_loss_epoch=3.620, val/F1_top1=0.0205, val/acc_top1=0\u001b[A\n",
      "                                                                                                                                                                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 203: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  81%|▊| 52/64 [00:31<00:07,  1.71it/s, loss=3.31, v_num=xp39, train_loss_step=3.120, lr_step=0.000452, val_loss_step=3.350, val_loss_epoch=3.620, val/F1_top1=0.0205, val/acc_top1=0\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                                                     | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   8%|██████████▊                                                                                                                                  | 1/13 [00:02<00:27,  2.30s/it]\u001b[A\n",
      "Epoch 4:  84%|▊| 54/64 [00:33<00:06,  1.63it/s, loss=3.31, v_num=xp39, train_loss_step=3.120, lr_step=0.000452, val_loss_step=3.350, val_loss_epoch=3.620, val/F1_top1=0.0205, val/acc_top1=0\u001b[A\n",
      "Validating:  23%|████████████████████████████████▌                                                                                                            | 3/13 [00:02<00:12,  1.28s/it]\u001b[A\n",
      "Epoch 4:  88%|▉| 56/64 [00:34<00:04,  1.66it/s, loss=3.31, v_num=xp39, train_loss_step=3.120, lr_step=0.000452, val_loss_step=3.350, val_loss_epoch=3.620, val/F1_top1=0.0205, val/acc_top1=0\u001b[A\n",
      "Validating:  38%|██████████████████████████████████████████████████████▏                                                                                      | 5/13 [00:04<00:07,  1.06it/s]\u001b[A\n",
      "Epoch 4:  91%|▉| 58/64 [00:35<00:03,  1.67it/s, loss=3.31, v_num=xp39, train_loss_step=3.120, lr_step=0.000452, val_loss_step=3.350, val_loss_epoch=3.620, val/F1_top1=0.0205, val/acc_top1=0\u001b[A\n",
      "Validating:  54%|███████████████████████████████████████████████████████████████████████████▉                                                                 | 7/13 [00:04<00:03,  1.62it/s]\u001b[A\n",
      "Epoch 4:  94%|▉| 60/64 [00:36<00:02,  1.69it/s, loss=3.31, v_num=xp39, train_loss_step=3.120, lr_step=0.000452, val_loss_step=3.350, val_loss_epoch=3.620, val/F1_top1=0.0205, val/acc_top1=0\u001b[A\n",
      "Validating:  69%|█████████████████████████████████████████████████████████████████████████████████████████████████▌                                           | 9/13 [00:05<00:02,  1.78it/s]\u001b[A\n",
      "Epoch 4:  97%|▉| 62/64 [00:36<00:01,  1.70it/s, loss=3.31, v_num=xp39, train_loss_step=3.120, lr_step=0.000452, val_loss_step=3.350, val_loss_epoch=3.620, val/F1_top1=0.0205, val/acc_top1=0\u001b[A\n",
      "Validating:  85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                     | 11/13 [00:06<00:00,  2.34it/s]\u001b[A\n",
      "Epoch 4: 100%|█| 64/64 [00:37<00:00,  1.73it/s, loss=3.31, v_num=xp39, train_loss_step=3.120, lr_step=0.000452, val_loss_step=3.350, val_loss_epoch=3.620, val/F1_top1=0.0205, val/acc_top1=0\u001b[A\n",
      "Epoch 4: 100%|█| 64/64 [00:39<00:00,  1.63it/s, loss=3.31, v_num=xp39, train_loss_step=3.120, lr_step=0.000452, val_loss_step=3.160, val_loss_epoch=3.310, val/F1_top1=0.0346, val/acc_top1=0\u001b[A\n",
      "                                                                                                                                                                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 254: val_loss reached 3.30863 (best 3.30863), saving model to \"/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/image_classification_train/2xf9xp39/checkpoints/checkpoint/epoch=04-val_loss=3.3086-val_f1=0.0000.ckpt\" as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  81%|▊| 52/64 [00:30<00:06,  1.73it/s, loss=3.24, v_num=xp39, train_loss_step=3.160, lr_step=0.000427, val_loss_step=3.160, val_loss_epoch=3.310, val/F1_top1=0.0346, val/acc_top1=0\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                                                     | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   8%|██████████▊                                                                                                                                  | 1/13 [00:02<00:25,  2.13s/it]\u001b[A\n",
      "Epoch 5:  84%|▊| 54/64 [00:33<00:06,  1.66it/s, loss=3.24, v_num=xp39, train_loss_step=3.160, lr_step=0.000427, val_loss_step=3.160, val_loss_epoch=3.310, val/F1_top1=0.0346, val/acc_top1=0\u001b[A\n",
      "Validating:  23%|████████████████████████████████▌                                                                                                            | 3/13 [00:02<00:11,  1.19s/it]\u001b[A\n",
      "Epoch 5:  88%|▉| 56/64 [00:33<00:04,  1.69it/s, loss=3.24, v_num=xp39, train_loss_step=3.160, lr_step=0.000427, val_loss_step=3.160, val_loss_epoch=3.310, val/F1_top1=0.0346, val/acc_top1=0\u001b[A\n",
      "Validating:  38%|██████████████████████████████████████████████████████▏                                                                                      | 5/13 [00:03<00:06,  1.20it/s]\u001b[A\n",
      "Epoch 5:  91%|▉| 58/64 [00:34<00:03,  1.71it/s, loss=3.24, v_num=xp39, train_loss_step=3.160, lr_step=0.000427, val_loss_step=3.160, val_loss_epoch=3.310, val/F1_top1=0.0346, val/acc_top1=0\u001b[A\n",
      "Validating:  54%|███████████████████████████████████████████████████████████████████████████▉                                                                 | 7/13 [00:04<00:03,  1.78it/s]\u001b[A\n",
      "Epoch 5:  94%|▉| 60/64 [00:35<00:02,  1.73it/s, loss=3.24, v_num=xp39, train_loss_step=3.160, lr_step=0.000427, val_loss_step=3.160, val_loss_epoch=3.310, val/F1_top1=0.0346, val/acc_top1=0\u001b[A\n",
      "Validating:  69%|█████████████████████████████████████████████████████████████████████████████████████████████████▌                                           | 9/13 [00:05<00:01,  2.04it/s]\u001b[A\n",
      "Epoch 5:  97%|▉| 62/64 [00:35<00:01,  1.75it/s, loss=3.24, v_num=xp39, train_loss_step=3.160, lr_step=0.000427, val_loss_step=3.160, val_loss_epoch=3.310, val/F1_top1=0.0346, val/acc_top1=0\u001b[A\n",
      "Validating:  85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                     | 11/13 [00:05<00:00,  2.56it/s]\u001b[A\n",
      "Epoch 5: 100%|█| 64/64 [00:36<00:00,  1.78it/s, loss=3.24, v_num=xp39, train_loss_step=3.160, lr_step=0.000427, val_loss_step=3.160, val_loss_epoch=3.310, val/F1_top1=0.0346, val/acc_top1=0\u001b[A\n",
      "Epoch 5: 100%|█| 64/64 [00:38<00:00,  1.69it/s, loss=3.24, v_num=xp39, train_loss_step=3.160, lr_step=0.000427, val_loss_step=3.280, val_loss_epoch=3.130, val/F1_top1=0.0356, val/acc_top1=0\u001b[A\n",
      "                                                                                                                                                                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 305: val_loss reached 3.13088 (best 3.13088), saving model to \"/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/image_classification_train/2xf9xp39/checkpoints/checkpoint/epoch=05-val_loss=3.1309-val_f1=0.0000.ckpt\" as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  81%|▊| 52/64 [00:31<00:07,  1.67it/s, loss=2.99, v_num=xp39, train_loss_step=2.980, lr_step=0.000397, val_loss_step=3.280, val_loss_epoch=3.130, val/F1_top1=0.0356, val/acc_top1=0\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                                                     | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   8%|██████████▊                                                                                                                                  | 1/13 [00:01<00:22,  1.91s/it]\u001b[A\n",
      "Epoch 6:  84%|▊| 54/64 [00:33<00:06,  1.62it/s, loss=2.99, v_num=xp39, train_loss_step=2.980, lr_step=0.000397, val_loss_step=3.280, val_loss_epoch=3.130, val/F1_top1=0.0356, val/acc_top1=0\u001b[A\n",
      "Validating:  23%|████████████████████████████████▌                                                                                                            | 3/13 [00:02<00:10,  1.08s/it]\u001b[A\n",
      "Epoch 6:  88%|▉| 56/64 [00:34<00:04,  1.65it/s, loss=2.99, v_num=xp39, train_loss_step=2.980, lr_step=0.000397, val_loss_step=3.280, val_loss_epoch=3.130, val/F1_top1=0.0356, val/acc_top1=0\u001b[A\n",
      "Validating:  38%|██████████████████████████████████████████████████████▏                                                                                      | 5/13 [00:03<00:06,  1.33it/s]\u001b[A\n",
      "Epoch 6:  91%|▉| 58/64 [00:35<00:03,  1.67it/s, loss=2.99, v_num=xp39, train_loss_step=2.980, lr_step=0.000397, val_loss_step=3.280, val_loss_epoch=3.130, val/F1_top1=0.0356, val/acc_top1=0\u001b[A\n",
      "Validating:  54%|███████████████████████████████████████████████████████████████████████████▉                                                                 | 7/13 [00:03<00:03,  1.95it/s]\u001b[A\n",
      "Epoch 6:  94%|▉| 60/64 [00:35<00:02,  1.70it/s, loss=2.99, v_num=xp39, train_loss_step=2.980, lr_step=0.000397, val_loss_step=3.280, val_loss_epoch=3.130, val/F1_top1=0.0356, val/acc_top1=0\u001b[A\n",
      "Validating:  69%|█████████████████████████████████████████████████████████████████████████████████████████████████▌                                           | 9/13 [00:04<00:01,  2.19it/s]\u001b[A\n",
      "Epoch 6:  97%|▉| 62/64 [00:36<00:01,  1.72it/s, loss=2.99, v_num=xp39, train_loss_step=2.980, lr_step=0.000397, val_loss_step=3.280, val_loss_epoch=3.130, val/F1_top1=0.0356, val/acc_top1=0\u001b[A\n",
      "Validating:  85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                     | 11/13 [00:05<00:00,  2.72it/s]\u001b[A\n",
      "Epoch 6: 100%|█| 64/64 [00:37<00:00,  1.75it/s, loss=2.99, v_num=xp39, train_loss_step=2.980, lr_step=0.000397, val_loss_step=3.280, val_loss_epoch=3.130, val/F1_top1=0.0356, val/acc_top1=0\u001b[A\n",
      "Epoch 6: 100%|█| 64/64 [00:39<00:00,  1.66it/s, loss=2.99, v_num=xp39, train_loss_step=2.980, lr_step=0.000397, val_loss_step=2.670, val_loss_epoch=3.200, val/F1_top1=0.0323, val/acc_top1=0\u001b[A\n",
      "                                                                                                                                                                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 356: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  81%|▊| 52/64 [00:32<00:07,  1.66it/s, loss=2.99, v_num=xp39, train_loss_step=2.820, lr_step=0.000364, val_loss_step=2.670, val_loss_epoch=3.200, val/F1_top1=0.0323, val/acc_top1=0\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                                                     | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   8%|██████████▊                                                                                                                                  | 1/13 [00:01<00:23,  1.94s/it]\u001b[A\n",
      "Epoch 7:  84%|▊| 54/64 [00:34<00:06,  1.61it/s, loss=2.99, v_num=xp39, train_loss_step=2.820, lr_step=0.000364, val_loss_step=2.670, val_loss_epoch=3.200, val/F1_top1=0.0323, val/acc_top1=0\u001b[A\n",
      "Validating:  23%|████████████████████████████████▌                                                                                                            | 3/13 [00:02<00:10,  1.10s/it]\u001b[A\n",
      "Epoch 7:  88%|▉| 56/64 [00:34<00:04,  1.64it/s, loss=2.99, v_num=xp39, train_loss_step=2.820, lr_step=0.000364, val_loss_step=2.670, val_loss_epoch=3.200, val/F1_top1=0.0323, val/acc_top1=0\u001b[A\n",
      "Validating:  38%|██████████████████████████████████████████████████████▏                                                                                      | 5/13 [00:03<00:06,  1.28it/s]\u001b[A\n",
      "Epoch 7:  91%|▉| 58/64 [00:35<00:03,  1.65it/s, loss=2.99, v_num=xp39, train_loss_step=2.820, lr_step=0.000364, val_loss_step=2.670, val_loss_epoch=3.200, val/F1_top1=0.0323, val/acc_top1=0\u001b[A\n",
      "Validating:  54%|███████████████████████████████████████████████████████████████████████████▉                                                                 | 7/13 [00:03<00:03,  1.89it/s]\u001b[A\n",
      "Epoch 7:  94%|▉| 60/64 [00:36<00:02,  1.68it/s, loss=2.99, v_num=xp39, train_loss_step=2.820, lr_step=0.000364, val_loss_step=2.670, val_loss_epoch=3.200, val/F1_top1=0.0323, val/acc_top1=0\u001b[A\n",
      "Validating:  69%|█████████████████████████████████████████████████████████████████████████████████████████████████▌                                           | 9/13 [00:04<00:01,  2.25it/s]\u001b[A\n",
      "Epoch 7:  97%|▉| 62/64 [00:36<00:01,  1.70it/s, loss=2.99, v_num=xp39, train_loss_step=2.820, lr_step=0.000364, val_loss_step=2.670, val_loss_epoch=3.200, val/F1_top1=0.0323, val/acc_top1=0\u001b[A\n",
      "Validating:  85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                     | 11/13 [00:05<00:00,  2.72it/s]\u001b[A\n",
      "Epoch 7: 100%|█| 64/64 [00:37<00:00,  1.73it/s, loss=2.99, v_num=xp39, train_loss_step=2.820, lr_step=0.000364, val_loss_step=2.670, val_loss_epoch=3.200, val/F1_top1=0.0323, val/acc_top1=0\u001b[A\n",
      "Epoch 7: 100%|█| 64/64 [00:39<00:00,  1.66it/s, loss=2.99, v_num=xp39, train_loss_step=2.820, lr_step=0.000364, val_loss_step=2.640, val_loss_epoch=2.970, val/F1_top1=0.050, val/acc_top1=0.\u001b[A\n",
      "                                                                                                                                                                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 407: val_loss reached 2.96658 (best 2.96658), saving model to \"/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/image_classification_train/2xf9xp39/checkpoints/checkpoint/epoch=07-val_loss=2.9666-val_f1=0.0000.ckpt\" as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  81%|▊| 52/64 [00:33<00:07,  1.60it/s, loss=2.76, v_num=xp39, train_loss_step=3.190, lr_step=0.000328, val_loss_step=2.640, val_loss_epoch=2.970, val/F1_top1=0.050, val/acc_top1=0.\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                                                     | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8:  84%|▊| 54/64 [00:35<00:06,  1.57it/s, loss=2.76, v_num=xp39, train_loss_step=3.190, lr_step=0.000328, val_loss_step=2.640, val_loss_epoch=2.970, val/F1_top1=0.050, val/acc_top1=0.\u001b[A\n",
      "Epoch 8:  88%|▉| 56/64 [00:35<00:04,  1.62it/s, loss=2.76, v_num=xp39, train_loss_step=3.190, lr_step=0.000328, val_loss_step=2.640, val_loss_epoch=2.970, val/F1_top1=0.050, val/acc_top1=0.\u001b[A\n",
      "Epoch 8:  91%|▉| 58/64 [00:36<00:03,  1.62it/s, loss=2.76, v_num=xp39, train_loss_step=3.190, lr_step=0.000328, val_loss_step=2.640, val_loss_epoch=2.970, val/F1_top1=0.050, val/acc_top1=0.\u001b[A\n",
      "Epoch 8:  94%|▉| 60/64 [00:36<00:02,  1.67it/s, loss=2.76, v_num=xp39, train_loss_step=3.190, lr_step=0.000328, val_loss_step=2.640, val_loss_epoch=2.970, val/F1_top1=0.050, val/acc_top1=0.\u001b[A\n",
      "Validating:  69%|█████████████████████████████████████████████████████████████████████████████████████████████████▌                                           | 9/13 [00:04<00:02,  1.37it/s]\u001b[A\n",
      "Epoch 8:  97%|▉| 62/64 [00:38<00:01,  1.65it/s, loss=2.76, v_num=xp39, train_loss_step=3.190, lr_step=0.000328, val_loss_step=2.640, val_loss_epoch=2.970, val/F1_top1=0.050, val/acc_top1=0.\u001b[A\n",
      "Validating:  85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                     | 11/13 [00:05<00:01,  1.99it/s]\u001b[A\n",
      "Epoch 8: 100%|█| 64/64 [00:38<00:00,  1.68it/s, loss=2.76, v_num=xp39, train_loss_step=3.190, lr_step=0.000328, val_loss_step=2.640, val_loss_epoch=2.970, val/F1_top1=0.050, val/acc_top1=0.\u001b[A\n",
      "Epoch 8: 100%|█| 64/64 [00:41<00:00,  1.58it/s, loss=2.76, v_num=xp39, train_loss_step=3.190, lr_step=0.000328, val_loss_step=2.650, val_loss_epoch=2.980, val/F1_top1=0.0508, val/acc_top1=0\u001b[A\n",
      "                                                                                                                                                                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 458: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  81%|▊| 52/64 [00:29<00:06,  1.79it/s, loss=2.71, v_num=xp39, train_loss_step=2.610, lr_step=0.00029, val_loss_step=2.650, val_loss_epoch=2.980, val/F1_top1=0.0508, val/acc_top1=0.\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                                                                                                                                     | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   8%|██████████▊                                                                                                                                  | 1/13 [00:02<00:28,  2.35s/it]\u001b[A\n",
      "Epoch 9:  84%|▊| 54/64 [00:32<00:05,  1.70it/s, loss=2.71, v_num=xp39, train_loss_step=2.610, lr_step=0.00029, val_loss_step=2.650, val_loss_epoch=2.980, val/F1_top1=0.0508, val/acc_top1=0.\u001b[A\n",
      "Validating:  23%|████████████████████████████████▌                                                                                                            | 3/13 [00:02<00:12,  1.30s/it]\u001b[A\n",
      "Epoch 9:  88%|▉| 56/64 [00:32<00:04,  1.73it/s, loss=2.71, v_num=xp39, train_loss_step=2.610, lr_step=0.00029, val_loss_step=2.650, val_loss_epoch=2.980, val/F1_top1=0.0508, val/acc_top1=0.\u001b[A\n",
      "Validating:  38%|██████████████████████████████████████████████████████▏                                                                                      | 5/13 [00:04<00:07,  1.02it/s]\u001b[A\n",
      "Epoch 9:  91%|▉| 58/64 [00:34<00:03,  1.73it/s, loss=2.71, v_num=xp39, train_loss_step=2.610, lr_step=0.00029, val_loss_step=2.650, val_loss_epoch=2.980, val/F1_top1=0.0508, val/acc_top1=0.\u001b[A\n",
      "Validating:  54%|███████████████████████████████████████████████████████████████████████████▉                                                                 | 7/13 [00:04<00:03,  1.60it/s]\u001b[A\n",
      "Epoch 9:  94%|▉| 60/64 [00:34<00:02,  1.76it/s, loss=2.71, v_num=xp39, train_loss_step=2.610, lr_step=0.00029, val_loss_step=2.650, val_loss_epoch=2.980, val/F1_top1=0.0508, val/acc_top1=0.\u001b[A\n",
      "Validating:  69%|█████████████████████████████████████████████████████████████████████████████████████████████████▌                                           | 9/13 [00:05<00:02,  1.69it/s]\u001b[A\n",
      "Epoch 9:  97%|▉| 62/64 [00:35<00:01,  1.76it/s, loss=2.71, v_num=xp39, train_loss_step=2.610, lr_step=0.00029, val_loss_step=2.650, val_loss_epoch=2.980, val/F1_top1=0.0508, val/acc_top1=0.\u001b[A\n",
      "Validating:  85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                     | 11/13 [00:06<00:00,  2.30it/s]\u001b[A\n",
      "Epoch 9: 100%|█| 64/64 [00:36<00:00,  1.79it/s, loss=2.71, v_num=xp39, train_loss_step=2.610, lr_step=0.00029, val_loss_step=2.650, val_loss_epoch=2.980, val/F1_top1=0.0508, val/acc_top1=0.\u001b[A\n",
      "Epoch 9: 100%|█| 64/64 [00:38<00:00,  1.69it/s, loss=2.71, v_num=xp39, train_loss_step=2.610, lr_step=0.00029, val_loss_step=2.800, val_loss_epoch=3.030, val/F1_top1=0.038, val/acc_top1=0.0\u001b[A\n",
      "                                                                                                                                                                                             \u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 509: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|█| 64/64 [00:39<00:00,  1.66it/s, loss=2.71, v_num=xp39, train_loss_step=2.610, lr_step=0.00029, val_loss_step=2.800, val_loss_epoch=3.030, val/F1_top1=0.038, val/acc_top1=0.0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving latest checkpoint...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/pytorch_lightning/trainer/deprecated_api.py:32: LightningDeprecationWarning: `Trainer.train_loop` has been renamed to `Trainer.fit_loop` and will be removed in v1.6.\n",
      "  rank_zero_deprecation(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 32143<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 4.35MB of 4.35MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/wandb/run-20210830_220529-2xf9xp39/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/wandb/run-20210830_220529-2xf9xp39/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss_step</td><td>2.04558</td></tr><tr><td>lr_step</td><td>0.00029</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>trainer/global_step</td><td>509</td></tr><tr><td>_runtime</td><td>414</td></tr><tr><td>_timestamp</td><td>1630375943</td></tr><tr><td>_step</td><td>159</td></tr><tr><td>val_loss_step</td><td>2.80243</td></tr><tr><td>val_loss_epoch</td><td>3.02703</td></tr><tr><td>val/F1_top1</td><td>0.03804</td></tr><tr><td>val/acc_top1</td><td>0.04932</td></tr><tr><td>val/acc_top3</td><td>0.10013</td></tr><tr><td>val/precision_top1</td><td>0.03572</td></tr><tr><td>val/recall_top1</td><td>0.04932</td></tr><tr><td>train_loss_epoch</td><td>2.75546</td></tr><tr><td>lr_epoch</td><td>0.00029</td></tr><tr><td>train/F1_top1</td><td>0.05317</td></tr><tr><td>train/acc_top1</td><td>0.06203</td></tr><tr><td>train/acc_top3</td><td>0.10718</td></tr><tr><td>train/precision_top1</td><td>0.05242</td></tr><tr><td>train/recall_top1</td><td>0.06203</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_loss_step</td><td>█▇▆▄▆▆▃▅▃▁</td></tr><tr><td>lr_step</td><td>███▇▆▆▅▃▂▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▃▃▃▃▃▃▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇███</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃█</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>val_loss_step</td><td>▄▅▇█▄▅▅▆▃▄▄▃▃▅▅▅▃▄▄▄▂▃▃▃▃▄▄▄▁▃▃▄▂▅▃▃▃▃▃▂</td></tr><tr><td>val_loss_epoch</td><td>█▆▄▅▃▂▂▁▁▁</td></tr><tr><td>val/F1_top1</td><td>▁▂▃▂▅▅▄██▅</td></tr><tr><td>val/acc_top1</td><td>▁▂▃▂▅▅▄██▆</td></tr><tr><td>val/acc_top3</td><td>▁▂▃▂▅▆▅▇██</td></tr><tr><td>val/precision_top1</td><td>▁▂▂▂▅▅▄██▅</td></tr><tr><td>val/recall_top1</td><td>▁▂▃▂▅▅▄██▆</td></tr><tr><td>train_loss_epoch</td><td>█▇▅▄▄▃▃▂▁▁</td></tr><tr><td>lr_epoch</td><td>███▇▆▆▅▃▂▁</td></tr><tr><td>train/F1_top1</td><td>▁▂▃▄▄▅▅▆██</td></tr><tr><td>train/acc_top1</td><td>▁▂▃▄▃▅▆▆██</td></tr><tr><td>train/acc_top3</td><td>▁▂▃▅▅▆▆▇██</td></tr><tr><td>train/precision_top1</td><td>▁▂▃▄▄▅▆▆██</td></tr><tr><td>train/recall_top1</td><td>▁▂▃▄▃▅▆▆██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">scarlet-sun-127</strong>: <a href=\"https://wandb.ai/jrose/image_classification_train/runs/2xf9xp39\" target=\"_blank\">https://wandb.ai/jrose/image_classification_train/runs/2xf9xp39</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model ⚡🚅⚡\n",
    "trainer.fit(model, datamodule)\n",
    "\n",
    "# Close wandb run\n",
    "wandb.finish() \n",
    "\n",
    "# datamodule.num_classes\n",
    "# sorted(datamodule.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1494cbff",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80d2572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning_hydra_classifiers.utils.common_utils import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "experiment = TransferExperiment()\n",
    "\n",
    "task_0 = experiment.setup_task_0()\n",
    "\n",
    "task_0['train'].label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "285d25b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<LabelEncoder>:\n",
       "    num_classes: 93\n",
       "    fit on num_samples: 16605"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_0['val'].label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "449a02b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<LabelEncoder>:\n",
       "    num_classes: 20\n",
       "    fit on num_samples: 2797"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_0['test'].label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "52fdebd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<LabelEncoder(num_classes=0)>\n",
      "<num_replaced_classes=1>\n",
      "<LabelEncoder(num_classes=0)>\n",
      "<num_replaced_classes=1>\n"
     ]
    }
   ],
   "source": [
    "replace_class_indices = {\"Nothofagaceae\":\"Fagaceae\"}\n",
    "task_0_label_encoder = task_0['train'].label_encoder\n",
    "print(task_0_label_encoder)\n",
    "\n",
    "task_0_label_encoder.__init__(replace = replace_class_indices)\n",
    "\n",
    "print(task_0_label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3049c075",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(task_0_label_encoder.classes))\n",
    "print(task_0_label_encoder)\n",
    "task_0_label_encoder.fit(task_0['test'].targets)\n",
    "print(len(task_0_label_encoder.classes))\n",
    "print(task_0_label_encoder)\n",
    "task_0_label_encoder.fit(task_0['train'].targets)\n",
    "print(len(task_0_label_encoder.classes))\n",
    "print(task_0_label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "afacf310",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(task_0_label_encoder)\n",
    "\n",
    "\n",
    "\n",
    "import collections\n",
    "\n",
    "self = task_0_label_encoder\n",
    "y = task_0['test'].targets\n",
    "\n",
    "counts = collections.Counter(y)\n",
    "print(self.num_samples)\n",
    "self.num_samples += sum(counts.values())\n",
    "print(self.num_samples)\n",
    "\n",
    "classes = sorted(counts.keys())\n",
    "print(classes)\n",
    "print(len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "724563ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old_num_classes = len(self)\n",
    "# print(f\"old_num_classes={old_num_classes}\")\n",
    "# new_classes = sorted([label for label in classes if label not in self.classes])\n",
    "# print(f'new_classes={new_classes}')\n",
    "# print(f'len(new_classes)={len(new_classes)}')\n",
    "\n",
    "old_num_classes = len(self)\n",
    "print(f\"old_num_classes={old_num_classes}\")\n",
    "new_classes = []\n",
    "for label in classes:\n",
    "    if (label not in self.classes) and (label not in self.replace):\n",
    "        new_classes.append(label)\n",
    "# new_classes = sorted([label for label in classes if label not in self.classes])\n",
    "print(f'new_classes={new_classes}')\n",
    "print(f'len(new_classes)={len(new_classes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f8685eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, label in enumerate(new_classes):\n",
    "    self.class2idx[label] = old_num_classes + i\n",
    "print(self.class2idx)\n",
    "print(len(self.class2idx))\n",
    "\n",
    "self.index2class = {v: k for k, v in self.class2idx.items()}\n",
    "\n",
    "all_classes = []\n",
    "for label in self.class2idx.keys():\n",
    "    if label not in self.replace.keys():\n",
    "        all_classes.append(label)\n",
    "print(f\"all_classes={all_classes}\")\n",
    "print(f\"len(all_classes)={len(all_classes)}\")\n",
    "\n",
    "self.classes = sorted(all_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "278268b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.classes = [k for k in self.class2idx.keys() if k not in self.replace.keys()] \n",
    "print(len(self.class2idx), len(self.index2class), len(self.classes))\n",
    "\n",
    "self.replace_class2idx_items()\n",
    "print(len(self.class2idx), len(self.index2class), len(self.classes))\n",
    "\n",
    "new_classes = [c for c in new_classes if c not in self.replace.keys()]\n",
    "if len(new_classes):\n",
    "    log.debug(f\"[FITTING] {len(y)} samples with {len(classes)} classes, adding {len(new_classes)} new class labels. Latest num_classes = {len(self)}\")\n",
    "assert len(self) == (old_num_classes + len(new_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9941d6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.index2class = {v: k for k, v in self.class2idx.items()}\n",
    "\n",
    "# all_classes = []\n",
    "\n",
    "self.classes = [k for k in self.class2idx.keys() if k not in self.replace.keys()]        \n",
    "self.replace_class2idx_items()\n",
    "\n",
    "new_classes = [c for c in new_classes if c not in self.replace.keys()]\n",
    "if len(new_classes):\n",
    "    log.debug(f\"[FITTING] {len(y)} samples with {len(classes)} classes, adding {len(new_classes)} new class labels. Latest num_classes = {len(self)}\")\n",
    "assert len(self) == (old_num_classes + len(new_classes))\n",
    "\n",
    "(task_0['test'].label_encoder)\n",
    "\n",
    "(task_0['test'].classes)\n",
    "\n",
    "\n",
    "\n",
    "sorted(set(datamodule.train_dataset.targets))\n",
    "\n",
    "len(sorted(set(datamodule.train_dataset.classes)))\n",
    "\n",
    "\n",
    "len(sorted(set(datamodule.train_dataset.classes)))\n",
    "\n",
    "\n",
    "datamodule.num_classes\n",
    "\n",
    "import numpy as np\n",
    "set(np.arange(len(datamodule.train_dataset.classes))) - set(datamodule.train_dataset.targets)\n",
    "\n",
    "import numpy as np\n",
    "set(datamodule.train_dataset.targets) - set(np.arange(len(datamodule.train_dataset.classes)))\n",
    "\n",
    "\n",
    "len(sorted(set(datamodule.train_dataset.targets)))\n",
    "\n",
    "model.metrics_train\n",
    "\n",
    "model.metrics_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b1b7f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bca4f8ae",
   "metadata": {},
   "source": [
    "## Export experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03a8ffda",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_path = \"/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/experiments_August_2021/Extant-to-PNAS-512-transfer_benchmark/task_0/test.json\"\n",
    "\n",
    "from lightning_hydra_classifiers.utils.common_utils import LabelEncoder\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85de203e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<LabelEncoder>:\n",
       "    num_classes: 177\n",
       "    fit on num_samples: 0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelEncoder.load(encoder_path)\n",
    "\n",
    "encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20faf1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoder.class2idx)\n",
    "\n",
    "len(encoder.index2class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86534cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Fagaceae', 'Phyllanthaceae'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(encoder.class2idx.keys()) - set(encoder.index2class.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23506c4b",
   "metadata": {},
   "source": [
    "```\n",
    "LabelEncoder:  \n",
    "    ::class2idx  \n",
    "        - Needs to have a many-to-one mapping from text to int. All int labels are unique, but multiple class names can map to 1 int label.\n",
    "    ::idx2class  \n",
    "        - Needs to have a one-to-one mapping from int to text. For ints that map to more than 1 text label, this maps the int only to the correct standardized label for the experiment. As in, it maps only to the label we used to replace another label. e.g. If replacements includes {\"NothoFagaceae\": \"Fagaceae\"}, and both  of them maps to int label 16, then encoder.idx2class[16] must return \"Fagaceae\".\n",
    "    ::classes  \n",
    "    ::num_classes  \n",
    "        - Needs to correspond to actual neural net output size, therefore excludes replaced classes\n",
    "    ::replacements  \n",
    "```\n",
    "\n",
    "* len(idx2class) <= len(class2idx)\n",
    "* num_classes == len(idx2class) <= len(class2idx)\n",
    "\n",
    "\n",
    "\n",
    "1. Initialize blank label encoder\n",
    "    - Provide replacements dict to allow backwards compatible mappings\n",
    "        - e.g. Nothofagaceae (newer, Extant) -> Fagaceae (older, PNAS)\n",
    "\n",
    "2. Fit encoder on $|y_s|$ to have "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaf282c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df08dfa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8115c1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting experiment to experiment_dir: /media/data_cifs/projects/prj_fossils/users/jacob/experiments/July2021-Nov2021/csv_datasets/experimental_datasets/Extant-to-PNAS-512-transfer_benchmark\n",
      "train 16605\n",
      "val 4152\n",
      "train 2011\n",
      "val 503\n",
      "19\n",
      "92\n"
     ]
    }
   ],
   "source": [
    "from lightning_hydra_classifiers.experiments.transfer_experiment import TransferExperiment\n",
    "output_root_dir = \"/media/data_cifs/projects/prj_fossils/users/jacob/experiments/July2021-Nov2021/csv_datasets/experimental_datasets\"\n",
    "experiment = TransferExperiment()\n",
    "experiment.export_experiment_spec(output_root_dir=output_root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf92c3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "self = experiment\n",
    "\n",
    "replace_class_indices = {\"Nothofagaceae\":\"Fagaceae\"}\n",
    "\n",
    "task_0 = self.setup_task_0()\n",
    "task_1 = self.setup_task_1()\n",
    "\n",
    "#         import pdb;pdb.set_trace()\n",
    "\n",
    "\n",
    "\n",
    "#         print(f\"__init__: {task_0['train'].label_encoder}\")\n",
    "task_0_label_encoder = task_0['train'].label_encoder\n",
    "task_0_label_encoder.__init__(replacements = replace_class_indices)\n",
    "\n",
    "# print(max(task_0_label_encoder.class2idx.values()))\n",
    "task_0_label_encoder.class2idx\n",
    "\n",
    "print(len(set(task_0['test'].targets)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(len(set(task_0_label_encoder.classes)))\n",
    "task_0_label_encoder.fit(task_0['test'].targets)\n",
    "print(len(set(task_0_label_encoder.classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44fc68a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Anacardiaceae': 0,\n",
       " 'Annonaceae': 1,\n",
       " 'Apocynaceae': 2,\n",
       " 'Betulaceae': 3,\n",
       " 'Celastraceae': 4,\n",
       " 'Combretaceae': 5,\n",
       " 'Ericaceae': 6,\n",
       " 'Fabaceae': 7,\n",
       " 'Fagaceae': 8,\n",
       " 'Lauraceae': 9,\n",
       " 'Malvaceae': 10,\n",
       " 'Melastomataceae': 11,\n",
       " 'Myrtaceae': 12,\n",
       " 'Passifloraceae': 13,\n",
       " 'Phyllanthaceae': 14,\n",
       " 'Rosaceae': 15,\n",
       " 'Rubiaceae': 16,\n",
       " 'Salicaceae': 17,\n",
       " 'Sapindaceae': 18,\n",
       " 'Nothofagaceae': 8}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(max(task_0_label_encoder.class2idx.values()))\n",
    "task_0_label_encoder.class2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60fe646e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n"
     ]
    }
   ],
   "source": [
    "print(len(set(task_0['train'].targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44233894",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(len(set(task_0_label_encoder.classes)))\n",
    "task_0_label_encoder.fit(task_0['train'].targets)\n",
    "print(len(set(task_0_label_encoder.classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e392dabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(max(task_0_label_encoder.class2idx.values()))\n",
    "task_0_label_encoder.class2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79ab1350",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_0_label_encoder.classes\n",
    "\n",
    "task_0_label_encoder.idx2class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aace7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r \"/media/data_cifs/projects/prj_fossils/users/jacob/experiments/July2021-Nov2021/csv_datasets/experimental_datasets/task_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5455a7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class self:\n",
    "    idx2class = {0:\"test\",\n",
    "                 1:\"2\"}\n",
    "\n",
    "\n",
    "\n",
    "old_highest_class = max(self.idx2class.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e16eefe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_highest_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5560c1c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Refactor LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17da326c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numbers\n",
    "from typing import Union, List, Any, Tuple, Dict, Optional, Sequence\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "from lightning_hydra_classifiers.utils import template_utils\n",
    "from lightning_hydra_classifiers.utils.plot_utils import colorbar\n",
    "\n",
    "\n",
    "log = template_utils.get_logger(__name__)\n",
    "\n",
    "\n",
    "# __all__ = [\"LabelEncoder\", \"trainval_split\", \"trainvaltest_split\", \"plot_split_distributions\", \"plot_class_distributions\",\n",
    "#            \"filter_df_by_threshold\", \"compute_class_counts\"]\n",
    "\n",
    "\n",
    "\n",
    "class LabelEncoder(object):\n",
    "    \n",
    "    \"\"\"Label encoder for tag labels.\"\"\"\n",
    "    def __init__(self,\n",
    "                 class2idx: Dict[str,int]=None,\n",
    "                 replacements: Optional[Dict[str,str]]=None):\n",
    "        self.class2idx = class2idx or {}\n",
    "        self.replacements = replacements or {}\n",
    "#         self.idx2class = {v: k for k, v in self.class2idx.items() if k not in self.replacements.keys()}\n",
    "#         self.classes = [k for k in self.class2idx.keys() if k not in self.replacements.keys()]\n",
    "        \n",
    "        assert len(self.classes) == len(self.idx2class) <= len(self.class2idx)\n",
    "        self.num_samples = 0\n",
    "        self.verbose=False\n",
    "        self.replace_class2idx_items()\n",
    "        \n",
    "\n",
    "    @property\n",
    "    def idx2class(self):\n",
    "        return {v: k for k, v in self.class2idx.items() if k not in self.replacements.keys()}\n",
    "    \n",
    "    @property\n",
    "    def classes(self):\n",
    "        return [k for k in self.class2idx.keys() if k not in self.replacements.keys()]\n",
    "    \n",
    "\n",
    "        \n",
    "    def replace_class2idx_items(self):\n",
    "        \"\"\"\n",
    "        Update inplace self.class2idx mappings, so that any class labels in self.replacements.keys()\n",
    "        map to the same int label as their corresponding value in self.replacements.values().\n",
    "        \n",
    "        \"\"\"\n",
    "        if (len(self.replacements) == 0) \\\n",
    "        or (len([k for k in self.replacements.keys() if k in self.class2idx.keys()]) == 0):\n",
    "            # No-op if replacements keys are empty or have zero overlap with class2idx keys.\n",
    "            return\n",
    "        \n",
    "        if self.verbose:\n",
    "            log.info(f'LabelEncoder replacing {len(self.replacements.keys())} class encodings with that other an another class')\n",
    "            log.info('Replacing: ' + str({k:v for k,v in self.replacements.items() if k in self.class2idx}))\n",
    "        for old, new in self.replacements.items():\n",
    "            if old in list(self.class2idx.keys()):\n",
    "                self.class2idx[old] = self.class2idx[new]\n",
    "#         self.idx2class = {v: k for k, v in self.class2idx.items()}\n",
    "#         self.classes = [k for k in self.class2idx.keys() if k not in self.replacements.keys()]                \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.idx2class)\n",
    "#         return len(self.classes)\n",
    "\n",
    "    def num_classes(self):\n",
    "        return len(self)\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        msg = f\"<LabelEncoder(num_classes={len(self)})>\"\n",
    "        if len(self.replacements) > 0:\n",
    "            msg += \"\\n\" + f\"<num_replaced_classes={len(self.replacements)}>\"\n",
    "        return msg\n",
    "\n",
    "    def fit(self, y):\n",
    "        \n",
    "        counts = collections.Counter(y)\n",
    "        self.num_samples += sum(counts.values())\n",
    "        \n",
    "        classes = sorted(list(counts.keys()))\n",
    "        new_classes = sorted([label for label in classes if label not in self.classes])\n",
    "        \n",
    "        old_num_classes = len(self)\n",
    "        old_highest_class = max(self.idx2class.keys())\n",
    "        for i, label in enumerate(new_classes):\n",
    "            self.class2idx[label] = old_highest_class + i\n",
    "#         self.idx2class = {v: k for k, v in self.class2idx.items()}\n",
    "#         self.classes = [k for k in self.class2idx.keys() if k not in self.replacements.keys()]        \n",
    "        self.replace_class2idx_items()\n",
    "\n",
    "        new_classes = [c for c in new_classes if c not in self.replacements.keys()]\n",
    "        if len(new_classes):\n",
    "            log.debug(f\"[FITTING] {len(y)} samples with {len(classes)} classes, adding {len(new_classes)} new class labels. Latest num_classes = {len(self)}\")\n",
    "        assert len(self) == (old_num_classes + len(new_classes))\n",
    "        assert np.all([label in self.idx2class.values() for label in new_classes])\n",
    "        return self\n",
    "\n",
    "    def encode(self, y):\n",
    "        if not hasattr(y,\"__len__\"):\n",
    "            y = [y]\n",
    "#         print(self.class2idx)\n",
    "        return np.array([self.class2idx[label] for label in y])\n",
    "\n",
    "    def decode(self, y):\n",
    "        if not hasattr(y,\"__len__\"):\n",
    "            y = [y]\n",
    "        return np.array([self.idx2class[label] for label in y])\n",
    "\n",
    "    def save(self, fp):\n",
    "        with open(fp, \"w\") as fp:\n",
    "            contents = self.getstate() # {\"class2idx\": self.class2idx}\n",
    "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, fp):\n",
    "        with open(fp, \"r\") as fp:\n",
    "            kwargs = json.load(fp=fp)\n",
    "        return cls(**kwargs)\n",
    "    \n",
    "    def getstate(self):\n",
    "        return {\"class2idx\": self.class2idx,\n",
    "                \"replacements\": self.replacements}\n",
    "    \n",
    "    def __repr__(self):\n",
    "        disp = f\"\"\"<{str(type(self)).strip(\"'>\").split('.')[-1]}>:\\n\"\"\"\n",
    "        disp += f\"    num_classes: {len(self)}\\n\"\n",
    "        disp += f\"    fit on num_samples: {self.num_samples}\"\n",
    "        return disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d496d85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91e68cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 16605\n",
      "val 4152\n"
     ]
    }
   ],
   "source": [
    "from lightning_hydra_classifiers.utils.common_utils import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "experiment = TransferExperiment()\n",
    "task_0 = experiment.setup_task_0()\n",
    "\n",
    "old_encoder = task_0['train'].label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21908585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old: <LabelEncoder(num_classes=93)>\n",
      "New, initialized: <LabelEncoder(num_classes=0)>\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "print(f\"Old:\", old_encoder)\n",
    "print(\"New, initialized:\", encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b65e1e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = task_0['train']\n",
    "data_df = data.samples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "322de5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment\n",
    "\n",
    "replace_class_indices = {\"Nothofagaceae\":\"Fagaceae\"}\n",
    "\n",
    "(data.label_encoder.replace)\n",
    "\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd217b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>newest_family</th>\n",
       "      <th>genus</th>\n",
       "      <th>species</th>\n",
       "      <th>collection</th>\n",
       "      <th>catalog_number</th>\n",
       "      <th>family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Cannabaceae/Cannabaceae_Celtis_biondii_Wolfe_Wolfe_8999b.jpg</td>\n",
       "      <td>Cannabaceae</td>\n",
       "      <td>Celtis</td>\n",
       "      <td>biondii</td>\n",
       "      <td>Wolfe</td>\n",
       "      <td>Wolfe_8999b</td>\n",
       "      <td>Cannabaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Sapindaceae/Sapindaceae_Serjania_acutidentata_Wing_Wing_597-003b.jpg</td>\n",
       "      <td>Sapindaceae</td>\n",
       "      <td>Serjania</td>\n",
       "      <td>acutidentata</td>\n",
       "      <td>Wing</td>\n",
       "      <td>Wing_597-003b</td>\n",
       "      <td>Sapindaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Fabaceae/Fabaceae_Pithecellobium_lasiopus_Hickey_Hickey_4124.jpg</td>\n",
       "      <td>Fabaceae</td>\n",
       "      <td>Pithecellobium</td>\n",
       "      <td>lasiopus</td>\n",
       "      <td>Hickey</td>\n",
       "      <td>Hickey_4124</td>\n",
       "      <td>Fabaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Rutaceae/Rutaceae_Clausena_heptaphylla_Hickey_Hickey_6081.jpg</td>\n",
       "      <td>Rutaceae</td>\n",
       "      <td>Clausena</td>\n",
       "      <td>heptaphylla</td>\n",
       "      <td>Hickey</td>\n",
       "      <td>Hickey_6081</td>\n",
       "      <td>Rutaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Bignoniaceae/Bignoniaceae_Dolichandrone_cauda-felina_Wolfe_Wolfe_2413a.jpg</td>\n",
       "      <td>Bignoniaceae</td>\n",
       "      <td>Dolichandrone</td>\n",
       "      <td>cauda-felina</td>\n",
       "      <td>Wolfe</td>\n",
       "      <td>Wolfe_2413a</td>\n",
       "      <td>Bignoniaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16600</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Rosaceae/Rosaceae_Prunus_subcordata_Axelrod_Axelrod_387.jpg</td>\n",
       "      <td>Rosaceae</td>\n",
       "      <td>Prunus</td>\n",
       "      <td>subcordata</td>\n",
       "      <td>Axelrod</td>\n",
       "      <td>Axelrod_387</td>\n",
       "      <td>Rosaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16601</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Celastraceae/Celastraceae_Celastrus_paniculatus_Hickey_Hickey_4380.jpg</td>\n",
       "      <td>Celastraceae</td>\n",
       "      <td>Celastrus</td>\n",
       "      <td>paniculatus</td>\n",
       "      <td>Hickey</td>\n",
       "      <td>Hickey_4380</td>\n",
       "      <td>Celastraceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16602</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Acanthaceae/Acanthaceae_Staurogyne_anigozanthus_Hickey_Hickey_1238_1.jpg</td>\n",
       "      <td>Acanthaceae</td>\n",
       "      <td>Staurogyne</td>\n",
       "      <td>anigozanthus</td>\n",
       "      <td>Hickey</td>\n",
       "      <td>Hickey_1238_1</td>\n",
       "      <td>Acanthaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16603</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Lauraceae/Lauraceae_Stemmatodaphne_perakensis_Wolfe_Wolfe_15508a.jpg</td>\n",
       "      <td>Lauraceae</td>\n",
       "      <td>Stemmatodaphne</td>\n",
       "      <td>perakensis</td>\n",
       "      <td>Wolfe</td>\n",
       "      <td>Wolfe_15508a</td>\n",
       "      <td>Lauraceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16604</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Salicaceae/Salicaceae_Salix_pulchra_Wolfe_Wolfe_2196.jpg</td>\n",
       "      <td>Salicaceae</td>\n",
       "      <td>Salix</td>\n",
       "      <td>pulchra</td>\n",
       "      <td>Wolfe</td>\n",
       "      <td>Wolfe_2196</td>\n",
       "      <td>Salicaceae</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16605 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                     path  \\\n",
       "0                    /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Cannabaceae/Cannabaceae_Celtis_biondii_Wolfe_Wolfe_8999b.jpg   \n",
       "1            /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Sapindaceae/Sapindaceae_Serjania_acutidentata_Wing_Wing_597-003b.jpg   \n",
       "2                /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Fabaceae/Fabaceae_Pithecellobium_lasiopus_Hickey_Hickey_4124.jpg   \n",
       "3                   /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Rutaceae/Rutaceae_Clausena_heptaphylla_Hickey_Hickey_6081.jpg   \n",
       "4      /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Bignoniaceae/Bignoniaceae_Dolichandrone_cauda-felina_Wolfe_Wolfe_2413a.jpg   \n",
       "...                                                                                                                                                                                   ...   \n",
       "16600                 /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Rosaceae/Rosaceae_Prunus_subcordata_Axelrod_Axelrod_387.jpg   \n",
       "16601      /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Celastraceae/Celastraceae_Celastrus_paniculatus_Hickey_Hickey_4380.jpg   \n",
       "16602    /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Acanthaceae/Acanthaceae_Staurogyne_anigozanthus_Hickey_Hickey_1238_1.jpg   \n",
       "16603        /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Lauraceae/Lauraceae_Stemmatodaphne_perakensis_Wolfe_Wolfe_15508a.jpg   \n",
       "16604                    /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Salicaceae/Salicaceae_Salix_pulchra_Wolfe_Wolfe_2196.jpg   \n",
       "\n",
       "      newest_family           genus       species collection catalog_number  \\\n",
       "0       Cannabaceae          Celtis       biondii      Wolfe    Wolfe_8999b   \n",
       "1       Sapindaceae        Serjania  acutidentata       Wing  Wing_597-003b   \n",
       "2          Fabaceae  Pithecellobium      lasiopus     Hickey    Hickey_4124   \n",
       "3          Rutaceae        Clausena   heptaphylla     Hickey    Hickey_6081   \n",
       "4      Bignoniaceae   Dolichandrone  cauda-felina      Wolfe    Wolfe_2413a   \n",
       "...             ...             ...           ...        ...            ...   \n",
       "16600      Rosaceae          Prunus    subcordata    Axelrod    Axelrod_387   \n",
       "16601  Celastraceae       Celastrus   paniculatus     Hickey    Hickey_4380   \n",
       "16602   Acanthaceae      Staurogyne  anigozanthus     Hickey  Hickey_1238_1   \n",
       "16603     Lauraceae  Stemmatodaphne    perakensis      Wolfe   Wolfe_15508a   \n",
       "16604    Salicaceae           Salix       pulchra      Wolfe     Wolfe_2196   \n",
       "\n",
       "             family  \n",
       "0       Cannabaceae  \n",
       "1       Sapindaceae  \n",
       "2          Fabaceae  \n",
       "3          Rutaceae  \n",
       "4      Bignoniaceae  \n",
       "...             ...  \n",
       "16600      Rosaceae  \n",
       "16601  Celastraceae  \n",
       "16602   Acanthaceae  \n",
       "16603     Lauraceae  \n",
       "16604    Salicaceae  \n",
       "\n",
       "[16605 rows x 7 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = data_df.rename(columns={\"family\":\"newest_family\"})\n",
    "data_df = data_df.assign(family = data_df.newest_family.replace(replace_class_indices))\n",
    "data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1bb7b4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16605 entries, 0 to 16604\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   path            16605 non-null  string\n",
      " 1   newest_family   16605 non-null  string\n",
      " 2   genus           16605 non-null  string\n",
      " 3   species         16605 non-null  string\n",
      " 4   collection      16605 non-null  string\n",
      " 5   catalog_number  16605 non-null  string\n",
      " 6   family          16605 non-null  object\n",
      "dtypes: object(1), string(6)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# data_df = data_df.sort_values(\"family\").astype({\"family\":pd.CategoricalDtype(),\n",
    "#                           \"newest_family\":pd.CategoricalDtype()}) #family.cat #!=data_df.newest_family]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "48def6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16605 entries, 16111 to 8302\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype   \n",
      "---  ------          --------------  -----   \n",
      " 0   path            16605 non-null  string  \n",
      " 1   newest_family   16605 non-null  category\n",
      " 2   genus           16605 non-null  string  \n",
      " 3   species         16605 non-null  string  \n",
      " 4   collection      16605 non-null  string  \n",
      " 5   catalog_number  16605 non-null  string  \n",
      " 6   family          16605 non-null  category\n",
      "dtypes: category(2), string(5)\n",
      "memory usage: 816.3 KB\n"
     ]
    }
   ],
   "source": [
    "data_df = data_df.sort_values(\"family\").astype({\"family\":pd.CategoricalDtype()})\n",
    "data_df = data_df.convert_dtypes()\n",
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "08f84637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " '_AXIS_LEN',\n",
       " '_AXIS_ORDERS',\n",
       " '_AXIS_REVERSED',\n",
       " '_AXIS_TO_AXIS_NUMBER',\n",
       " '_HANDLED_TYPES',\n",
       " '__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__annotations__',\n",
       " '__array__',\n",
       " '__array_priority__',\n",
       " '__array_ufunc__',\n",
       " '__array_wrap__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__divmod__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__finalize__',\n",
       " '__float__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__iand__',\n",
       " '__ifloordiv__',\n",
       " '__imod__',\n",
       " '__imul__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__int__',\n",
       " '__invert__',\n",
       " '__ior__',\n",
       " '__ipow__',\n",
       " '__isub__',\n",
       " '__iter__',\n",
       " '__itruediv__',\n",
       " '__ixor__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__long__',\n",
       " '__lt__',\n",
       " '__matmul__',\n",
       " '__mod__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__or__',\n",
       " '__pos__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rand__',\n",
       " '__rdivmod__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rmatmul__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__ror__',\n",
       " '__round__',\n",
       " '__rpow__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__rxor__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__weakref__',\n",
       " '__xor__',\n",
       " '_accessors',\n",
       " '_accum_func',\n",
       " '_add_numeric_operations',\n",
       " '_agg_by_level',\n",
       " '_agg_examples_doc',\n",
       " '_agg_see_also_doc',\n",
       " '_align_frame',\n",
       " '_align_series',\n",
       " '_arith_method',\n",
       " '_as_manager',\n",
       " '_attrs',\n",
       " '_binop',\n",
       " '_can_hold_na',\n",
       " '_check_inplace_and_allows_duplicate_labels',\n",
       " '_check_inplace_setting',\n",
       " '_check_is_chained_assignment_possible',\n",
       " '_check_label_or_level_ambiguity',\n",
       " '_check_setitem_copy',\n",
       " '_clear_item_cache',\n",
       " '_clip_with_one_bound',\n",
       " '_clip_with_scalar',\n",
       " '_cmp_method',\n",
       " '_consolidate',\n",
       " '_consolidate_inplace',\n",
       " '_construct_axes_dict',\n",
       " '_construct_axes_from_arguments',\n",
       " '_construct_result',\n",
       " '_constructor',\n",
       " '_constructor_expanddim',\n",
       " '_convert',\n",
       " '_convert_dtypes',\n",
       " '_data',\n",
       " '_dir_additions',\n",
       " '_dir_deletions',\n",
       " '_drop_axis',\n",
       " '_drop_labels_or_levels',\n",
       " '_duplicated',\n",
       " '_find_valid_index',\n",
       " '_flags',\n",
       " '_from_mgr',\n",
       " '_get_axis',\n",
       " '_get_axis_name',\n",
       " '_get_axis_number',\n",
       " '_get_axis_resolvers',\n",
       " '_get_block_manager_axis',\n",
       " '_get_bool_data',\n",
       " '_get_cacher',\n",
       " '_get_cleaned_column_resolvers',\n",
       " '_get_index_resolvers',\n",
       " '_get_label_or_level_values',\n",
       " '_get_numeric_data',\n",
       " '_get_value',\n",
       " '_get_values',\n",
       " '_get_values_tuple',\n",
       " '_get_with',\n",
       " '_gotitem',\n",
       " '_hidden_attrs',\n",
       " '_index',\n",
       " '_indexed_same',\n",
       " '_info_axis',\n",
       " '_info_axis_name',\n",
       " '_info_axis_number',\n",
       " '_init_dict',\n",
       " '_init_mgr',\n",
       " '_inplace_method',\n",
       " '_internal_names',\n",
       " '_internal_names_set',\n",
       " '_is_cached',\n",
       " '_is_copy',\n",
       " '_is_label_or_level_reference',\n",
       " '_is_label_reference',\n",
       " '_is_level_reference',\n",
       " '_is_mixed_type',\n",
       " '_is_view',\n",
       " '_item_cache',\n",
       " '_ixs',\n",
       " '_logical_func',\n",
       " '_logical_method',\n",
       " '_map_values',\n",
       " '_maybe_update_cacher',\n",
       " '_memory_usage',\n",
       " '_metadata',\n",
       " '_mgr',\n",
       " '_min_count_stat_function',\n",
       " '_name',\n",
       " '_needs_reindex_multi',\n",
       " '_protect_consolidate',\n",
       " '_reduce',\n",
       " '_reindex_axes',\n",
       " '_reindex_indexer',\n",
       " '_reindex_multi',\n",
       " '_reindex_with_indexers',\n",
       " '_replace_single',\n",
       " '_repr_data_resource_',\n",
       " '_repr_latex_',\n",
       " '_reset_cache',\n",
       " '_reset_cacher',\n",
       " '_set_as_cached',\n",
       " '_set_axis',\n",
       " '_set_axis_name',\n",
       " '_set_axis_nocheck',\n",
       " '_set_is_copy',\n",
       " '_set_labels',\n",
       " '_set_name',\n",
       " '_set_value',\n",
       " '_set_values',\n",
       " '_set_with',\n",
       " '_set_with_engine',\n",
       " '_slice',\n",
       " '_stat_axis',\n",
       " '_stat_axis_name',\n",
       " '_stat_axis_number',\n",
       " '_stat_function',\n",
       " '_stat_function_ddof',\n",
       " '_take_with_is_copy',\n",
       " '_typ',\n",
       " '_update_inplace',\n",
       " '_validate_dtype',\n",
       " '_values',\n",
       " '_where',\n",
       " 'abs',\n",
       " 'add',\n",
       " 'add_prefix',\n",
       " 'add_suffix',\n",
       " 'agg',\n",
       " 'aggregate',\n",
       " 'align',\n",
       " 'all',\n",
       " 'any',\n",
       " 'append',\n",
       " 'apply',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'argsort',\n",
       " 'array',\n",
       " 'asfreq',\n",
       " 'asof',\n",
       " 'astype',\n",
       " 'at',\n",
       " 'at_time',\n",
       " 'attrs',\n",
       " 'autocorr',\n",
       " 'axes',\n",
       " 'backfill',\n",
       " 'between',\n",
       " 'between_time',\n",
       " 'bfill',\n",
       " 'bool',\n",
       " 'cat',\n",
       " 'clip',\n",
       " 'combine',\n",
       " 'combine_first',\n",
       " 'compare',\n",
       " 'convert_dtypes',\n",
       " 'copy',\n",
       " 'corr',\n",
       " 'count',\n",
       " 'cov',\n",
       " 'cummax',\n",
       " 'cummin',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'describe',\n",
       " 'diff',\n",
       " 'div',\n",
       " 'divide',\n",
       " 'divmod',\n",
       " 'dot',\n",
       " 'drop',\n",
       " 'drop_duplicates',\n",
       " 'droplevel',\n",
       " 'dropna',\n",
       " 'dtype',\n",
       " 'dtypes',\n",
       " 'duplicated',\n",
       " 'empty',\n",
       " 'eq',\n",
       " 'equals',\n",
       " 'ewm',\n",
       " 'expanding',\n",
       " 'explode',\n",
       " 'factorize',\n",
       " 'ffill',\n",
       " 'fillna',\n",
       " 'filter',\n",
       " 'first',\n",
       " 'first_valid_index',\n",
       " 'flags',\n",
       " 'floordiv',\n",
       " 'ge',\n",
       " 'get',\n",
       " 'groupby',\n",
       " 'gt',\n",
       " 'hasnans',\n",
       " 'head',\n",
       " 'hist',\n",
       " 'iat',\n",
       " 'idxmax',\n",
       " 'idxmin',\n",
       " 'iloc',\n",
       " 'index',\n",
       " 'infer_objects',\n",
       " 'interpolate',\n",
       " 'is_monotonic',\n",
       " 'is_monotonic_decreasing',\n",
       " 'is_monotonic_increasing',\n",
       " 'is_unique',\n",
       " 'isin',\n",
       " 'isna',\n",
       " 'isnull',\n",
       " 'item',\n",
       " 'items',\n",
       " 'iteritems',\n",
       " 'keys',\n",
       " 'kurt',\n",
       " 'kurtosis',\n",
       " 'last',\n",
       " 'last_valid_index',\n",
       " 'le',\n",
       " 'loc',\n",
       " 'lt',\n",
       " 'mad',\n",
       " 'map',\n",
       " 'mask',\n",
       " 'max',\n",
       " 'mean',\n",
       " 'median',\n",
       " 'memory_usage',\n",
       " 'min',\n",
       " 'mod',\n",
       " 'mode',\n",
       " 'mul',\n",
       " 'multiply',\n",
       " 'name',\n",
       " 'nbytes',\n",
       " 'ndim',\n",
       " 'ne',\n",
       " 'nlargest',\n",
       " 'notna',\n",
       " 'notnull',\n",
       " 'nsmallest',\n",
       " 'nunique',\n",
       " 'pad',\n",
       " 'pct_change',\n",
       " 'pipe',\n",
       " 'plot',\n",
       " 'pop',\n",
       " 'pow',\n",
       " 'prod',\n",
       " 'product',\n",
       " 'quantile',\n",
       " 'radd',\n",
       " 'rank',\n",
       " 'ravel',\n",
       " 'rdiv',\n",
       " 'rdivmod',\n",
       " 'reindex',\n",
       " 'reindex_like',\n",
       " 'rename',\n",
       " 'rename_axis',\n",
       " 'reorder_levels',\n",
       " 'repeat',\n",
       " 'replace',\n",
       " 'resample',\n",
       " 'reset_index',\n",
       " 'rfloordiv',\n",
       " 'rmod',\n",
       " 'rmul',\n",
       " 'rolling',\n",
       " 'round',\n",
       " 'rpow',\n",
       " 'rsub',\n",
       " 'rtruediv',\n",
       " 'sample',\n",
       " 'searchsorted',\n",
       " 'sem',\n",
       " 'set_axis',\n",
       " 'set_flags',\n",
       " 'shape',\n",
       " 'shift',\n",
       " 'size',\n",
       " 'skew',\n",
       " 'slice_shift',\n",
       " 'sort_index',\n",
       " 'sort_values',\n",
       " 'squeeze',\n",
       " 'std',\n",
       " 'str',\n",
       " 'sub',\n",
       " 'subtract',\n",
       " 'sum',\n",
       " 'swapaxes',\n",
       " 'swaplevel',\n",
       " 'tail',\n",
       " 'take',\n",
       " 'to_clipboard',\n",
       " 'to_csv',\n",
       " 'to_dict',\n",
       " 'to_excel',\n",
       " 'to_frame',\n",
       " 'to_hdf',\n",
       " 'to_json',\n",
       " 'to_latex',\n",
       " 'to_list',\n",
       " 'to_markdown',\n",
       " 'to_numpy',\n",
       " 'to_period',\n",
       " 'to_pickle',\n",
       " 'to_sql',\n",
       " 'to_string',\n",
       " 'to_timestamp',\n",
       " 'to_xarray',\n",
       " 'transform',\n",
       " 'transpose',\n",
       " 'truediv',\n",
       " 'truncate',\n",
       " 'tz_convert',\n",
       " 'tz_localize',\n",
       " 'unique',\n",
       " 'unstack',\n",
       " 'update',\n",
       " 'value_counts',\n",
       " 'values',\n",
       " 'var',\n",
       " 'view',\n",
       " 'where',\n",
       " 'xs']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(data_df.family[~data_df.family.duplicated(keep='first')])\n",
    "# data_df.family.duplicated(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d62cee1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = \"family\"\n",
    "category_df = data_df[y_col][~data_df[y_col].duplicated(keep='first')]   #.to_list()\n",
    "class2index = dict(zip(category_df.to_list(), category_df.cat.codes.to_list()))\n",
    "# data_df.family.duplicated(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5802eaeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Acanthaceae': 0,\n",
       " 'Achariaceae': 1,\n",
       " 'Actinidiaceae': 2,\n",
       " 'Altingiaceae': 3,\n",
       " 'Amaranthaceae': 4,\n",
       " 'Anacardiaceae': 5,\n",
       " 'Annonaceae': 6,\n",
       " 'Apiaceae': 7,\n",
       " 'Apocynaceae': 8,\n",
       " 'Aquifoliaceae': 9,\n",
       " 'Araliaceae': 10,\n",
       " 'Asteraceae': 11,\n",
       " 'Berberidaceae': 12,\n",
       " 'Betulaceae': 13,\n",
       " 'Bignoniaceae': 14,\n",
       " 'Burseraceae': 15,\n",
       " 'Cannabaceae': 16,\n",
       " 'Capparaceae': 17,\n",
       " 'Caprifoliaceae': 18,\n",
       " 'Celastraceae': 19,\n",
       " 'Chloranthaceae': 20,\n",
       " 'Chrysobalanaceae': 21,\n",
       " 'Clusiaceae': 22,\n",
       " 'Combretaceae': 23,\n",
       " 'Connaraceae': 24,\n",
       " 'Cornaceae': 25,\n",
       " 'Crassulaceae': 26,\n",
       " 'Cunoniaceae': 27,\n",
       " 'Dilleniaceae': 28,\n",
       " 'Dipterocarpaceae': 29,\n",
       " 'Ebenaceae': 30,\n",
       " 'Elaeocarpaceae': 31,\n",
       " 'Ericaceae': 32,\n",
       " 'Euphorbiaceae': 33,\n",
       " 'Fabaceae': 34,\n",
       " 'Fagaceae': 35,\n",
       " 'Grossulariaceae': 36,\n",
       " 'Hamamelidaceae': 37,\n",
       " 'Hydrangeaceae': 38,\n",
       " 'Icacinaceae': 39,\n",
       " 'Juglandaceae': 40,\n",
       " 'Lamiaceae': 41,\n",
       " 'Lauraceae': 42,\n",
       " 'Lecythidaceae': 43,\n",
       " 'Loranthaceae': 44,\n",
       " 'Lythraceae': 45,\n",
       " 'Magnoliaceae': 46,\n",
       " 'Malpighiaceae': 47,\n",
       " 'Malvaceae': 48,\n",
       " 'Marantaceae': 49,\n",
       " 'Melastomataceae': 50,\n",
       " 'Meliaceae': 51,\n",
       " 'Menispermaceae': 52,\n",
       " 'Monimiaceae': 53,\n",
       " 'Moraceae': 54,\n",
       " 'Myristicaceae': 55,\n",
       " 'Myrtaceae': 56,\n",
       " 'Ochnaceae': 57,\n",
       " 'Olacaceae': 58,\n",
       " 'Oleaceae': 59,\n",
       " 'Onagraceae': 60,\n",
       " 'Passifloraceae': 61,\n",
       " 'Pentaphylacaceae': 62,\n",
       " 'Phyllanthaceae': 63,\n",
       " 'Pittosporaceae': 64,\n",
       " 'Platanaceae': 65,\n",
       " 'Polygalaceae': 66,\n",
       " 'Primulaceae': 67,\n",
       " 'Proteaceae': 68,\n",
       " 'Ranunculaceae': 69,\n",
       " 'Rhamnaceae': 70,\n",
       " 'Rhizophoraceae': 71,\n",
       " 'Rosaceae': 72,\n",
       " 'Rubiaceae': 73,\n",
       " 'Rutaceae': 74,\n",
       " 'Sabiaceae': 75,\n",
       " 'Salicaceae': 76,\n",
       " 'Santalaceae': 77,\n",
       " 'Sapindaceae': 78,\n",
       " 'Sapotaceae': 79,\n",
       " 'Saxifragaceae': 80,\n",
       " 'Schisandraceae': 81,\n",
       " 'Scrophulariaceae': 82,\n",
       " 'Simaroubaceae': 83,\n",
       " 'Solanaceae': 84,\n",
       " 'Theaceae': 85,\n",
       " 'Thymelaeaceae': 86,\n",
       " 'Ulmaceae': 87,\n",
       " 'Violaceae': 88,\n",
       " 'Vitaceae': 89,\n",
       " 'Winteraceae': 90,\n",
       " 'Zygophyllaceae': 91}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b06c314b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16605 entries, 0 to 16604\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype   \n",
      "---  ------          --------------  -----   \n",
      " 0   path            16605 non-null  string  \n",
      " 1   newest_family   16605 non-null  string  \n",
      " 2   genus           16605 non-null  string  \n",
      " 3   species         16605 non-null  string  \n",
      " 4   collection      16605 non-null  string  \n",
      " 5   catalog_number  16605 non-null  string  \n",
      " 6   family          16605 non-null  category\n",
      "dtypes: category(1), string(6)\n",
      "memory usage: 927.1 KB\n"
     ]
    }
   ],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8f74981c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__annotations__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__frozen',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_accessors',\n",
       " '_add_delegate_accessors',\n",
       " '_constructor',\n",
       " '_delegate_method',\n",
       " '_delegate_property_get',\n",
       " '_delegate_property_set',\n",
       " '_dir_additions',\n",
       " '_dir_deletions',\n",
       " '_freeze',\n",
       " '_hidden_attrs',\n",
       " '_index',\n",
       " '_name',\n",
       " '_parent',\n",
       " '_reset_cache',\n",
       " '_validate',\n",
       " 'add_categories',\n",
       " 'as_ordered',\n",
       " 'as_unordered',\n",
       " 'categories',\n",
       " 'codes',\n",
       " 'ordered',\n",
       " 'remove_categories',\n",
       " 'remove_unused_categories',\n",
       " 'rename_categories',\n",
       " 'reorder_categories',\n",
       " 'set_categories']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(data_df.family.cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "044ffab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(data_df.family.cat.codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "69d7f895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.family.cat.ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74b140c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.family.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "75e13489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>newest_family</th>\n",
       "      <th>genus</th>\n",
       "      <th>species</th>\n",
       "      <th>collection</th>\n",
       "      <th>catalog_number</th>\n",
       "      <th>family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_macrophylla_Hickey_Hickey_6169.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Nothofagus</td>\n",
       "      <td>macrophylla</td>\n",
       "      <td>Hickey</td>\n",
       "      <td>Hickey_6169</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_grandis_Hickey_Hickey_1766.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Nothofagus</td>\n",
       "      <td>grandis</td>\n",
       "      <td>Hickey</td>\n",
       "      <td>Hickey_1766</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Trisyngyne_discoidea_Hickey_Hickey_718.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Trisyngyne</td>\n",
       "      <td>discoidea</td>\n",
       "      <td>Hickey</td>\n",
       "      <td>Hickey_718</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_discoidea_Wolfe_Wolfe_8533.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Nothofagus</td>\n",
       "      <td>discoidea</td>\n",
       "      <td>Wolfe</td>\n",
       "      <td>Wolfe_8533</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_aequilateralis_Wolfe_Wolfe_8530.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Nothofagus</td>\n",
       "      <td>aequilateralis</td>\n",
       "      <td>Wolfe</td>\n",
       "      <td>Wolfe_8530</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3066</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_nitida_Hickey_Hickey_1781.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Nothofagus</td>\n",
       "      <td>nitida</td>\n",
       "      <td>Hickey</td>\n",
       "      <td>Hickey_1781</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3294</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_discoidea_Hickey_Hickey_6432.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Nothofagus</td>\n",
       "      <td>discoidea</td>\n",
       "      <td>Hickey</td>\n",
       "      <td>Hickey_6432</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4482</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_perryi_Wolfe_Wolfe_8534.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Nothofagus</td>\n",
       "      <td>perryi</td>\n",
       "      <td>Wolfe</td>\n",
       "      <td>Wolfe_8534</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5272</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_gunni_Hickey_Hickey_1773.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Nothofagus</td>\n",
       "      <td>gunni</td>\n",
       "      <td>Hickey</td>\n",
       "      <td>Hickey_1773</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5283</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_fusca_Wolfe_Wolfe_3218.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Nothofagus</td>\n",
       "      <td>fusca</td>\n",
       "      <td>Wolfe</td>\n",
       "      <td>Wolfe_3218</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6341</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_brassi_Hickey_Hickey_1777.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Nothofagus</td>\n",
       "      <td>brassi</td>\n",
       "      <td>Hickey</td>\n",
       "      <td>Hickey_1777</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7764</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_dombeyi_Hickey_Hickey_189.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Nothofagus</td>\n",
       "      <td>dombeyi</td>\n",
       "      <td>Hickey</td>\n",
       "      <td>Hickey_189</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8309</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_codonandra_Hickey_Hickey_6649.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Nothofagus</td>\n",
       "      <td>codonandra</td>\n",
       "      <td>Hickey</td>\n",
       "      <td>Hickey_6649</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8830</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_leoni_Hickey_Hickey_1782.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Nothofagus</td>\n",
       "      <td>leoni</td>\n",
       "      <td>Hickey</td>\n",
       "      <td>Hickey_1782</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9043</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_moorei_Wolfe_Wolfe_3219.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Nothofagus</td>\n",
       "      <td>moorei</td>\n",
       "      <td>Wolfe</td>\n",
       "      <td>Wolfe_3219</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9085</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_dombeyi_Hickey_Hickey_216.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Nothofagus</td>\n",
       "      <td>dombeyi</td>\n",
       "      <td>Hickey</td>\n",
       "      <td>Hickey_216</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9640</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_balansae_Wolfe_Wolfe_8531.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Nothofagus</td>\n",
       "      <td>balansae</td>\n",
       "      <td>Wolfe</td>\n",
       "      <td>Wolfe_8531</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9681</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_truncata_Hickey_Hickey_1769.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Nothofagus</td>\n",
       "      <td>truncata</td>\n",
       "      <td>Hickey</td>\n",
       "      <td>Hickey_1769</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10135</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_menziesi_Hickey_Hickey_1767_2.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Nothofagus</td>\n",
       "      <td>menziesi</td>\n",
       "      <td>Hickey</td>\n",
       "      <td>Hickey_1767_2</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10755</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_moorei_Hickey_Hickey_55.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Nothofagus</td>\n",
       "      <td>moorei</td>\n",
       "      <td>Hickey</td>\n",
       "      <td>Hickey_55</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10858</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_procera_Hickey_Hickey_1760.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Nothofagus</td>\n",
       "      <td>procera</td>\n",
       "      <td>Hickey</td>\n",
       "      <td>Hickey_1760</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11000</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_aequilateralis_Hickey_Hickey_1771.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Nothofagus</td>\n",
       "      <td>aequilateralis</td>\n",
       "      <td>Hickey</td>\n",
       "      <td>Hickey_1771</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11051</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_baumanniae_Hickey_Hickey_1772.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Nothofagus</td>\n",
       "      <td>baumanniae</td>\n",
       "      <td>Hickey</td>\n",
       "      <td>Hickey_1772</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11183</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_glauca_Hickey_Hickey_1780.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Nothofagus</td>\n",
       "      <td>glauca</td>\n",
       "      <td>Hickey</td>\n",
       "      <td>Hickey_1780</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11764</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_codonandra_Hickey_Hickey_6650_2.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Nothofagus</td>\n",
       "      <td>codonandra</td>\n",
       "      <td>Hickey</td>\n",
       "      <td>Hickey_6650_2</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11839</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_baumanniae_Wolfe_Wolfe_8532.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Nothofagus</td>\n",
       "      <td>baumanniae</td>\n",
       "      <td>Wolfe</td>\n",
       "      <td>Wolfe_8532</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12113</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_pumilio_Hickey_Hickey_1761.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Nothofagus</td>\n",
       "      <td>pumilio</td>\n",
       "      <td>Hickey</td>\n",
       "      <td>Hickey_1761</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12416</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_antarctica_Wolfe_Wolfe_6784.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Nothofagus</td>\n",
       "      <td>antarctica</td>\n",
       "      <td>Wolfe</td>\n",
       "      <td>Wolfe_6784</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12596</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_flaviramea_Wolfe_Wolfe_3217.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Nothofagus</td>\n",
       "      <td>flaviramea</td>\n",
       "      <td>Wolfe</td>\n",
       "      <td>Wolfe_3217</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13034</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_dombeyi_Hickey_Hickey_197.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Nothofagus</td>\n",
       "      <td>dombeyi</td>\n",
       "      <td>Hickey</td>\n",
       "      <td>Hickey_197</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14355</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_cunninghamii_Hickey_Hickey_1770_2.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Nothofagus</td>\n",
       "      <td>cunninghamii</td>\n",
       "      <td>Hickey</td>\n",
       "      <td>Hickey_1770_2</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15411</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_betuloides_Hickey_Hickey_1758.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Nothofagus</td>\n",
       "      <td>betuloides</td>\n",
       "      <td>Hickey</td>\n",
       "      <td>Hickey_1758</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15712</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_alessandri_Hickey_Hickey_1783.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Nothofagus</td>\n",
       "      <td>alessandri</td>\n",
       "      <td>Hickey</td>\n",
       "      <td>Hickey_1783</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15935</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_balansae_Hickey_Hickey_1762.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Nothofagus</td>\n",
       "      <td>balansae</td>\n",
       "      <td>Hickey</td>\n",
       "      <td>Hickey_1762</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16013</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_carri_Hickey_Hickey_1776.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Nothofagus</td>\n",
       "      <td>carri</td>\n",
       "      <td>Hickey</td>\n",
       "      <td>Hickey_1776</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16080</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_antarctica_Hickey_Hickey_1757.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Nothofagus</td>\n",
       "      <td>antarctica</td>\n",
       "      <td>Hickey</td>\n",
       "      <td>Hickey_1757</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16229</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_antarctica_Hickey_Hickey_1756.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Nothofagus</td>\n",
       "      <td>antarctica</td>\n",
       "      <td>Hickey</td>\n",
       "      <td>Hickey_1756</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16330</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_pullei_Hickey_Hickey_1775.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Nothofagus</td>\n",
       "      <td>pullei</td>\n",
       "      <td>Hickey</td>\n",
       "      <td>Hickey_1775</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16494</th>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_discoidea_Hickey_Hickey_6668.jpg</td>\n",
       "      <td>Nothofagaceae</td>\n",
       "      <td>Nothofagus</td>\n",
       "      <td>discoidea</td>\n",
       "      <td>Hickey</td>\n",
       "      <td>Hickey_6668</td>\n",
       "      <td>Fagaceae</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                       path  \\\n",
       "533       /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_macrophylla_Hickey_Hickey_6169.jpg   \n",
       "668           /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_grandis_Hickey_Hickey_1766.jpg   \n",
       "1237         /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Trisyngyne_discoidea_Hickey_Hickey_718.jpg   \n",
       "1277          /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_discoidea_Wolfe_Wolfe_8533.jpg   \n",
       "1685     /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_aequilateralis_Wolfe_Wolfe_8530.jpg   \n",
       "3066           /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_nitida_Hickey_Hickey_1781.jpg   \n",
       "3294        /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_discoidea_Hickey_Hickey_6432.jpg   \n",
       "4482             /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_perryi_Wolfe_Wolfe_8534.jpg   \n",
       "5272            /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_gunni_Hickey_Hickey_1773.jpg   \n",
       "5283              /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_fusca_Wolfe_Wolfe_3218.jpg   \n",
       "6341           /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_brassi_Hickey_Hickey_1777.jpg   \n",
       "7764           /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_dombeyi_Hickey_Hickey_189.jpg   \n",
       "8309       /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_codonandra_Hickey_Hickey_6649.jpg   \n",
       "8830            /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_leoni_Hickey_Hickey_1782.jpg   \n",
       "9043             /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_moorei_Wolfe_Wolfe_3219.jpg   \n",
       "9085           /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_dombeyi_Hickey_Hickey_216.jpg   \n",
       "9640           /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_balansae_Wolfe_Wolfe_8531.jpg   \n",
       "9681         /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_truncata_Hickey_Hickey_1769.jpg   \n",
       "10135      /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_menziesi_Hickey_Hickey_1767_2.jpg   \n",
       "10755            /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_moorei_Hickey_Hickey_55.jpg   \n",
       "10858         /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_procera_Hickey_Hickey_1760.jpg   \n",
       "11000  /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_aequilateralis_Hickey_Hickey_1771.jpg   \n",
       "11051      /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_baumanniae_Hickey_Hickey_1772.jpg   \n",
       "11183          /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_glauca_Hickey_Hickey_1780.jpg   \n",
       "11764    /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_codonandra_Hickey_Hickey_6650_2.jpg   \n",
       "11839        /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_baumanniae_Wolfe_Wolfe_8532.jpg   \n",
       "12113         /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_pumilio_Hickey_Hickey_1761.jpg   \n",
       "12416        /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_antarctica_Wolfe_Wolfe_6784.jpg   \n",
       "12596        /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_flaviramea_Wolfe_Wolfe_3217.jpg   \n",
       "13034          /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_dombeyi_Hickey_Hickey_197.jpg   \n",
       "14355  /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_cunninghamii_Hickey_Hickey_1770_2.jpg   \n",
       "15411      /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_betuloides_Hickey_Hickey_1758.jpg   \n",
       "15712      /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_alessandri_Hickey_Hickey_1783.jpg   \n",
       "15935        /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_balansae_Hickey_Hickey_1762.jpg   \n",
       "16013           /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_carri_Hickey_Hickey_1776.jpg   \n",
       "16080      /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_antarctica_Hickey_Hickey_1757.jpg   \n",
       "16229      /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_antarctica_Hickey_Hickey_1756.jpg   \n",
       "16330          /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_pullei_Hickey_Hickey_1775.jpg   \n",
       "16494       /media/data_cifs/projects/prj_fossils/data/processed_data/leavesdb-v1_0/images/Extant_Leaves/512/50/jpg/Nothofagaceae/Nothofagaceae_Nothofagus_discoidea_Hickey_Hickey_6668.jpg   \n",
       "\n",
       "       newest_family       genus         species collection catalog_number  \\\n",
       "533    Nothofagaceae  Nothofagus     macrophylla     Hickey    Hickey_6169   \n",
       "668    Nothofagaceae  Nothofagus         grandis     Hickey    Hickey_1766   \n",
       "1237   Nothofagaceae  Trisyngyne       discoidea     Hickey     Hickey_718   \n",
       "1277   Nothofagaceae  Nothofagus       discoidea      Wolfe     Wolfe_8533   \n",
       "1685   Nothofagaceae  Nothofagus  aequilateralis      Wolfe     Wolfe_8530   \n",
       "3066   Nothofagaceae  Nothofagus          nitida     Hickey    Hickey_1781   \n",
       "3294   Nothofagaceae  Nothofagus       discoidea     Hickey    Hickey_6432   \n",
       "4482   Nothofagaceae  Nothofagus          perryi      Wolfe     Wolfe_8534   \n",
       "5272   Nothofagaceae  Nothofagus           gunni     Hickey    Hickey_1773   \n",
       "5283   Nothofagaceae  Nothofagus           fusca      Wolfe     Wolfe_3218   \n",
       "6341   Nothofagaceae  Nothofagus          brassi     Hickey    Hickey_1777   \n",
       "7764   Nothofagaceae  Nothofagus         dombeyi     Hickey     Hickey_189   \n",
       "8309   Nothofagaceae  Nothofagus      codonandra     Hickey    Hickey_6649   \n",
       "8830   Nothofagaceae  Nothofagus           leoni     Hickey    Hickey_1782   \n",
       "9043   Nothofagaceae  Nothofagus          moorei      Wolfe     Wolfe_3219   \n",
       "9085   Nothofagaceae  Nothofagus         dombeyi     Hickey     Hickey_216   \n",
       "9640   Nothofagaceae  Nothofagus        balansae      Wolfe     Wolfe_8531   \n",
       "9681   Nothofagaceae  Nothofagus        truncata     Hickey    Hickey_1769   \n",
       "10135  Nothofagaceae  Nothofagus        menziesi     Hickey  Hickey_1767_2   \n",
       "10755  Nothofagaceae  Nothofagus          moorei     Hickey      Hickey_55   \n",
       "10858  Nothofagaceae  Nothofagus         procera     Hickey    Hickey_1760   \n",
       "11000  Nothofagaceae  Nothofagus  aequilateralis     Hickey    Hickey_1771   \n",
       "11051  Nothofagaceae  Nothofagus      baumanniae     Hickey    Hickey_1772   \n",
       "11183  Nothofagaceae  Nothofagus          glauca     Hickey    Hickey_1780   \n",
       "11764  Nothofagaceae  Nothofagus      codonandra     Hickey  Hickey_6650_2   \n",
       "11839  Nothofagaceae  Nothofagus      baumanniae      Wolfe     Wolfe_8532   \n",
       "12113  Nothofagaceae  Nothofagus         pumilio     Hickey    Hickey_1761   \n",
       "12416  Nothofagaceae  Nothofagus      antarctica      Wolfe     Wolfe_6784   \n",
       "12596  Nothofagaceae  Nothofagus      flaviramea      Wolfe     Wolfe_3217   \n",
       "13034  Nothofagaceae  Nothofagus         dombeyi     Hickey     Hickey_197   \n",
       "14355  Nothofagaceae  Nothofagus    cunninghamii     Hickey  Hickey_1770_2   \n",
       "15411  Nothofagaceae  Nothofagus      betuloides     Hickey    Hickey_1758   \n",
       "15712  Nothofagaceae  Nothofagus      alessandri     Hickey    Hickey_1783   \n",
       "15935  Nothofagaceae  Nothofagus        balansae     Hickey    Hickey_1762   \n",
       "16013  Nothofagaceae  Nothofagus           carri     Hickey    Hickey_1776   \n",
       "16080  Nothofagaceae  Nothofagus      antarctica     Hickey    Hickey_1757   \n",
       "16229  Nothofagaceae  Nothofagus      antarctica     Hickey    Hickey_1756   \n",
       "16330  Nothofagaceae  Nothofagus          pullei     Hickey    Hickey_1775   \n",
       "16494  Nothofagaceae  Nothofagus       discoidea     Hickey    Hickey_6668   \n",
       "\n",
       "         family  \n",
       "533    Fagaceae  \n",
       "668    Fagaceae  \n",
       "1237   Fagaceae  \n",
       "1277   Fagaceae  \n",
       "1685   Fagaceae  \n",
       "3066   Fagaceae  \n",
       "3294   Fagaceae  \n",
       "4482   Fagaceae  \n",
       "5272   Fagaceae  \n",
       "5283   Fagaceae  \n",
       "6341   Fagaceae  \n",
       "7764   Fagaceae  \n",
       "8309   Fagaceae  \n",
       "8830   Fagaceae  \n",
       "9043   Fagaceae  \n",
       "9085   Fagaceae  \n",
       "9640   Fagaceae  \n",
       "9681   Fagaceae  \n",
       "10135  Fagaceae  \n",
       "10755  Fagaceae  \n",
       "10858  Fagaceae  \n",
       "11000  Fagaceae  \n",
       "11051  Fagaceae  \n",
       "11183  Fagaceae  \n",
       "11764  Fagaceae  \n",
       "11839  Fagaceae  \n",
       "12113  Fagaceae  \n",
       "12416  Fagaceae  \n",
       "12596  Fagaceae  \n",
       "13034  Fagaceae  \n",
       "14355  Fagaceae  \n",
       "15411  Fagaceae  \n",
       "15712  Fagaceae  \n",
       "15935  Fagaceae  \n",
       "16013  Fagaceae  \n",
       "16080  Fagaceae  \n",
       "16229  Fagaceae  \n",
       "16330  Fagaceae  \n",
       "16494  Fagaceae  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[data_df.family!=data_df.newest_family]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50d9572",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "# BYOL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243ec9fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load and preprocess pre-formatted csv datasets and create train val test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c2130fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '5'\n",
    "\n",
    "from torchvision.models import mobilenet_v2, resnet50\n",
    "from torchvision.datasets import STL10\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "from lightning_hydra_classifiers.train_BYOL import *\n",
    "torch.backends.cudnn.benchmark = True\n",
    "from munch import Munch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de759e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config: Munch({'dataset_name': 'Extant-PNAS', 'model': {'backbone': 'resnet50'}})\n",
      "\n",
      " List of all classes: \n",
      "['Fagaceae', 'Ericaceae', 'Fabaceae', 'Anacardiaceae', 'Rosaceae', 'Betulaceae', 'Salicaceae', 'Sapindaceae', 'Lauraceae', 'Rubiaceae', 'Celastraceae', 'Malvaceae', 'Myrtaceae', 'Apocynaceae', 'Melastomataceae', 'Passifloraceae', 'Combretaceae', 'Annonaceae', 'Phyllanthaceae', 'Clusiaceae', 'Sapotaceae', 'Lythraceae', 'Burseraceae', 'Bignoniaceae', 'Meliaceae', 'Malpighiaceae', 'Cunoniaceae', 'Onagraceae', 'Marantaceae', 'Santalaceae', 'Berberidaceae', 'Ochnaceae', 'Ebenaceae', 'Cornaceae', 'Sabiaceae', 'Schisandraceae', 'Araliaceae', 'Staphyleaceae', 'Hamamelidaceae', 'Dipterocarpaceae', 'Dichapetalaceae', 'Dilleniaceae', 'Proteaceae', 'Connaraceae', 'Caprifoliaceae', 'Piperaceae', 'Bonnetiaceae', 'Juglandaceae', 'Geraniaceae', 'Aquifoliaceae', 'Moraceae', 'Rutaceae', 'Cercidiphyllaceae', 'Orchidaceae', 'Orobanchaceae', 'Apiaceae', 'Violaceae', 'Altingiaceae', 'Eucommiaceae', 'Gnetaceae', 'Rhamnaceae', 'Polemoniaceae', 'Menispermaceae', 'Polygalaceae', 'Lamiaceae', 'Oleaceae', 'Zygophyllaceae', 'Primulaceae', 'Canellaceae', 'Hydrangeaceae', 'Euphorbiaceae', 'Myristicaceae', 'Monimiaceae', 'Altiingiaceae', 'Adoxaceae', 'Ranunculaceae', 'Ancistrocladaceae', 'Nyctaginaceae', 'Actinidiaceae', 'Magnoliaceae', 'Cannabaceae', 'Olacaceae', 'Elaeocarpaceae', 'Campanulaceae', 'Achariaceae', 'Loganiaceae', 'Atherospermataceae', 'Crassulaceae', 'Acanthaceae', 'Icacinaceae', 'Simaroubaceae', 'Chrysobalanaceae', 'Papaveraceae', 'Pentaphylacaceae', 'Styracaceae', 'Stemonuraceae', 'Capparaceae', 'Thymelaeaceae', 'Siparunaceae', 'Asteraceae', 'Calophyllaceae', 'Pittosporaceae', 'Boraginaceae', 'Winteraceae', 'Platanaceae', 'Rhizophoraceae', 'Trigoniaceae', 'Clethraceae', 'Solanaceae', 'Buxaceae', 'Symplocaceae', 'Rhabdodendraceae', 'Amaranthaceae', 'Verbenaceae', 'Saxifragaceae', 'Vitaceae', 'Linaceae', 'Polygonaceae', 'Ulmaceae', 'Lecythidaceae', 'Marcgraviaceae', 'Humiriaceae', 'Stegnospermataceae', 'Chloranthaceae', 'Schoepfiaceae', 'Sarcolaenaceae', 'Lardizabalaceae', 'Hypericaceae', 'Liliaceae', 'Loranthaceae', 'Balsaminaceae', 'Oxalidaceae', 'Scrophulariaceae', 'Gesneriaceae', 'Urticaceae', 'Myricaceae', 'Grossulariaceae', 'Vochysiaceae', 'Coriariaceae', 'Caryocaraceae', 'Paracryphiaceae', 'Melianthaceae', 'Phytolaccaceae', 'Gentianaceae', 'Theaceae', 'Cardiopteridaceae', 'Cucurbitaceae', 'Iteaceae', 'Erythroxylaceae', 'Crossosomataceae', 'Anisophylleaceae', 'Irvingiaceae', 'Gunneraceae', 'Balanopaceae', 'Bixaceae', 'Calycanthaceae', 'Picrodendraceae', 'Penaeaceae', 'Garryaceae', 'Opiliaceae', 'Aristolochiaceae', 'Picramniaceae', 'Escalloniaceae', 'Hernandiaceae', 'Ixonanthaceae', 'Nitrariaceae', 'Argophyllaceae', 'Centroplacaceae', 'Pandaceae', 'Achatocarpaceae', 'Smilacaceae', 'Trochodendraceae', 'Stachyuraceae', 'Brunelliaceae', 'Sphaerosepalaceae', 'Peridiscaceae', 'Pedaliaceae', 'Caricaceae']\n",
      "len(classes)=178\n"
     ]
    }
   ],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "if 'TOY_DATA_DIR' not in os.environ: \n",
    "    print(f\"Setting env variable $TOY_DATA_DIR={os.environ['TOY_DATA_DIR']}\")\n",
    "    os.environ['TOY_DATA_DIR'] = \"/media/data_cifs/projects/prj_fossils/data/toy_data\"\n",
    "default_root_dir = os.environ['TOY_DATA_DIR']\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "\n",
    "\n",
    "config = Munch({\"dataset_name\":\"Extant-PNAS\",\n",
    "                \"model\":{\n",
    "                    \"backbone\":\"resnet50\"}\n",
    "               })\n",
    "# config = Munch({\"dataset_name\":\"STL10\"})\n",
    "print(f\"config: {config}\")\n",
    "\n",
    "\n",
    "transform = transforms.Compose([ToTensor(),\n",
    "                               normalize])\n",
    "\n",
    "\n",
    "\n",
    "if config.dataset_name == \"STL10\":\n",
    "    from torchbearer.cv_utils import DatasetValidationSplitter\n",
    "\n",
    "    train_data = STL10(os.environ['TOY_DATA_DIR'], split='train', transform=transform, download=True)\n",
    "    test_data = STL10(os.environ['TOY_DATA_DIR'], split='test', transform=transform, download=True)\n",
    "    \n",
    "    splitter = DatasetValidationSplitter(len(train_data), 0.1)\n",
    "    train_set = splitter.get_train_dataset(train_data)\n",
    "    val_set = splitter.get_val_dataset(train_data)\n",
    "    \n",
    "else:\n",
    "    exp = TransferExperiment()\n",
    "    task_0, task_1 = exp.get_multitask_datasets(train_transform=transform,\n",
    "                                                val_transform=transform)\n",
    "    train_data, val_data, test_data = task_0[\"train\"], task_0[\"val\"], task_0[\"test\"]\n",
    "    train_set, val_set = train_data, val_data\n",
    "\n",
    "classes = train_data.classes\n",
    "num_classes = len(classes)\n",
    "print('\\n List of all classes: ')\n",
    "print(classes)\n",
    "print(f\"len(classes)={len(classes)}\")\n",
    "\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "num_workers = 2\n",
    "pin_memory = False\n",
    "\n",
    "train_gen = torch.utils.data.DataLoader(train_set, pin_memory=pin_memory, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers)\n",
    "val_gen = torch.utils.data.DataLoader(val_set, pin_memory=pin_memory, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers)\n",
    "test_gen = torch.utils.data.DataLoader(test_data, pin_memory=pin_memory, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a91a204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = PyCM().on_val().to_html_file('cm.{epoch}')\n",
    "\n",
    "# We copy the final layer form MobileNetV2 and replace the linear layer with one to 10 channels\n",
    "\n",
    "if config.model.backbone == \"mobilenet_v2\":\n",
    "    model = mobilenet_v2(pretrained=True, progress=False)\n",
    "    model.classifier = nn.Sequential(\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Linear(model.last_channel, num_classes),\n",
    "            )\n",
    "\n",
    "elif config.model.backbone == \"resnet50\":\n",
    "    model = resnet50(pretrained=True, progress=False)\n",
    "    model.fc = nn.Sequential(\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Linear(model.fc.in_features, num_classes+1),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31627cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchsummary\n",
    "# import torchinfo\n",
    "import torch.optim as optim\n",
    "# import torchbearer\n",
    "# from torchbearer import Trial\n",
    "# from torchbearer.callbacks import PyCM\n",
    "\n",
    "# for k, m in model.named_modules():\n",
    "#     if (k.startswith(\"features\")) or (k.startswith(\"layer\")):\n",
    "#         print(f\"Freezing: {k}\")\n",
    "#         m.requires_grad = False\n",
    "#     else:\n",
    "#         print(f\"Unfreezing: {k}\")\n",
    "#         m.requires_grad = True\n",
    "        \n",
    "#     print(f\"{k} : {m.requires_grad}\")\n",
    "\n",
    "freeze_at = \"fc\"\n",
    "\n",
    "freeze_current=False\n",
    "for k, m in model.named_modules():\n",
    "    if (k == freeze_at) or freeze_current:\n",
    "        freeze_current=True\n",
    "        print(f\"Unfreezing: {k}\")\n",
    "        m.requires_grad = True\n",
    "    else:\n",
    "        print(f\"Freezing: {k}\")\n",
    "        m.requires_grad = False\n",
    "        \n",
    "    print(f\"{k} : {m.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd1bffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = PyCM().on_val().to_pyplot(normalize=True, title='Confusion Matrix: {epoch}')\n",
    "# cm_csv = PyCM().on_val().to_csv_file(\"cm_{epoch}\")\n",
    "# model = SimpleModel()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# trial = Trial(model, optimizer, loss, metrics=['acc', 'loss'], callbacks=[cm,cm_csv]).to(device)\n",
    "# trial.with_generators(train_generator=train_gen, val_generator=val_gen)\n",
    "# history = trial.run(epochs=2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91285848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e7943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SelfSupervisedLearner(\n",
    "    resnet,\n",
    "    image_size = IMAGE_SIZE,\n",
    "    hidden_layer = 'avgpool',\n",
    "    projection_size = 256,\n",
    "    projection_hidden_size = 4096,\n",
    "    moving_average_decay = 0.99\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus = NUM_GPUS,\n",
    "    max_epochs = EPOCHS,\n",
    "    accumulate_grad_batches = 1,\n",
    "    sync_batchnorm = True\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ca0ff67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchdata\n",
    "\n",
    "# class UnsupervisedDatasetWrapper(torchdata.datasets.Files):\n",
    "class UnsupervisedDatasetWrapper(torchvision.datasets.ImageFolder):\n",
    "    \n",
    "    def __init__(self, dataset):\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.dataset[index][0]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        out = \"<UnsupervisedDatasetWrapper>\\n\"\n",
    "        out += self.dataset.__repr__()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d104783",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_0['test'][0]\n",
    "\n",
    "for subset in [\"train\",\"val\",\"test\"]:\n",
    "    task_0[subset] = UnsupervisedDatasetWrapper(task_0[subset])\n",
    "    task_1[subset] = UnsupervisedDatasetWrapper(task_1[subset])\n",
    "\n",
    "task_0['test'][0]\n",
    "\n",
    "type(task_0['test'].dataset)\n",
    "\n",
    "task_0['test']#.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0719977",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62e99df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from typing import *\n",
    "\n",
    "\n",
    "totensor: Callable = torchvision.transforms.ToTensor()\n",
    "\n",
    "def toPIL(img: torch.Tensor, mode=\"RGB\") -> Callable:\n",
    "    return torchvision.transforms.ToPILImage(mode)\n",
    "\n",
    "\n",
    "def normalize_transform(mean = [0.485, 0.456, 0.406],\n",
    "                        std = [0.229, 0.224, 0.225]) -> Callable:\n",
    "    return transforms.Normalize(mean=mean,\n",
    "                                std=std)\n",
    "\n",
    "def default_train_transforms(image_size: int=224,\n",
    "                             normalize: bool=True, \n",
    "                             augment:bool=True,\n",
    "                             grayscale: bool=True,\n",
    "                             channels: Optional[int]=3,\n",
    "                             mean = [0.485, 0.456, 0.406],\n",
    "                             std = [0.229, 0.224, 0.225]):\n",
    "    \"\"\"Subclasses can override this or user can provide custom transforms at runtime\"\"\"\n",
    "    transform_list = []\n",
    "#         transform_jit_list = []\n",
    "    resize_PIL = not augment\n",
    "    if augment:\n",
    "        transform_list.extend([transforms.RandomResizedCrop(size=image_size,\n",
    "                                                            scale=(0.25, 1.2),\n",
    "                                                            ratio=(0.7, 1.3),\n",
    "                                                            interpolation=2),\n",
    "                               totensor\n",
    "                             ])\n",
    "    return default_eval_transforms(image_size=image_size,\n",
    "                                        normalize=normalize,\n",
    "                                        resize_PIL=resize_PIL,\n",
    "                                        grayscale=grayscale,\n",
    "                                        channels=channels,\n",
    "                                        transform_list=transform_list,\n",
    "                                        mean=mean,\n",
    "                                        std=std)\n",
    "\n",
    "def default_eval_transforms(image_size: int=224,\n",
    "                            image_buffer_size: int=32,\n",
    "                            normalize: bool=True,\n",
    "                            resize_PIL: bool=True,\n",
    "                            grayscale: bool=True,\n",
    "                            channels: Optional[int]=3,\n",
    "                            transform_list: Optional[List[Callable]]=None,\n",
    "                            mean = [0.485, 0.456, 0.406],\n",
    "                            std = [0.229, 0.224, 0.225]):\n",
    "    \"\"\"Subclasses can override this or user can provide custom transforms at runtime\"\"\"\n",
    "    transform_list = transform_list or []\n",
    "    transform_jit_list = []\n",
    "\n",
    "    if resize_PIL:\n",
    "        # if True, assumes input images are PIL.Images (But need to check if this even matters.)\n",
    "        # if False, expects input images to already be torch.Tensors\n",
    "        transform_list.extend([transforms.Resize(image_size+image_buffer_size),\n",
    "                               transforms.CenterCrop(image_size),\n",
    "                               totensor])\n",
    "    if normalize:\n",
    "        transform_jit_list.append(normalize_transform(mean, std))\n",
    "\n",
    "    if grayscale:\n",
    "        transform_jit_list.append(transforms.Grayscale(num_output_channels=channels))\n",
    "\n",
    "    return transforms.Compose([*transform_list, *transform_jit_list])\n",
    "\n",
    "\n",
    "def get_default_transforms(image_size: int=224,\n",
    "                           normalize: bool=True,\n",
    "                           augment:bool=True,\n",
    "                           grayscale: bool=True,\n",
    "                           channels: Optional[int]=3,\n",
    "                           mean = [0.485, 0.456, 0.406],\n",
    "                           std = [0.229, 0.224, 0.225]):\n",
    "\n",
    "    \n",
    "    train_transform = default_train_transforms(image_size=image_size,\n",
    "                                               normalize=normalize,\n",
    "                                               augment=augment,\n",
    "                                               grayscale=grayscale,\n",
    "                                               channels=channels,\n",
    "                                               mean=mean,\n",
    "                                               std=std)\n",
    "    eval_transform = default_eval_transforms(image_size=image_size,\n",
    "                                             image_buffer_size=32,\n",
    "                                             normalize=normalize,\n",
    "                                             resize_PIL=not augment,\n",
    "                                             grayscale=grayscale,\n",
    "                                             channels=channels,\n",
    "                                             transform_list=None,\n",
    "                                             mean=mean,\n",
    "                                             std=std)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return train_transform, eval_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d469fc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform, val_transform = get_default_transforms(image_size=224,\n",
    "                                                         normalize=True,\n",
    "                                                         augment=True,\n",
    "                                                         grayscale=True,\n",
    "                                                         channels=3,\n",
    "                                                         mean = [0.485, 0.456, 0.406],\n",
    "                                                         std = [0.229, 0.224, 0.225])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1c0686ae52b501c5138d1ad3c292b1aad199ba0a61e288abba1616901d57bf21"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('sequoia': conda)",
   "language": "python",
   "name": "python385jvsc74a57bd01c0686ae52b501c5138d1ad3c292b1aad199ba0a61e288abba1616901d57bf21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
