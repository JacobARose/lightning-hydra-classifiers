{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Kernel is based on this amazing [‚ö°Plant2021 PyTorch Lightning Starter [ Training ]‚ö°](https://www.kaggle.com/pegasos/plant2021-pytorch-lightning-starter-training) by [Sh1r0](https://www.kaggle.com/pegasos). This kernel is intended to showcase [Weights and Biases](https://wandb.ai/site) integration with PyTorch Lightning. \n",
    "\n",
    "# ‚ö° PyTorch Lightning\n",
    "\n",
    "PyTorch is an extremely powerful framework for your deep learning research. But once the research gets complicated and things like 16-bit precision, multi-GPU training, and TPU training get mixed in, users are likely to introduce bugs. **PyTorch Lightning lets you decouple research from engineering.**\n",
    "\n",
    "**PyTorch Lightning ‚ö° is not another framework but a style guide for PyTorch.**\n",
    "\n",
    "To learn more about PyTorch Lightning check out my blog posts at Weights and Biases [Fully Connected](https://wandb.ai/fully-connected):\n",
    "\n",
    "* [Image Classification using PyTorch Lightning](https://wandb.ai/wandb/wandb-lightning/reports/Image-Classification-using-PyTorch-Lightning--VmlldzoyODk1NzY)\n",
    "* [Transfer Learning Using PyTorch Lightning](https://wandb.ai/wandb/wandb-lightning/reports/Transfer-Learning-Using-PyTorch-Lightning--VmlldzoyODk2MjA)\n",
    "* [Multi-GPU Training Using PyTorch Lightning](https://wandb.ai/wandb/wandb-lightning/reports/Multi-GPU-Training-Using-PyTorch-Lightning--VmlldzozMTk3NTk)\n",
    "\n",
    "# <img src=\"https://i.imgur.com/gb6B4ig.png\" width=\"400\" alt=\"Weights & Biases\" />\n",
    "\n",
    "Weights & Biases helps you build better models faster with a central dashboard for your machine learning projects. It not only logs your training metrics but can log hyperparameters and output metrics, then visualize and compare results and quickly share findings with your team mates. Track everything you need to make your models reproducible with Weights & Biases‚Äî from hyperparameters and code to model weights and dataset versions. \n",
    "\n",
    "### [Check this Kaggle kernel to learn more about Weights and Biases$\\rightarrow$](https://www.kaggle.com/ayuraj/experiment-tracking-with-weights-and-biases)\n",
    "![img](https://i.imgur.com/BGgfZj3.png)\n",
    "\n",
    "# PyTorch Lightning + Weights and Biases \n",
    "\n",
    "PyTorch Lightning provides a lightweight wrapper for organizing your PyTorch code and easily adding advanced features such as distributed training and 16-bit precision. W&B provides a lightweight wrapper for logging your ML experiments. It is incorporated directly into the PyTorch Lightning library, so you can check out [their documentation](https://pytorch-lightning.readthedocs.io/en/stable/extensions/generated/pytorch_lightning.loggers.WandbLogger.html#pytorch_lightning.loggers.WandbLogger) for the API and reference info.\n",
    "\n",
    "### Use the intergration in few lines of code.\n",
    "\n",
    "```\n",
    "from pytorch_lightning.loggers import WandbLogger  # newline 1\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "wandb_logger = WandbLogger()  # newline 2\n",
    "trainer = Trainer(logger=wandb_logger)\n",
    "```\n",
    "\n",
    "[![thumbnail](https://i.imgur.com/M7xZ04g.png)](https://www.youtube.com/watch?v=hUXQm46TAKc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import timm\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn as nn\n",
    "import albumentations as A\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from albumentations.core.composition import Compose, OneOf\n",
    "from albumentations.augmentations.transforms import CLAHE, GaussNoise, ISONoise\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning import Callback\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìÄ Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Config dictionary that will be logged to W&B.\n",
    "CONFIG = dict (\n",
    "    seed = 42,\n",
    "    train_val_split = 0.2,\n",
    "    model_name = 'resnet50',\n",
    "    pretrained = True,\n",
    "    img_size = 256,\n",
    "    num_classes = 12,\n",
    "    lr = 5e-4,\n",
    "    min_lr = 1e-6,\n",
    "    t_max = 20,\n",
    "    num_epochs = 10,\n",
    "    batch_size = 32,\n",
    "    accum = 1,\n",
    "    precision = 16,\n",
    "    n_fold = 5,\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    ")\n",
    "\n",
    "# Directories\n",
    "PATH = \"../input/plant-pathology-2021-fgvc8/\"\n",
    "\n",
    "image_size = CONFIG['img_size']\n",
    "TRAIN_DIR = f'../input/resized-plant2021/img_sz_{image_size}/'\n",
    "TEST_DIR = PATH + 'test_images/'\n",
    "\n",
    "# Seed everything\n",
    "seed_everything(CONFIG['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîß DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>800113bb65efe69e.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8002cb321f8bfcdf.jpg</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80070f7fb5e2ccaa.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80077517781fb94f.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>800cbf0ff87721f8.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  image  labels\n",
       "0  800113bb65efe69e.jpg       1\n",
       "1  8002cb321f8bfcdf.jpg       7\n",
       "2  80070f7fb5e2ccaa.jpg       0\n",
       "3  80077517781fb94f.jpg       0\n",
       "4  800cbf0ff87721f8.jpg       4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read CSV file\n",
    "df = pd.read_csv(PATH + \"train.csv\")\n",
    "\n",
    "# Label encode \n",
    "labels = list(df['labels'].value_counts().keys())\n",
    "labels_dict = dict(zip(labels, range(12)))\n",
    "df = df.replace({\"labels\": labels_dict})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlantDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.image_id = df['image'].values\n",
    "        self.labels = df['labels'].values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_id[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        image_path = TRAIN_DIR + image_id\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        augmented = self.transform(image=image)\n",
    "        image = augmented['image']\n",
    "        return {'image':image, 'target': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlantDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size, data_dir: str = './'):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Train augmentation policy\n",
    "        self.train_transform = Compose([\n",
    "            A.RandomResizedCrop(height=CONFIG['img_size'], width=CONFIG['img_size']),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.ShiftScaleRotate(p=0.5),\n",
    "            A.RandomBrightnessContrast(p=0.5),\n",
    "            A.Normalize(),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "        # Validation/Test augmentation policy\n",
    "        self.test_transform = Compose([\n",
    "            A.Resize(height=CONFIG['img_size'], width=CONFIG['img_size']),\n",
    "            A.Normalize(),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "        \n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == 'fit' or stage is None:\n",
    "            # Random train-validation split\n",
    "            train_df, valid_df = train_test_split(df, test_size=CONFIG['train_val_split'])\n",
    "            \n",
    "            # Train dataset\n",
    "            self.train_dataset = PlantDataset(train_df, self.train_transform)\n",
    "            # Validation dataset\n",
    "            self.valid_dataset = PlantDataset(valid_df, self.test_transform)\n",
    "                        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.valid_dataset, batch_size=self.batch_size, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé∫ LightningModule - Define the System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomResNet(nn.Module):\n",
    "    def __init__(self, model_name='resnet18', pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        in_features = self.model.get_classifier().in_features\n",
    "        self.model.fc = nn.Linear(in_features, CONFIG['num_classes'])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitCassava(pl.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super(LitCassava, self).__init__()\n",
    "        self.model = model\n",
    "        self.metric = pl.metrics.F1(num_classes=CONFIG['num_classes'])\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.lr = CONFIG['lr']\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=CONFIG['t_max'], eta_min=CONFIG['min_lr'])\n",
    "\n",
    "        return {'optimizer': self.optimizer, 'lr_scheduler': self.scheduler}\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        image = batch['image']\n",
    "        target = batch['target']\n",
    "        output = self.model(image)\n",
    "        loss = self.criterion(output, target)\n",
    "        score = self.metric(output.argmax(1), target)\n",
    "        logs = {'train_loss': loss, 'train_f1': score, 'lr': self.optimizer.param_groups[0]['lr']}\n",
    "        self.log_dict(\n",
    "            logs,\n",
    "            on_step=False, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        image = batch['image']\n",
    "        target = batch['target']\n",
    "        output = self.model(image)\n",
    "        loss = self.criterion(output, target)\n",
    "        score = self.metric(output.argmax(1), target)\n",
    "        logs = {'valid_loss': loss, 'valid_f1': score}\n",
    "        self.log_dict(\n",
    "            logs,\n",
    "            on_step=False, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üì≤ Callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint\n",
    "checkpoint_callback = ModelCheckpoint(monitor='valid_loss',\n",
    "                                      save_top_k=1,\n",
    "                                      save_last=True,\n",
    "                                      save_weights_only=True,\n",
    "                                      filename='checkpoint/{epoch:02d}-{valid_loss:.4f}-{valid_f1:.4f}',\n",
    "                                      verbose=False,\n",
    "                                      mode='min')\n",
    "\n",
    "# Earlystopping\n",
    "earlystopping = EarlyStopping(monitor='valid_loss', patience=3, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Callback\n",
    "class ImagePredictionLogger(Callback):\n",
    "    def __init__(self, val_samples, num_samples=32):\n",
    "        super().__init__()\n",
    "        self.num_samples = num_samples\n",
    "        self.val_imgs, self.val_labels = val_samples['image'], val_samples['target']\n",
    "        \n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        # Bring the tensors to CPU\n",
    "        val_imgs = self.val_imgs.to(device=pl_module.device)\n",
    "        val_labels = self.val_labels.to(device=pl_module.device)\n",
    "        # Get model prediction\n",
    "        logits = pl_module(val_imgs)\n",
    "        preds = torch.argmax(logits, -1)\n",
    "        # Log the images as wandb Image\n",
    "        trainer.logger.experiment.log({\n",
    "            \"examples\":[wandb.Image(x, caption=f\"Pred:{pred}, Label:{y}\") \n",
    "                           for x, pred, y in zip(val_imgs[:self.num_samples], \n",
    "                                                 preds[:self.num_samples], \n",
    "                                                 val_labels[:self.num_samples])]\n",
    "            }, commit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üìå Tip: When logging manually through `wandb.log` or `trainer.logger.experiment.log`, make sure to use `commit=False` so the logging step does not increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö° Train and Evaluate the Model with W&B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 256, 256]), torch.Size([32]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init our data pipeline\n",
    "datamodule = PlantDataModule(batch_size=CONFIG['batch_size'])\n",
    "datamodule.setup()\n",
    "\n",
    "# Samples required by the custom ImagePredictionLogger callback to log image predictions.\n",
    "val_samples = next(iter(datamodule.val_dataloader()))\n",
    "val_imgs, val_labels = val_samples['image'], val_samples['target']\n",
    "val_imgs.shape, val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnet50_ram-a26f946b.pth\" to /root/.cache/torch/hub/checkpoints/resnet50_ram-a26f946b.pth\n"
     ]
    }
   ],
   "source": [
    "# Init our model\n",
    "model = CustomResNet(model_name=CONFIG['model_name'], pretrained=CONFIG['pretrained'])\n",
    "lit_model = LitCassava(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the documentation for WandbLogger [here](https://pytorch-lightning.readthedocs.io/en/stable/extensions/generated/pytorch_lightning.loggers.WandbLogger.html#pytorch_lightning.loggers.WandbLogger).\n",
    "\n",
    "> üìå Tip: dditional arguments like entity, group, tags, etc. used by `wandb.init()` can be passed as keyword arguments in this logger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "Using native 16bit precision.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mayush-thakur\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">cool-frog-7</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ayush-thakur/plant-pathology-lightning\" target=\"_blank\">https://wandb.ai/ayush-thakur/plant-pathology-lightning</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ayush-thakur/plant-pathology-lightning/runs/11c7pitj\" target=\"_blank\">https://wandb.ai/ayush-thakur/plant-pathology-lightning/runs/11c7pitj</a><br/>\n",
       "                Run data is saved locally in <code>/kaggle/working/wandb/run-20210430_182413-11c7pitj</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | model     | CustomResNet     | 23.5 M\n",
      "1 | metric    | F1               | 0     \n",
      "2 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "23.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.130    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8de61f3054548598b63f90a80b6f493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving latest checkpoint...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 132<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 31.51MB of 31.68MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=0.994544584‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/kaggle/working/wandb/run-20210430_182413-11c7pitj/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/kaggle/working/wandb/run-20210430_182413-11c7pitj/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>1353</td></tr><tr><td>_timestamp</td><td>1619808406</td></tr><tr><td>_step</td><td>4649</td></tr><tr><td>train_loss</td><td>0.64505</td></tr><tr><td>train_f1</td><td>0.79147</td></tr><tr><td>lr</td><td>0.00029</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>valid_loss</td><td>0.45967</td></tr><tr><td>valid_f1</td><td>0.86021</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà</td></tr><tr><td>_timestamp</td><td>‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà</td></tr><tr><td>_step</td><td>‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà</td></tr><tr><td>train_loss</td><td>‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ</td></tr><tr><td>train_f1</td><td>‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà</td></tr><tr><td>lr</td><td>‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ</td></tr><tr><td>epoch</td><td>‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà</td></tr><tr><td>valid_loss</td><td>‚ñà‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÅ</td></tr><tr><td>valid_f1</td><td>‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñà‚ñà</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 352 media file(s), 0 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">cool-frog-7</strong>: <a href=\"https://wandb.ai/ayush-thakur/plant-pathology-lightning/runs/11c7pitj\" target=\"_blank\">https://wandb.ai/ayush-thakur/plant-pathology-lightning/runs/11c7pitj</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Initialize wandb logger\n",
    "wandb_logger = WandbLogger(project='plant-pathology-lightning', \n",
    "                           config=CONFIG,\n",
    "                           group='ResNet', \n",
    "                           job_type='train')\n",
    "\n",
    "# Initialize a trainer\n",
    "trainer = Trainer(\n",
    "            max_epochs=CONFIG['num_epochs'],\n",
    "            gpus=1,\n",
    "            accumulate_grad_batches=CONFIG['accum'],\n",
    "            precision=CONFIG['precision'],\n",
    "            callbacks=[earlystopping,\n",
    "                       ImagePredictionLogger(val_samples)],\n",
    "            checkpoint_callback=checkpoint_callback,\n",
    "            logger=wandb_logger,\n",
    "            weights_summary='top',\n",
    ")\n",
    "\n",
    "# Train the model ‚ö°üöÖ‚ö°\n",
    "trainer.fit(lit_model, datamodule)\n",
    "\n",
    "# Close wandb run\n",
    "wandb.finish() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Metrics\n",
    "\n",
    "![img](https://i.imgur.com/n6P7K4M.gif)\n",
    "\n",
    "## Visualize Model Predictions\n",
    "\n",
    "![img](https://i.imgur.com/lgkLnrt.gif)\n",
    "\n",
    "## Visualize CPU and GPU Metrics\n",
    "\n",
    "![img](https://i.imgur.com/ZLjrbhj.gif)\n",
    "\n",
    "# ‚ùÑÔ∏è Resources\n",
    "\n",
    "I hope you find this kernel useful and will encouage you to try out Weights and Biases. Here are some relevant links that you might want to check out:\n",
    "\n",
    "* Check out the [official documentation](https://docs.wandb.ai/) to learn more about the best practices and advanced features. \n",
    "\n",
    "* Check out the [examples GitHub repository](https://github.com/wandb/examples) for curated and minimal examples. This can be a good starting point. \n",
    "\n",
    "* [Weights and Biases Fully Connected](https://wandb.ai/fully-connected) is a home for curated tutorials, free-form dicussions, paper summaries, industry expert advices and more. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
