{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Transfer Learning Experiments\n",
    "\n",
    "Created by: Jacob A Rose  \n",
    "Created On: Wednesday Oct 6th, 2021  \n",
    "\n",
    "Based on Notebook located at: https://jarvislabs.ai/blogs/transfer-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports & Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "from rich import print as pp\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import logging\n",
    "\n",
    "logger = logging.Logger(__name__)\n",
    "logger.setLevel('INFO')\n",
    "\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import timm\n",
    "import glob\n",
    "import hydra\n",
    "from collections import OrderedDict\n",
    "from typing import *\n",
    "\n",
    "from lightning_hydra_classifiers.models.transfer import *\n",
    "from rich import print as pp\n",
    "from lightning_hydra_classifiers.utils.model_utils import count_parameters, collect_results\n",
    "from lightning_hydra_classifiers.utils.metric_utils import get_per_class_metrics, get_scalar_metrics\n",
    "from lightning_hydra_classifiers.models.backbones.backbone import build_model\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "pl.seed_everything(42)\n",
    "\n",
    "from lightning_hydra_classifiers.scripts.multitask.train import MultiTaskDataModule, LitMultiTaskModule, ImagePredictionLogger, train_task,  CIFAR10DataModule, run_multitask_test, load_data_and_model, load_data, resolve_config, configure_callbacks, configure_loggers, configure_trainer\n",
    "from lightning_hydra_classifiers.data.datasets.common import toPIL\n",
    "from lightning_hydra_classifiers.utils.etl_utils import ETL\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "from lightning_hydra_classifiers.scripts.pretrain import lr_tuner\n",
    "\n",
    "from lightning_hydra_classifiers.scripts.multitask.train import configure_callbacks, configure_loggers#, configure_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing Early Stopping multi-stage subclass for finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "### trying out built in lightning tests for fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(Path(pl.__file__).parent)\n",
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%writefile first_test.py\n",
    "\n",
    "# # See the License for the specific language governing permissions and\n",
    "# # limitations under the License.\n",
    "# from collections import OrderedDict\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# import pytest\n",
    "# import torch\n",
    "# from torch import nn\n",
    "# from torch.optim import Optimizer, SGD\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# from pytorch_lightning import LightningModule, seed_everything, Trainer\n",
    "# from pytorch_lightning.callbacks import BackboneFinetuning, BaseFinetuning, ModelCheckpoint\n",
    "# from pytorch_lightning.callbacks.base import Callback\n",
    "# from tests.helpers import BoringModel, RandomDataset\n",
    "\n",
    "# from typing import *\n",
    "\n",
    "# # class RandomDataset(torch.utils.data.Dataset):\n",
    "# #     def __init__(self, num_samples=2000, shape=(3,64,64)):\n",
    "# #         self.num_samples = num_samples\n",
    "# #         self.shape = shape\n",
    "# #         self.data = torch.randn(num_samples, *shape)\n",
    "\n",
    "# #     def __getitem__(self, index):\n",
    "# #         return self.data[index]\n",
    "\n",
    "# #     def __len__(self):\n",
    "# #         return self.num_samples\n",
    "\n",
    "# # class RandomTupleSupervisedDataset(RandomDataset):\n",
    "    \n",
    "# #     def __init__(self, num_classes=1000, num_samples=2000, shape=(3,64,64)):\n",
    "# #         super().__init__(num_samples, shape)\n",
    "# #         self.num_classes = num_classes\n",
    "        \n",
    "# #         self.targets = torch.randperm(num_classes)[:num_samples]\n",
    "        \n",
    "# #     def __getitem__(self, index):\n",
    "# #         return self.data[index], self.targets[index]\n",
    "        \n",
    "\n",
    "# # dataset = RandomTupleSupervisedDataset(1000, 200, (3,128,128))\n",
    "# # dataset\n",
    "# # dataset.data.shape\n",
    "\n",
    "# # class TestBackboneFinetuningCallback(BackboneFinetuning):\n",
    "# #     def on_train_epoch_start(self, trainer, pl_module):\n",
    "# #         super().on_train_epoch_start(trainer, pl_module)\n",
    "# #         epoch = trainer.current_epoch\n",
    "# #         if self.unfreeze_backbone_at_epoch <= epoch:\n",
    "# #             optimizer = trainer.optimizers[0]\n",
    "# #             current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "# #             backbone_lr = self.previous_backbone_lr\n",
    "# #             if epoch < 6:\n",
    "# #                 assert backbone_lr <= current_lr\n",
    "# #             else:\n",
    "# #                 assert backbone_lr == current_lr\n",
    "\n",
    "# ###############################################################\n",
    "\n",
    "# # class BackboneFinetuningCallback(pl.callbacks.Callback):\n",
    "\n",
    "# #         def __init__(self,\n",
    "    \n",
    "\n",
    "# print(\"current dir:\", os.getcwd())\n",
    "\n",
    "# import os\n",
    "# os.path.abspath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile finetuning_callback_test.py\n",
    "\n",
    "# import numpy as np\n",
    "# import os\n",
    "# import pytest\n",
    "# from typing import *\n",
    "# import pytorch_lightning as pl\n",
    "# import torch\n",
    "# from lightning_hydra_classifiers.models.transfer import *\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# from torch import nn\n",
    "# # from pytorch_lightning import LightningModule, seed_everything, Trainer\n",
    "# import logging\n",
    "# import json\n",
    "# logging.basicConfig(level=logging.DEBUG)\n",
    "# logger = logging.Logger(__name__)\n",
    "# logger.setLevel('INFO')\n",
    "# pylog = logging.getLogger()\n",
    "\n",
    "\n",
    "# BN_TYPE = (torch.nn.modules.batchnorm._BatchNorm,)\n",
    "\n",
    "# def is_bn(layer: nn.Module) -> bool:\n",
    "#     \"\"\" Return True if layer's type is one of the batch norms.\"\"\"\n",
    "#     return isinstance(layer, BN_TYPE)\n",
    "\n",
    "# def grad_check(tensor: torch.Tensor) -> bool:\n",
    "#     \"\"\" Returns True if tensor.requires_grad==True, else False.\"\"\"\n",
    "#     return tensor.requires_grad == True\n",
    "\n",
    "\n",
    "# # os.chdir(\"/media/data/jacob/GitHub/lightning-hydra-classifiers\")#/tests\")\n",
    "\n",
    "# class RandomDataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self, num_samples=2000, shape=(3,64,64)):\n",
    "#         self.num_samples = num_samples\n",
    "#         self.shape = shape\n",
    "#         self.data = torch.randn(num_samples, *shape)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         return self.data[index]\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return self.num_samples\n",
    "\n",
    "# class RandomTupleSupervisedDataset(RandomDataset):\n",
    "    \n",
    "#     def __init__(self, num_classes=1000, num_samples=2000, shape=(3,64,64)):\n",
    "#         super().__init__(num_samples, shape)\n",
    "#         self.num_classes = num_classes\n",
    "        \n",
    "#         self.targets = torch.randperm(num_classes)[:num_samples]\n",
    "        \n",
    "#     def __getitem__(self, index):\n",
    "#         return self.data[index], self.targets[index]\n",
    "\n",
    "##############################################\n",
    "\n",
    "    \n",
    "    \n",
    "# class FinetuningLightningCallback(pl.callbacks.Callback):\n",
    "    \n",
    "# # class FinetuningLightningPlugin:\n",
    "#     mode_dict = {\"min\": torch.lt, \"max\": torch.gt}\n",
    "#     order_dict = {\"min\": \"<\", \"max\": \">\"}\n",
    "    \n",
    "    \n",
    "#     def __init__(self,\n",
    "#                  monitor: str=\"val_loss\",\n",
    "#                  mode: str=\"min\",\n",
    "#                  patience: int=4):\n",
    "        \n",
    "# #         if pl_module.hparams.finetuning_strategy == \"finetuning_unfreeze_layers_on_plateau\":\n",
    "#         self.monitor = monitor\n",
    "#         self.mode = mode\n",
    "#         self.patience = patience\n",
    "# #         self.best_metric = 0\n",
    "#         self.milestone_index = 0\n",
    "        \n",
    "# #         self.min_delta *= 1 if self.monitor_op == torch.gt else -1\n",
    "#         torch_inf = torch.tensor(np.Inf)\n",
    "#         self.best_score = torch_inf if self.monitor_op == torch.lt else -torch_inf\n",
    "    \n",
    "#         self.milestone_logs = []\n",
    "        \n",
    "#     def on_fit_start(self,\n",
    "#                      trainer,\n",
    "#                      pl_module):\n",
    "#         self.milestones = pl_module.finetuning_milestones\n",
    "#         print(f\"Setting milestones: {pl_module.finetuning_milestones}\")\n",
    "#         self._finished = False\n",
    "    \n",
    "    \n",
    "#     def finetuning_pretrained_strategy(self,\n",
    "#                                        trainer: \"pl.Trainer\",\n",
    "#                                        pl_module):\n",
    "#         \"\"\"\n",
    "        \n",
    "        \n",
    "#         \"\"\"\n",
    "#         epoch = trainer.current_epoch\n",
    "#         logs = trainer.callback_metrics\n",
    "#         current = logs.get(self.monitor)\n",
    "        \n",
    "#         if self.mode == \"min\":\n",
    "#             new_best = current < self.best_score\n",
    "#         elif self.mode == \"max\":\n",
    "#             new_best = current > self.best_score\n",
    "        \n",
    "#         if self._finished:\n",
    "#             return\n",
    "        \n",
    "#         if new_best:\n",
    "#             self.best_score = current\n",
    "#             self.wait_epochs = 0\n",
    "#             print(f\"New best score: {self.monitor}={self.best_score}.\")\n",
    "#         elif self.wait_epochs >= self.patience:\n",
    "            \n",
    "#             next_to_unfreeze = self.milestones[self.milestone_index]\n",
    "#             print(f\"Patience of {self.patience} surpassed at epoch: {epoch} unfreezing down to: {next_to_unfreeze}\")\n",
    "            \n",
    "#             pl_module.unfreeze_backbone_top_layers(unfreeze_down_to=next_to_unfreeze)\n",
    "#             self.wait_epochs = 0\n",
    "#             self.milestone_index += 1\n",
    "#             self.milestone_logs.append({\"epoch\":epoch,\n",
    "#                                         \"unfreeze_at_layer\":next_to_unfreeze,\n",
    "#                                         \"trainable_params\":pl_module.get_trainable_parameters(count_params=True),\n",
    "#                                         \"nontrainable_params\":pl_module.get_nontrainable_parameters(count_params=True)})\n",
    "#             if self.milestone_index >= len(self.milestones):\n",
    "#                 self._finished = True\n",
    "#         else:\n",
    "#             self.wait_epochs += 1\n",
    "    \n",
    "#     @property\n",
    "#     def monitor_op(self) -> Callable:\n",
    "#         return self.mode_dict[self.mode]\n",
    "    \n",
    "#     def on_epoch_end(self, trainer, pl_module):\n",
    "#         \"\"\"Called when the epoch ends.\"\"\"\n",
    "\n",
    "#         self.finetuning_pretrained_strategy(trainer=trainer, pl_module=pl_module)\n",
    "#         try:\n",
    "#             pl_module.log(\"nontrainable_params\", pl_module.get_nontrainable_parameters(count_params=True))\n",
    "#             pl_module.log(\"trainable_params\", pl_module.get_trainable_parameters(count_params=True))\n",
    "# #             pl_module.logger.summary[\"milestones\"] = self.milestone_logs[-1]\n",
    "#         except Exception as e:\n",
    "#             print(e)\n",
    "#             print(f\"logging to wandb didnt work bro\")\n",
    "\n",
    "\n",
    "\n",
    "########################\n",
    "########################\n",
    "\n",
    "\n",
    "from lightning_hydra_classifiers.callbacks.finetuning_callbacks import FinetuningLightningCallback\n",
    "\n",
    "class TestLightningClassifier(LightningClassifier):\n",
    "\n",
    "    def __init__(self,\n",
    "                 backbone_name='resnet50',\n",
    "                 pretrained: Union[bool, str]=True,\n",
    "                 num_classes: int=1000,\n",
    "                 finetuning_strategy: str=\"feature_extractor\",\n",
    "                 seed: int=None,\n",
    "                 **kwargs):\n",
    "\n",
    "        super().__init__(backbone_name=backbone_name,\n",
    "                         pretrained=pretrained,\n",
    "                         num_classes=num_classes,\n",
    "                         pool_type=\"avgdrop\",\n",
    "                         head_type=\"linear\",\n",
    "                         hidden_size=None, lr=0.01, backbone_lr_mult=0.1,\n",
    "                         weight_decay=0.01,\n",
    "                         finetuning_strategy=finetuning_strategy,\n",
    "                         seed=42,\n",
    "                        **kwargs)\n",
    "        self._verbose=True\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        self.log(\"train_loss\",1)\n",
    "        return {\"loss\": torch.ones(1, requires_grad=True)}\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self.log(\"val_loss\",1)\n",
    "        return {\"loss\": torch.ones(1, requires_grad=True)}\n",
    "    \n",
    "    \n",
    "#         output = super().training_step(batch, batch_idx)\n",
    "#         self._verbose=False\n",
    "#         return output\n",
    "\n",
    "    def training_step_end(self, outputs):\n",
    "        super().training_step_end(outputs)\n",
    "\n",
    "    def print(self, *args):\n",
    "        if self._verbose:\n",
    "            print(*args)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(RandomTupleSupervisedDataset(num_classes=1000, num_samples=50, shape=(3,64,64)), batch_size=2)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(RandomTupleSupervisedDataset(num_classes=1000, num_samples=50, shape=(3,64,64)), batch_size=2)\n",
    "\n",
    "\n",
    "def save_log(log, fp):\n",
    "    with open(fp, \"w\") as fp:\n",
    "        json.dump(log, fp, indent=4, sort_keys=False)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "###############################\n",
    "###############################\n",
    "\n",
    "\n",
    "# @pytest.mark.parametrize(\"finetuning_strategy\",\n",
    "#                         [(\"feature_extractor\",)\n",
    "#                          \"feature_extractor_+_bn.eval()\",\n",
    "#                          \"feature_extractor_+_except_bn\"])\n",
    "\n",
    "# @pytest.mark.parametrize(\"finetuning_strategy, expected_layer_counts\",\n",
    "#     [\n",
    "#         (\"feature_extractor\",\n",
    "#             {\"is_training\":{'True': 53, 'False': 0, 'Total': 53}, \n",
    "#              \"requires_grad\":{'True': 0, 'False': 53, 'Total': 53}}\n",
    "#         ),\n",
    "#         (\"feature_extractor_+_bn.eval()\",\n",
    "#             {\"is_training\":{'True': 0, 'False': 53, 'Total': 53}, \n",
    "#              \"requires_grad\":{'True': 0, 'False': 53, 'Total': 53}}\n",
    "#         ),\n",
    "#         (\"feature_extractor_+_except_bn\",\n",
    "#             {\"is_training\":{'True': 53, 'False': 0, 'Total': 53}, \n",
    "#              \"requires_grad\":{'True': 53, 'False': 0, 'Total': 53}}\n",
    "#         )\n",
    "#     ]\n",
    "#                         )\n",
    "# @pytest.mark.parametrize()\n",
    "def test_finetuning_callback(tmpdir):#, finetuning_strategy: str, expected_layer_counts: Dict[str,Dict[str,int]]):#, expectations: Dict[str,Any]):\n",
    "    \"\"\"Test finetuning strategy works as expected.\"\"\"\n",
    "\n",
    "    pl.seed_everything(42)\n",
    "    \n",
    "    callbacks = [FinetuningLightningCallback(monitor=\"val_loss\",\n",
    "                                             mode=\"min\",\n",
    "                                             patience=4)]\n",
    "\n",
    "    model = TestLightningClassifier(finetuning_strategy=\"finetuning_unfreeze_layers_on_plateau\")\n",
    "#     callback = TestBackboneFinetuningCallback(unfreeze_backbone_at_epoch=3, verbose=False)\n",
    "\n",
    "    trainer = pl.Trainer(limit_train_batches=2,\n",
    "                         limit_val_batches=2,\n",
    "                         default_root_dir=\"/home/jrose3\",\n",
    "                         log_every_n_steps=1,\n",
    "                         callbacks=callbacks,\n",
    "                         max_epochs=25)\n",
    "    trainer.fit(model)\n",
    "    \n",
    "    \n",
    "#     pylog.info(f\"strategy: {finetuning_strategy}\")\n",
    "    model._verbose = True\n",
    "    layer_counts = model.count_trainable_batchnorm_layers()\n",
    "\n",
    "\n",
    "\n",
    "    from rich import print as pp\n",
    "    print(\"milestone_logs:\")\n",
    "    pp(callbacks[0].milestone_logs)\n",
    "\n",
    "#     pylog.info(f\"strategy: {finetuning_strategy}\")\n",
    "#     pylog.info(f\"Expected layer counts: {expected_layer_counts}\")\n",
    "    pylog.info(f\"count trainable batchnorm layers`: {model.count_trainable_batchnorm_layers()}\")\n",
    "    pylog.info(f\"count trainable layers: {model.get_trainable_parameters(count_layers=True)}\")\n",
    "    pylog.info(f\"count nontrainable layers: {model.get_nontrainable_parameters(count_layers=True)}\")\n",
    "    pylog.info(f\"count trainable params: {model.get_trainable_parameters(count_params=True)}\")\n",
    "    pylog.info(f\"count nontrainable params: {model.get_nontrainable_parameters(count_params=True)}\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#     assert expected_layer_counts[\"is_training\"][\"True\"] == layer_counts[0][\"True\"]\n",
    "#     assert expected_layer_counts[\"is_training\"][\"False\"] == layer_counts[0][\"False\"]\n",
    "\n",
    "#     assert expected_layer_counts[\"requires_grad\"][\"True\"] == layer_counts[1][\"True\"]\n",
    "#     assert expected_layer_counts[\"requires_grad\"][\"False\"] == layer_counts[1][\"False\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TestLightningClassifier(finetuning_strategy=\"feature_extractor_+_except_bn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TestLightningClassifier(LightningClassifier):\n",
    "\n",
    "#     def __init__(self,\n",
    "#                  backbone_name='resnet50',\n",
    "#                  pretrained: Union[bool, str]=True,\n",
    "#                  num_classes: int=1000,\n",
    "#                  finetuning_strategy: str=\"feature_extractor\",\n",
    "#                  seed: int=None,\n",
    "#                  **kwargs):\n",
    "\n",
    "#         super().__init__(backbone_name=backbone_name,\n",
    "#                          pretrained=pretrained,\n",
    "#                          num_classes=num_classes,\n",
    "#                          pool_type=\"avgdrop\",\n",
    "#                          head_type=\"linear\",\n",
    "#                          hidden_size=None, lr=0.01, backbone_lr_mult=0.1,\n",
    "#                          weight_decay=0.01,\n",
    "#                          finetuning_strategy=finetuning_strategy,\n",
    "#                          seed=42,\n",
    "#                         **kwargs)\n",
    "#         self._verbose=True\n",
    "\n",
    "#     def training_step(self, batch, batch_idx):\n",
    "#         output = super().training_step(batch, batch_idx)\n",
    "# #             self.print(f\"During: self.training_step\")\n",
    "# #             self.count_trainable_batchnorm_layers()\n",
    "#         self._verbose=False\n",
    "#         return output\n",
    "\n",
    "#     def training_step_end(self, outputs):\n",
    "#         output = super().training_step_end(outputs)\n",
    "\n",
    "#     def print(self, *args):\n",
    "#         if self._verbose:\n",
    "#             print(*args)\n",
    "\n",
    "# #         def configure_optimizers(self):\n",
    "# #             optimizer = torch.optim.SGD(self.layer.parameters(), lr=0.1)\n",
    "# #             lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.7)\n",
    "# #             return [optimizer], [lr_scheduler]\n",
    "\n",
    "#     def train_dataloader(self):\n",
    "#         return DataLoader(RandomTupleSupervisedDataset(num_classes=1000, num_samples=50, shape=(3,64,64)), batch_size=2)\n",
    "\n",
    "#     def val_dataloader(self):\n",
    "#         return DataLoader(RandomTupleSupervisedDataset(num_classes=1000, num_samples=50, shape=(3,64,64)), batch_size=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # finetuning_strategy = \"feature_extractor\"\n",
    "# fixtures = [\"feature_extractor\",\n",
    "#             \"feature_extractor_+_bn.eval()\",\n",
    "#             \"feature_extractor_+_except_bn\"]\n",
    "\n",
    "# for finetuning_strategy in fixtures:\n",
    "#     print(f\"strategy: {finetuning_strategy}\")\n",
    "\n",
    "#     model = TestLightningClassifier(finetuning_strategy=finetuning_strategy)\n",
    "#     training_batch_stats, params_require_grads = model.count_trainable_batchnorm_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rich.console import Console\n",
    "# from rich.markdown import Markdown\n",
    "# console = Console()\n",
    "# markdown = Markdown(\"$$\\delta \\pi = 3.14159265358979323$$\")\n",
    "# console.print(markdown)\n",
    "# from IPython.display import display, Math, Latex\n",
    "# display(Math(r\"$$mean=E[x^k],\" + \"\\n\" +\"Var = Var[x^k]\"))\n",
    "# from IPython.display import display, Math, Latex\n",
    "# display(Math(r\"$$\\delta \\pi = 3.14159265358979323$$\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"count trainable layers: \", model.count_trainable_layers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# class ThresholdBasedFinetuning(pl.callbacks.EarlyStopping):\n",
    "    \n",
    "#     mode_dict = {\"min\": torch.lt, \"max\": torch.gt}\n",
    "\n",
    "#     order_dict = {\"min\": \"<\", \"max\": \">\"}\n",
    "    \n",
    "#     def __init__(self,\n",
    "#                  monitor: Optional[str] = None,\n",
    "#                  min_delta: float = 0.0,\n",
    "#                  patience: int = 3,\n",
    "#                  verbose: bool = False,\n",
    "#                  mode: str = \"min\",\n",
    "#                  strict: bool = True,\n",
    "#                  check_finite: bool = True,\n",
    "#                  stopping_threshold: Optional[float] = None,\n",
    "#                  divergence_threshold: Optional[float] = None,\n",
    "#                  check_on_train_epoch_end: Optional[bool] = None):\n",
    "#         super().__init__()\n",
    "        \n",
    "        \n",
    "        \n",
    "#     def on_save_checkpoint(\n",
    "#         self, trainer: \"pl.Trainer\", pl_module: \"pl.LightningModule\", checkpoint: Dict[str, Any]\n",
    "#     ) -> Dict[str, Any]:\n",
    "#         return {\n",
    "#             \"wait_count\": self.wait_count,\n",
    "#             \"stopped_epoch\": self.stopped_epoch,\n",
    "#             \"best_score\": self.best_score,\n",
    "#             \"patience\": self.patience,\n",
    "#         }\n",
    "\n",
    "#     def on_load_checkpoint(\n",
    "#         self, trainer: \"pl.Trainer\", pl_module: \"pl.LightningModule\", callback_state: Dict[str, Any]\n",
    "#     ) -> None:\n",
    "#         self.wait_count = callback_state[\"wait_count\"]\n",
    "#         self.stopped_epoch = callback_state[\"stopped_epoch\"]\n",
    "#         self.best_score = callback_state[\"best_score\"]\n",
    "#         self.patience = callback_state[\"patience\"]\n",
    "\n",
    "        \n",
    "#     def _should_skip_check(self, trainer: \"pl.Trainer\") -> bool:\n",
    "#         from pytorch_lightning.trainer.states import TrainerFn\n",
    "\n",
    "#         return trainer.state.fn != TrainerFn.FITTING or trainer.sanity_checking\n",
    "\n",
    "#     def on_validation_end(self, trainer: \"pl.Trainer\", pl_module: \"pl.LightningModule\") -> None:\n",
    "#         if self._should_skip_check(trainer):\n",
    "#             return\n",
    "#         self._run_early_stopping_check(trainer)\n",
    "\n",
    "        \n",
    "#     def _run_early_stopping_check(self, trainer: \"pl.Trainer\") -> None:\n",
    "#         \"\"\"Checks whether the early stopping condition is met and if so tells the trainer to stop the training.\"\"\"\n",
    "#         logs = trainer.callback_metrics\n",
    "\n",
    "#         if trainer.fast_dev_run or not self._validate_condition_metric(  # disable early_stopping with fast_dev_run\n",
    "#             logs\n",
    "#         ):  # short circuit if metric not present\n",
    "#             return\n",
    "\n",
    "#         current = logs.get(self.monitor)\n",
    "#         should_stop, reason = self._evaluate_stopping_criteria(current)\n",
    "\n",
    "#         # stop every ddp process if any world process decides to stop\n",
    "#         should_stop = trainer.training_type_plugin.reduce_boolean_decision(should_stop)\n",
    "#         trainer.should_stop = trainer.should_stop or should_stop\n",
    "#         if should_stop:\n",
    "#             self.stopped_epoch = trainer.current_epoch\n",
    "#         if reason and self.verbose:\n",
    "#             self._log_info(trainer, reason)\n",
    "\n",
    "#     def _evaluate_stopping_criteria(self, current: torch.Tensor) -> Tuple[bool, Optional[str]]:\n",
    "#         should_stop = False\n",
    "#         reason = None\n",
    "#         if self.check_finite and not torch.isfinite(current):\n",
    "#             should_stop = True\n",
    "#             reason = (\n",
    "#                 f\"Monitored metric {self.monitor} = {current} is not finite.\"\n",
    "#                 f\" Previous best value was {self.best_score:.3f}. Signaling Trainer to stop.\"\n",
    "#             )\n",
    "#         elif self.stopping_threshold is not None and self.monitor_op(current, self.stopping_threshold):\n",
    "#             should_stop = True\n",
    "#             reason = (\n",
    "#                 \"Stopping threshold reached:\"\n",
    "#                 f\" {self.monitor} = {current} {self.order_dict[self.mode]} {self.stopping_threshold}.\"\n",
    "#                 \" Signaling Trainer to stop.\"\n",
    "#             )\n",
    "#         elif self.divergence_threshold is not None and self.monitor_op(-current, -self.divergence_threshold):\n",
    "#             should_stop = True\n",
    "#             reason = (\n",
    "#                 \"Divergence threshold reached:\"\n",
    "#                 f\" {self.monitor} = {current} {self.order_dict[self.mode]} {self.divergence_threshold}.\"\n",
    "#                 \" Signaling Trainer to stop.\"\n",
    "#             )\n",
    "#         elif self.monitor_op(current - self.min_delta, self.best_score.to(current.device)):\n",
    "#             should_stop = False\n",
    "#             reason = self._improvement_message(current)\n",
    "#             self.best_score = current\n",
    "#             self.wait_count = 0\n",
    "#         else:\n",
    "#             self.wait_count += 1\n",
    "#             if self.wait_count >= self.patience:\n",
    "#                 should_stop = True\n",
    "#                 reason = (\n",
    "#                     f\"Monitored metric {self.monitor} did not improve in the last {self.wait_count} records.\"\n",
    "#                     f\" Best score: {self.best_score:.3f}. Signaling Trainer to stop.\"\n",
    "#                 )\n",
    "\n",
    "#         return should_stop, reason"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "### Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "class TestLightningClassifier(LightningClassifier):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 backbone_name='resnet50',\n",
    "                 pretrained: Union[bool, str]=True,\n",
    "                 num_classes: int=1000,\n",
    "                 pool_size: int=1,\n",
    "                 pool_type: str='avg',\n",
    "                 head_type: str='linear',\n",
    "                 hidden_size: Optional[int]=512,\n",
    "                 lr: float=2e-03,\n",
    "                 backbone_lr_mult: bool=0.1,\n",
    "                 weight_decay: float=0.01,\n",
    "                 finetuning_strategy: str=\"finetuning_unfreeze_layers_on_plateau\", #\"feature_extractor\",\n",
    "                 seed: int=None,\n",
    "                 **kwargs):\n",
    "        \n",
    "        super().__init__(backbone_name=backbone_name,\n",
    "                         pretrained=pretrained,\n",
    "                         num_classes=num_classes,\n",
    "                         pool_size=pool_size,\n",
    "                         pool_type=pool_type,\n",
    "                         head_type=head_type,\n",
    "                         hidden_size=hidden_size,\n",
    "                         lr=lr,\n",
    "                         backbone_lr_mult=backbone_lr_mult,\n",
    "                         weight_decay=weight_decay,\n",
    "                         finetuning_strategy=finetuning_strategy,\n",
    "                         seed=seed,\n",
    "                        **kwargs)\n",
    "        self._verbose=True\n",
    "    \n",
    "    def print(self, *args):\n",
    "        if self._verbose:\n",
    "            print(*args)\n",
    "    \n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "#         self.print(f\"Before: self.training_step\")\n",
    "#         self.count_trainable_batchnorm_layers()\n",
    "        output = super().training_step(batch, batch_idx)\n",
    "        self.print(f\"During: self.training_step\")\n",
    "        self.count_trainable_batchnorm_layers()\n",
    "#         if self.eval_bn:\n",
    "#             if not self.freeze_bn:\n",
    "#                 self.unfreeze(self.model,\n",
    "#                               filter_pattern=\"bn\")\n",
    "\n",
    "#         self.print(f\"After: self.training_step\")\n",
    "#         self.count_trainable_batchnorm_layers()\n",
    "        self._verbose=False\n",
    "        return output\n",
    "    \n",
    "    def training_step_end(self, outputs): #batch, batch_idx):\n",
    "#         self.print(f\"Before: self.training_step_end\")\n",
    "#         self.count_trainable_batchnorm_layers()\n",
    "        output = super().training_step_end(outputs) #batch, batch_idx)\n",
    "#         self.print(f\"After: self.training_step_end\")\n",
    "#         self.count_trainable_batchnorm_layers()\n",
    "        \n",
    "#         return output\n",
    "    \n",
    "#     def training_epoch_end(self, outputs):\n",
    "#         self.print(f\"Before: self.training_epoch_end\")\n",
    "        self.count_trainable_batchnorm_layers()\n",
    "#         super().training_epoch_end(outputs)\n",
    "#         self.print(f\"After: self.training_epoch_end\")\n",
    "#         self.count_trainable_batchnorm_layers()\n",
    "#         self._verbose=False\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial5/Inception_ResNet_DenseNet.html\n",
    "from lightning_hydra_classifiers.callbacks.finetuning_callbacks import FinetuningLightningCallback\n",
    "\n",
    "\n",
    "def test_model_freeze_strategy(config, datamodule, **kwargs):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        model_name - Name of the model you want to run. Is used to look up the class in \"model_dict\"\n",
    "        save_name (optional) - If specified, this name will be used for creating the checkpoint and logging directory.\n",
    "    \"\"\"\n",
    "    \n",
    "    config.model.finetuning_strategy = \"finetuning_unfreeze_layers_on_plateau\"\n",
    "    \n",
    "    group=f'{config.model.backbone.backbone_name}_{config.data.experiment.experiment_name}'#_task_{task_id}'\n",
    "    config.logger.wandb.group = group\n",
    "    config.callbacks.log_per_class_metrics_to_wandb.class_names = datamodule.classes\n",
    "\n",
    "    callbacks = configure_callbacks(config)\n",
    "    \n",
    "    callbacks.append(FinetuningLightningCallback(monitor=\"val_loss\",\n",
    "                                                 mode=\"min\",\n",
    "                                                 patience=5))\n",
    "    logger = configure_loggers(config)\n",
    "    \n",
    "\n",
    "    # Create a PyTorch Lightning trainer with the generation callback\n",
    "    trainer = pl.Trainer(default_root_dir=config.checkpoint_dir, #config.experiment_dir,\n",
    "                         gpus=1,\n",
    "                         max_epochs=config.trainer.max_epochs,\n",
    "                         callbacks=callbacks,\n",
    "#                                     ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\"),\n",
    "#                                     LearningRateMonitor(\"epoch\")],\n",
    "                         logger=logger,\n",
    "                         resume_from_checkpoint=config.trainer.resume_from_checkpoint,\n",
    "                         progress_bar_refresh_rate=1)\n",
    "    trainer.logger._log_graph = True         # If True, we plot the computation graph in tensorboard\n",
    "    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    pretrained_filename = config.trainer.resume_from_checkpoint #config.checkpoint_dir\n",
    "    if os.path.isfile(str(pretrained_filename)):\n",
    "        print(f\"Found pretrained model at {pretrained_filename}, loading...\")\n",
    "        model = TestLightningClassifier.load_from_checkpoint(pretrained_filename) # Automatically loads the model with the saved hyperparameters\n",
    "    else:\n",
    "        pl.seed_everything(config.model.seed)\n",
    "        model = TestLightningClassifier(**config.model, **kwargs)\n",
    "        model.label_encoder = datamodule.label_encoder\n",
    "        \n",
    "\n",
    "\n",
    "        if config.trainer.auto_lr_find:\n",
    "\n",
    "            lr_tune_output = lr_tuner.run_lr_tuner(trainer=trainer,\n",
    "                                                   model=model,\n",
    "                                                   datamodule=datamodule,\n",
    "                                                   config=config,\n",
    "                                                   results_dir=config.lr_tuner_dir,\n",
    "                                                   group=\"bn_eval_trials\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        trainer.fit(model, datamodule=datamodule)\n",
    "        model = TestLightningClassifier.load_from_checkpoint(trainer.checkpoint_callback.best_model_path) # Load best checkpoint after training\n",
    "        print(f\"Best checkpoint saved to: {trainer.checkpoint_callback.best_model_path}\")\n",
    "\n",
    "    # Test best model on validation and test set\n",
    "    val_result = trainer.test(model, test_dataloaders=datamodule.val_dataloader(), verbose=False)\n",
    "    test_result = trainer.test(model, test_dataloaders=datamodule.test_dataloader(), verbose=False)\n",
    "    \n",
    "    try:\n",
    "        result = {\"test_acc\": test_result[0][\"test_acc\"], \"val_acc\": val_result[0][\"test_acc\"]}\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        result = {\"test_acc\": test_result, \"val_acc\": val_result}\n",
    "        \n",
    "    result[\"ckpt_path\"] = trainer.checkpoint_callback.best_model_path\n",
    "\n",
    "    return model, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lightning_hydra_classifiers.scripts.multitask.train import MultiTaskDataModule, LitMultiTaskModule, ImagePredictionLogger, train_task,  CIFAR10DataModule, run_multitask_test, load_data_and_model, load_data, resolve_config, configure_callbacks, configure_loggers, configure_trainer\n",
    "\n",
    "# from lightning_hydra_classifiers.data.datasets.common import toPIL\n",
    "# from lightning_hydra_classifiers.utils.etl_utils import ETL\n",
    "# from omegaconf import OmegaConf\n",
    "\n",
    "\n",
    "def get_config_and_load_data(overrides = None,\n",
    "                             task_id: int = 1,\n",
    "                             pool_type='avgdrop',\n",
    "                             finetuning_strategy=\"feature_extractor_+_bn.eval()\",\n",
    "                             lr=2e-03,\n",
    "                             dropout_p: float=0.3,\n",
    "                             max_epochs: int=5):\n",
    "    overrides = overrides or []    \n",
    "    config = ETL.load_hydra_config(config_name = \"config\",\n",
    "                                   config_path = \"/media/data/jacob/GitHub/lightning-hydra-classifiers/configs\",\n",
    "                                   overrides=overrides)\n",
    "    OmegaConf.set_struct(config, False)\n",
    "    \n",
    "\n",
    "    datamodule = load_data(config,\n",
    "                           task_id=task_id)\n",
    "\n",
    "    model_config = OmegaConf.create(dict(\n",
    "                                    backbone={\"backbone_name\":config.model.backbone.backbone_name},\n",
    "                                    backbone_name=config.model.backbone.backbone_name,\n",
    "                                    pretrained=True,\n",
    "                                    num_classes=datamodule.num_classes,\n",
    "                                    pool_type=pool_type,\n",
    "                                    head_type='linear',\n",
    "                                    hidden_size=None,\n",
    "                                    dropout_p=dropout_p,\n",
    "                                    lr=2e-03,\n",
    "                                    backbone_lr_mult=0.1,\n",
    "                                    finetuning_strategy=finetuning_strategy,\n",
    "                                    weight_decay=0.01,\n",
    "                                    seed=98))\n",
    "    config.model = model_config\n",
    "#     config.trainer.max_epochs = max_epochs\n",
    "#     config.trainer.auto_lr_find = False\n",
    "    config.experiment_name = f\"{config.model.finetuning_strategy}-PNAS-{datamodule.num_classes}_classes-res_{config.data.image_size}-bsz_{config.data.batch_size}-{config.model.backbone_name}-pretrained_{config.model.pretrained}-pool_{config.model.pool_type}\"\n",
    "    \n",
    "    config.root_dir = os.path.join(os.getcwd(), \"bn_unit_test_logs\", config.model.pool_type)\n",
    "    config.lr_tuner_dir = os.path.join(config.results_dir, f\"task_{task_id}\", \"lr_tuner\")\n",
    "    \n",
    "    config = OmegaConf.create(OmegaConf.to_container(config, resolve=True))\n",
    "    \n",
    "    os.makedirs(config.results_dir, exist_ok=True)\n",
    "    os.makedirs(config.checkpoint_dir, exist_ok=True)\n",
    "    os.makedirs(config.lr_tuner_dir, exist_ok=True)\n",
    "    return config, datamodule\n",
    "\n",
    "\n",
    "# model = LightningClassifier(**config.model)\n",
    "# model = TestLightningClassifier(**config.model)\n",
    "# model.label_encoder = datamodule.label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': '/media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/train/Melastomataceae/Melastomataceae_Miconia_aspergillaris_Klucking_04-057-05.jpg',\n",
       " 'catalog_number': 'Klucking_04-057-05'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 4170<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 19.12MB of 19.12MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/wandb/run-20211025_063051-3vpcag4j/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/wandb/run-20211025_063051-3vpcag4j/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_acc_step</td><td>0.57576</td></tr><tr><td>train_loss_step</td><td>1.73308</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>trainer/global_step</td><td>126</td></tr><tr><td>_runtime</td><td>199</td></tr><tr><td>_timestamp</td><td>1635158050</td></tr><tr><td>_step</td><td>38</td></tr><tr><td>val_acc_step</td><td>0.5</td></tr><tr><td>val_loss_step</td><td>0.81554</td></tr><tr><td>val_acc_epoch</td><td>0.47486</td></tr><tr><td>val_loss_epoch</td><td>1.10236</td></tr><tr><td>train_acc_epoch</td><td>0.29908</td></tr><tr><td>train_loss_epoch</td><td>1.86445</td></tr><tr><td>nontrainable_params</td><td>23454912.0</td></tr><tr><td>trainable_params</td><td>92051.0</td></tr><tr><td>test_acc</td><td>0.24481</td></tr><tr><td>test_loss</td><td>2.70842</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_acc_step</td><td>▁█</td></tr><tr><td>train_loss_step</td><td>▁█</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▄▇▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃████</td></tr><tr><td>_runtime</td><td>▁▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▄▄▄▆▆▇█</td></tr><tr><td>_timestamp</td><td>▁▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▄▄▄▆▆▇█</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc_step</td><td>▇▅▆▃▃▃▁▁▃▄▆▄▆▃▃▄█▅▂▅▅▃▄▅▂▄▂▂▄▃▂▃</td></tr><tr><td>val_loss_step</td><td>▁▅▄▃▅▄▆▅▄▃▂▃▂▆▄▃▁▃▄▂▆▃▄▅▆▄▄▇▅█▆▃</td></tr><tr><td>val_acc_epoch</td><td>▁</td></tr><tr><td>val_loss_epoch</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁</td></tr><tr><td>train_loss_epoch</td><td>▁</td></tr><tr><td>nontrainable_params</td><td>▁</td></tr><tr><td>trainable_params</td><td>▁</td></tr><tr><td>test_acc</td><td>█▁</td></tr><tr><td>test_loss</td><td>▁█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 71 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">golden-sun-4</strong>: <a href=\"https://wandb.ai/jrose/finetuning_on_plateau/runs/3vpcag4j\" target=\"_blank\">https://wandb.ai/jrose/finetuning_on_plateau/runs/3vpcag4j</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# config, datamodule = get_config_and_load_data(overrides = None, task_id = 1, finetuning_strategy=\"finetuning_unfreeze_layers_on_plateau\")\n",
    "\n",
    "datamodule.train_dataset[3].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGINNING STRATEGY: finetuning_unfreeze_layers_on_plateau\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/hydra/experimental/initialize.py:98: UserWarning: hydra.experimental.initialize_config_dir() is no longer experimental. Use hydra.initialize_config_dir().\n",
      "  deprecation_warning(\n",
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/hydra/experimental/compose.py:18: UserWarning: hydra.experimental.compose() is no longer experimental. Use hydra.compose()\n",
      "  deprecation_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_0[train].eager_encode_targets = False\n",
      "task_0[val].eager_encode_targets = False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-25 06:30:03,961 lightning_hydra_classifiers.experiments.multitask.datamodules INFO     set_task(task_id=1)\n",
      "2021-10-25 06:30:03,964 lightning_hydra_classifiers.experiments.multitask.datamodules INFO     Task_1 (None): datamodule.setup(stage=fit)\n",
      "2021-10-25 06:30:03,965 lightning_hydra_classifiers.experiments.multitask.datamodules INFO     Task_1: datamodule.setup(stage=test)\n",
      "2021-10-25 06:30:04,105 lightning_hydra_classifiers.scripts.multitask.train INFO     Instantiating callback <pytorch_lightning.callbacks.early_stopping.EarlyStopping>\n",
      "2021-10-25 06:30:04,108 lightning_hydra_classifiers.scripts.multitask.train INFO     Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>\n",
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:446: UserWarning: Checkpoint directory /media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/finetuning_unfreeze_layers_on_plateau-PNAS-19_classes-res_512-bsz_16-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/ exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "2021-10-25 06:30:04,112 lightning_hydra_classifiers.scripts.multitask.train INFO     Instantiating callback <lightning_hydra_classifiers.callbacks.wandb_callbacks.LogPerClassMetricsToWandb>\n",
      "2021-10-25 06:30:04,118 lightning_hydra_classifiers.scripts.multitask.train INFO     Instantiating callback <lightning_hydra_classifiers.utils.callback_utils.ImagePredictionLogger>\n",
      "2021-10-25 06:30:04,120 lightning_hydra_classifiers.scripts.multitask.train INFO     Instantiating callback <lightning_hydra_classifiers.callbacks.wandb_callbacks.WatchModelWithWandb>\n",
      "2021-10-25 06:30:04,122 lightning_hydra_classifiers.scripts.multitask.train INFO     Instantiating callback <pl_bolts.callbacks.ModuleDataMonitor>\n",
      "2021-10-25 06:30:04,123 lightning_hydra_classifiers.scripts.multitask.train INFO     Instantiating logger <pytorch_lightning.loggers.wandb.WandbLogger>\n",
      "2021-10-25 06:30:04,125 lightning_hydra_classifiers.scripts.multitask.train INFO     Instantiating logger <pytorch_lightning.loggers.csv_logs.CSVLogger>\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "Global seed set to 98\n",
      "Global seed set to 98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_0[test].eager_encode_targets = False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-25 06:30:05,375 lightning_hydra_classifiers.scripts.pretrain.lr_tuner INFO     Proceeding with overrides merged with default parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set current model training strategy to: finetuning_unfreeze_layers_on_plateau\n",
      "self.num_classes=19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.26<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">fancy-feather-35</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/jrose/default\" target=\"_blank\">https://wandb.ai/jrose/default</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/jrose/default/runs/319fjmq5\" target=\"_blank\">https://wandb.ai/jrose/default/runs/319fjmq5</a><br/>\n",
       "                Run data is saved locally in <code>/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/wandb/run-20211025_063005-319fjmq5</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-25 06:30:07,036 lightning_hydra_classifiers.scripts.pretrain.lr_tuner INFO     [Initiating Stage] lr_tuner\n",
      "2021-10-25 06:30:07,465 lightning_hydra_classifiers.experiments.multitask.datamodules INFO     Task_1 (None): datamodule.setup(stage=fit)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name                    | Type             | Params\n",
      "-------------------------------------------------------------\n",
      "0 | model                   | Sequential       | 23.5 M\n",
      "1 | criterion               | CrossEntropyLoss | 0     \n",
      "2 | metrics_train           | MetricCollection | 0     \n",
      "3 | metrics_train_per_class | MetricCollection | 0     \n",
      "4 | metrics_val             | MetricCollection | 0     \n",
      "5 | metrics_val_per_class   | MetricCollection | 0     \n",
      "6 | metrics_test            | MetricCollection | 0     \n",
      "7 | metrics_test_per_class  | MetricCollection | 0     \n",
      "-------------------------------------------------------------\n",
      "92.1 K    Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.188    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.hparams=\"backbone\":            {'backbone_name': 'resnet50'}\n",
      "\"backbone_lr_mult\":    0.1\n",
      "\"backbone_name\":       resnet50\n",
      "\"dropout_p\":           0.3\n",
      "\"finetuning_strategy\": finetuning_unfreeze_layers_on_plateau\n",
      "\"head_type\":           linear\n",
      "\"hidden_size\":         None\n",
      "\"lr\":                  0.002\n",
      "\"num_classes\":         19\n",
      "\"pool_size\":           1\n",
      "\"pool_type\":           avg\n",
      "\"pretrained\":          True\n",
      "\"seed\":                98\n",
      "\"weight_decay\":        0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set current model training strategy to: finetuning_unfreeze_layers_on_plateau\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfbdf0b9ac6444208a87da28b686c0c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During: self.training_step\n",
      "layer.training-> Use batch statistics\n",
      "layer.training-> Use running statistics\n",
      "is_training (layer.training==True):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'True'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">53</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'False'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Total'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">53</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'True'\u001b[0m: \u001b[1;36m53\u001b[0m, \u001b[32m'False'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'Total'\u001b[0m: \u001b[1;36m53\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requires_grad (layer.requires_grad==True):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'True'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">53</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'False'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Total'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">53</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'True'\u001b[0m: \u001b[1;36m53\u001b[0m, \u001b[32m'False'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'Total'\u001b[0m: \u001b[1;36m53\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint file at /media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/finetuning_unfreeze_layers_on_plateau-PNAS-19_classes-res_512-bsz_16-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/lr_find_temp_model.ckpt\n",
      "Restored all states from the checkpoint file at /media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/finetuning_unfreeze_layers_on_plateau-PNAS-19_classes-res_512-bsz_16-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/lr_find_temp_model.ckpt\n",
      "2021-10-25 06:30:47,204 lightning_hydra_classifiers.scripts.pretrain.lr_tuner INFO     Saved best lr value (along w/ batch_size, image_size) to file located at: /media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/finetuning_unfreeze_layers_on_plateau-PNAS-19_classes-res_512-bsz_16-resnet50-pretrained_True-pool_avg/replicate_1/results/task_1/lr_tuner/hparams.yaml\n",
      "2021-10-25 06:30:47,207 lightning_hydra_classifiers.scripts.pretrain.lr_tuner INFO     File contents expected to contain: \n",
      "{'optimized_hparam_key': 'lr', 'lr': 0.025118864315095822, 'batch_size': 16, 'image_size': 512, 'lr_tuner_config': {'min_lr': 1e-08, 'max_lr': 1, 'num_training': 100, 'mode': 'exponential', 'early_stop_threshold': 4.0}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 3654<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.89MB of 0.89MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/wandb/run-20211025_063005-319fjmq5/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/wandb/run-20211025_063005-319fjmq5/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>42</td></tr><tr><td>_timestamp</td><td>1635157847</td></tr><tr><td>_step</td><td>6</td></tr><tr><td>lr_finder/best/loss</td><td>2.69714</td></tr><tr><td>lr_finder/best/lr</td><td>0.02512</td></tr><tr><td>lr_finder/batch_size</td><td>16</td></tr><tr><td>image_size</td><td>512</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>_step</td><td>▁▂▃▅▆▇█</td></tr><tr><td>lr_finder/best/loss</td><td>▁</td></tr><tr><td>lr_finder/best/lr</td><td>▁</td></tr><tr><td>lr_finder/batch_size</td><td>▁</td></tr><tr><td>image_size</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 2 media file(s), 1 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">fancy-feather-35</strong>: <a href=\"https://wandb.ai/jrose/default/runs/319fjmq5\" target=\"_blank\">https://wandb.ai/jrose/default/runs/319fjmq5</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-25 06:30:51,590 lightning_hydra_classifiers.scripts.pretrain.lr_tuner INFO     FINISHED: `run_lr_tuner(config)`\n",
      "2021-10-25 06:30:51,591 lightning_hydra_classifiers.scripts.pretrain.lr_tuner INFO     Proceeding with:\n",
      "\n",
      "2021-10-25 06:30:51,592 lightning_hydra_classifiers.scripts.pretrain.lr_tuner INFO     Learning rate = 2.512e-02\n",
      "2021-10-25 06:30:51,593 lightning_hydra_classifiers.scripts.pretrain.lr_tuner INFO     Batch size = 16\n",
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.\n",
      "  rank_zero_deprecation(\n",
      "2021-10-25 06:30:51,598 lightning_hydra_classifiers.experiments.multitask.datamodules INFO     Task_1 (None): datamodule.setup(stage=fit)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.hparams=\"backbone\":            {'backbone_name': 'resnet50'}\n",
      "\"backbone_lr_mult\":    0.1\n",
      "\"backbone_name\":       resnet50\n",
      "\"dropout_p\":           0.3\n",
      "\"finetuning_strategy\": finetuning_unfreeze_layers_on_plateau\n",
      "\"head_type\":           linear\n",
      "\"hidden_size\":         None\n",
      "\"lr\":                  0.025118864315095822\n",
      "\"num_classes\":         19\n",
      "\"pool_size\":           1\n",
      "\"pool_type\":           avg\n",
      "\"pretrained\":          True\n",
      "\"seed\":                98\n",
      "\"weight_decay\":        0.01\n",
      "Setting milestones: ['layer4', 'layer3', 'layer2', 'layer1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.26<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">golden-sun-4</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/jrose/finetuning_on_plateau\" target=\"_blank\">https://wandb.ai/jrose/finetuning_on_plateau</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/jrose/finetuning_on_plateau/runs/3vpcag4j\" target=\"_blank\">https://wandb.ai/jrose/finetuning_on_plateau/runs/3vpcag4j</a><br/>\n",
       "                Run data is saved locally in <code>/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/wandb/run-20211025_063051-3vpcag4j</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name                    | Type             | Params\n",
      "-------------------------------------------------------------\n",
      "0 | model                   | Sequential       | 23.5 M\n",
      "1 | criterion               | CrossEntropyLoss | 0     \n",
      "2 | metrics_train           | MetricCollection | 0     \n",
      "3 | metrics_train_per_class | MetricCollection | 0     \n",
      "4 | metrics_val             | MetricCollection | 0     \n",
      "5 | metrics_val_per_class   | MetricCollection | 0     \n",
      "6 | metrics_test            | MetricCollection | 0     \n",
      "7 | metrics_test_per_class  | MetricCollection | 0     \n",
      "-------------------------------------------------------------\n",
      "92.1 K    Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.188    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set current model training strategy to: finetuning_unfreeze_layers_on_plateau\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/pl_bolts/callbacks/data_monitor.py:104: UserWarning: ModuleDataMonitor does not support logging with LoggerCollection. Supported loggers are: TensorBoardLogger, WandbLogger\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11c7eb68cc37476f990d2548e4a64773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 99it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/confusion_matrix/golden-sun-4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc improved. New best score: 0.475\n",
      "Epoch 0, global step 125: val_acc reached 0.47486 (best 0.47486), saving model to \"/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/finetuning_unfreeze_layers_on_plateau-PNAS-19_classes-res_512-bsz_16-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/epoch=00-val_loss=1.102-val_acc=0.475.ckpt\" as top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set current model training strategy to: finetuning_unfreeze_layers_on_plateau\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving latest checkpoint...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: val_loss=1.102356195449829.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/pytorch_lightning/trainer/deprecated_api.py:32: LightningDeprecationWarning: `Trainer.train_loop` has been renamed to `Trainer.fit_loop` and will be removed in v1.6.\n",
      "  rank_zero_deprecation(\n",
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.teardown has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.teardown.\n",
      "  rank_zero_deprecation(\n",
      "Global seed set to 98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set current model training strategy to: finetuning_unfreeze_layers_on_plateau\n",
      "self.num_classes=19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:679: LightningDeprecationWarning: `trainer.test(test_dataloaders)` is deprecated in v1.4 and will be removed in v1.6. Use `trainer.test(dataloaders)` instead.\n",
      "  rank_zero_deprecation(\n",
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.\n",
      "  rank_zero_deprecation(\n",
      "2021-10-25 06:33:33,779 lightning_hydra_classifiers.experiments.multitask.datamodules INFO     Task_1: datamodule.setup(stage=test)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best checkpoint saved to: /media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/finetuning_unfreeze_layers_on_plateau-PNAS-19_classes-res_512-bsz_16-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/epoch=00-val_loss=1.102-val_acc=0.475.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdbd5e1b13964f44bd36af45e48cb2c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-25 06:33:40,222 lightning_hydra_classifiers.experiments.multitask.datamodules INFO     Task_1: datamodule.setup(stage=test)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c5f58ccc7c4fb6b2aef27fa01629aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED TRIAL RESULTS] Location: /media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/finetuning_unfreeze_layers_on_plateau-PNAS-19_classes-res_512-bsz_16-resnet50-pretrained_True-pool_avg/replicate_1/results/results.yaml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'test_acc'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.24480852484703064</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'val_acc'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.47486215829849243</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ckpt_path'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">_logs/avg/finetuning_unfreeze_layers_on_plateau-PNAS-19_classes-res_512-bsz_16-resnet50-pretr</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ained_True-pool_avg/replicate_1/results/checkpoints/epoch=00-val_loss=1.102-val_acc=0.475.ckp</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">t'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_config'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'backbone'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'backbone_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'resnet50'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'backbone_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'resnet50'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'pretrained'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'num_classes'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'pool_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'avg'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'head_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'linear'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'hidden_size'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'dropout_p'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'lr'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.025118864315095822</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'backbone_lr_mult'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'finetuning_strategy'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'finetuning_unfreeze_layers_on_plateau'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'weight_decay'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'seed'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">98</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'data_config'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'_target_'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'lightning_hydra_classifiers.experiments.multitask.datamodules.MultiTaskDataModule'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'image_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'image_buffer_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'batch_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'num_workers'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'pin_memory'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'dataset_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Extant-PNAS_to_PNAS'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'experiment'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'source_root_dir'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/media/data_cifs/projects/prj_fossils/users/jacob/experiments</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">/July2021-Nov2021/csv_datasets/leavesdb-v1_0'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'experiment_root_dir'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/media/data_cifs/projects/prj_fossils/users/jacob/experim</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ents/July2021-Nov2021/csv_datasets/experimental_datasets'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'experiment_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Extant-to-PNAS-512-transfer_benchmark'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'seed'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">96857</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'task_0'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Extant_Leaves_family_10_512_minus_PNAS_family_100_512'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'val_split'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'test_split'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'task_1'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'PNAS_family_100_512_minus_Extant_Leaves_family_10_512'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'val_split'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'test_split'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'test_acc'\u001b[0m: \u001b[1;36m0.24480852484703064\u001b[0m,\n",
       "    \u001b[32m'val_acc'\u001b[0m: \u001b[1;36m0.47486215829849243\u001b[0m,\n",
       "    \u001b[32m'ckpt_path'\u001b[0m: \u001b[32m'/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test\u001b[0m\n",
       "\u001b[32m_logs/avg/finetuning_unfreeze_layers_on_plateau-PNAS-19_classes-res_512-bsz_16-resnet50-pretr\u001b[0m\n",
       "\u001b[32mained_True-pool_avg/replicate_1/results/checkpoints/\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m00\u001b[0m\u001b[32m-\u001b[0m\u001b[32mval_loss\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1\u001b[0m\u001b[32m.102-\u001b[0m\u001b[32mval_acc\u001b[0m\u001b[32m=\u001b[0m\u001b[32m0\u001b[0m\u001b[32m.475.ckp\u001b[0m\n",
       "\u001b[32mt'\u001b[0m,\n",
       "    \u001b[32m'model_config'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'backbone'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'backbone_name'\u001b[0m: \u001b[32m'resnet50'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'backbone_name'\u001b[0m: \u001b[32m'resnet50'\u001b[0m,\n",
       "        \u001b[32m'pretrained'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "        \u001b[32m'num_classes'\u001b[0m: \u001b[1;36m19\u001b[0m,\n",
       "        \u001b[32m'pool_type'\u001b[0m: \u001b[32m'avg'\u001b[0m,\n",
       "        \u001b[32m'head_type'\u001b[0m: \u001b[32m'linear'\u001b[0m,\n",
       "        \u001b[32m'hidden_size'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'dropout_p'\u001b[0m: \u001b[1;36m0.3\u001b[0m,\n",
       "        \u001b[32m'lr'\u001b[0m: \u001b[1;36m0.025118864315095822\u001b[0m,\n",
       "        \u001b[32m'backbone_lr_mult'\u001b[0m: \u001b[1;36m0.1\u001b[0m,\n",
       "        \u001b[32m'finetuning_strategy'\u001b[0m: \u001b[32m'finetuning_unfreeze_layers_on_plateau'\u001b[0m,\n",
       "        \u001b[32m'weight_decay'\u001b[0m: \u001b[1;36m0.01\u001b[0m,\n",
       "        \u001b[32m'seed'\u001b[0m: \u001b[1;36m98\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'data_config'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'_target_'\u001b[0m: \n",
       "\u001b[32m'lightning_hydra_classifiers.experiments.multitask.datamodules.MultiTaskDataModule'\u001b[0m,\n",
       "        \u001b[32m'image_size'\u001b[0m: \u001b[1;36m512\u001b[0m,\n",
       "        \u001b[32m'image_buffer_size'\u001b[0m: \u001b[1;36m32\u001b[0m,\n",
       "        \u001b[32m'batch_size'\u001b[0m: \u001b[1;36m16\u001b[0m,\n",
       "        \u001b[32m'num_workers'\u001b[0m: \u001b[1;36m4\u001b[0m,\n",
       "        \u001b[32m'pin_memory'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "        \u001b[32m'dataset_name'\u001b[0m: \u001b[32m'Extant-PNAS_to_PNAS'\u001b[0m,\n",
       "        \u001b[32m'experiment'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'source_root_dir'\u001b[0m: \u001b[32m'/media/data_cifs/projects/prj_fossils/users/jacob/experiments\u001b[0m\n",
       "\u001b[32m/July2021-Nov2021/csv_datasets/leavesdb-v1_0'\u001b[0m,\n",
       "            \u001b[32m'experiment_root_dir'\u001b[0m: \u001b[32m'/media/data_cifs/projects/prj_fossils/users/jacob/experim\u001b[0m\n",
       "\u001b[32ments/July2021-Nov2021/csv_datasets/experimental_datasets'\u001b[0m,\n",
       "            \u001b[32m'experiment_name'\u001b[0m: \u001b[32m'Extant-to-PNAS-512-transfer_benchmark'\u001b[0m,\n",
       "            \u001b[32m'seed'\u001b[0m: \u001b[1;36m96857\u001b[0m,\n",
       "            \u001b[32m'task_0'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'name'\u001b[0m: \u001b[32m'Extant_Leaves_family_10_512_minus_PNAS_family_100_512'\u001b[0m,\n",
       "                \u001b[32m'val_split'\u001b[0m: \u001b[1;36m0.2\u001b[0m,\n",
       "                \u001b[32m'test_split'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'task_1'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'name'\u001b[0m: \u001b[32m'PNAS_family_100_512_minus_Extant_Leaves_family_10_512'\u001b[0m,\n",
       "                \u001b[32m'val_split'\u001b[0m: \u001b[1;36m0.2\u001b[0m,\n",
       "                \u001b[32m'test_split'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL FINISHED!!! RESULTS:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'finetuning_unfreeze_layers_on_plateau'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'test_acc'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.24480852484703064</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'val_acc'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.47486215829849243</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'ckpt_path'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">test_logs/avg/finetuning_unfreeze_layers_on_plateau-PNAS-19_classes-res_512-bsz_16-resnet50-p</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">retrained_True-pool_avg/replicate_1/results/checkpoints/epoch=00-val_loss=1.102-val_acc=0.475</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">.ckpt'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model_config'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'backbone'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'backbone_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'resnet50'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'backbone_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'resnet50'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'pretrained'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'num_classes'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'pool_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'avg'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'head_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'linear'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'hidden_size'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'dropout_p'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'lr'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.025118864315095822</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'backbone_lr_mult'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'finetuning_strategy'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'finetuning_unfreeze_layers_on_plateau'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'weight_decay'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'seed'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">98</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'data_config'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'_target_'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'lightning_hydra_classifiers.experiments.multitask.datamodules.MultiTaskDataModule'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'image_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'image_buffer_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'batch_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'num_workers'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'pin_memory'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'dataset_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Extant-PNAS_to_PNAS'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'experiment'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'source_root_dir'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/media/data_cifs/projects/prj_fossils/users/jacob/experim</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ents/July2021-Nov2021/csv_datasets/leavesdb-v1_0'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'experiment_root_dir'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/media/data_cifs/projects/prj_fossils/users/jacob/exp</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">eriments/July2021-Nov2021/csv_datasets/experimental_datasets'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'experiment_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Extant-to-PNAS-512-transfer_benchmark'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'seed'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">96857</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'task_0'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Extant_Leaves_family_10_512_minus_PNAS_family_100_512'</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'val_split'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'test_split'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "                <span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'task_1'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'PNAS_family_100_512_minus_Extant_Leaves_family_10_512'</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'val_split'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'test_split'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "                <span style=\"font-weight: bold\">}</span>\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'finetuning_unfreeze_layers_on_plateau'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'test_acc'\u001b[0m: \u001b[1;36m0.24480852484703064\u001b[0m,\n",
       "        \u001b[32m'val_acc'\u001b[0m: \u001b[1;36m0.47486215829849243\u001b[0m,\n",
       "        \u001b[32m'ckpt_path'\u001b[0m: \u001b[32m'/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_\u001b[0m\n",
       "\u001b[32mtest_logs/avg/finetuning_unfreeze_layers_on_plateau-PNAS-19_classes-res_512-bsz_16-resnet50-p\u001b[0m\n",
       "\u001b[32mretrained_True-pool_avg/replicate_1/results/checkpoints/\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m00\u001b[0m\u001b[32m-\u001b[0m\u001b[32mval_loss\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1\u001b[0m\u001b[32m.102-\u001b[0m\u001b[32mval_acc\u001b[0m\u001b[32m=\u001b[0m\u001b[32m0\u001b[0m\u001b[32m.475\u001b[0m\n",
       "\u001b[32m.ckpt'\u001b[0m,\n",
       "        \u001b[32m'model_config'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'backbone'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'backbone_name'\u001b[0m: \u001b[32m'resnet50'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'backbone_name'\u001b[0m: \u001b[32m'resnet50'\u001b[0m,\n",
       "            \u001b[32m'pretrained'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "            \u001b[32m'num_classes'\u001b[0m: \u001b[1;36m19\u001b[0m,\n",
       "            \u001b[32m'pool_type'\u001b[0m: \u001b[32m'avg'\u001b[0m,\n",
       "            \u001b[32m'head_type'\u001b[0m: \u001b[32m'linear'\u001b[0m,\n",
       "            \u001b[32m'hidden_size'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[32m'dropout_p'\u001b[0m: \u001b[1;36m0.3\u001b[0m,\n",
       "            \u001b[32m'lr'\u001b[0m: \u001b[1;36m0.025118864315095822\u001b[0m,\n",
       "            \u001b[32m'backbone_lr_mult'\u001b[0m: \u001b[1;36m0.1\u001b[0m,\n",
       "            \u001b[32m'finetuning_strategy'\u001b[0m: \u001b[32m'finetuning_unfreeze_layers_on_plateau'\u001b[0m,\n",
       "            \u001b[32m'weight_decay'\u001b[0m: \u001b[1;36m0.01\u001b[0m,\n",
       "            \u001b[32m'seed'\u001b[0m: \u001b[1;36m98\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'data_config'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'_target_'\u001b[0m: \n",
       "\u001b[32m'lightning_hydra_classifiers.experiments.multitask.datamodules.MultiTaskDataModule'\u001b[0m,\n",
       "            \u001b[32m'image_size'\u001b[0m: \u001b[1;36m512\u001b[0m,\n",
       "            \u001b[32m'image_buffer_size'\u001b[0m: \u001b[1;36m32\u001b[0m,\n",
       "            \u001b[32m'batch_size'\u001b[0m: \u001b[1;36m16\u001b[0m,\n",
       "            \u001b[32m'num_workers'\u001b[0m: \u001b[1;36m4\u001b[0m,\n",
       "            \u001b[32m'pin_memory'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "            \u001b[32m'dataset_name'\u001b[0m: \u001b[32m'Extant-PNAS_to_PNAS'\u001b[0m,\n",
       "            \u001b[32m'experiment'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'source_root_dir'\u001b[0m: \u001b[32m'/media/data_cifs/projects/prj_fossils/users/jacob/experim\u001b[0m\n",
       "\u001b[32ments/July2021-Nov2021/csv_datasets/leavesdb-v1_0'\u001b[0m,\n",
       "                \u001b[32m'experiment_root_dir'\u001b[0m: \u001b[32m'/media/data_cifs/projects/prj_fossils/users/jacob/exp\u001b[0m\n",
       "\u001b[32meriments/July2021-Nov2021/csv_datasets/experimental_datasets'\u001b[0m,\n",
       "                \u001b[32m'experiment_name'\u001b[0m: \u001b[32m'Extant-to-PNAS-512-transfer_benchmark'\u001b[0m,\n",
       "                \u001b[32m'seed'\u001b[0m: \u001b[1;36m96857\u001b[0m,\n",
       "                \u001b[32m'task_0'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                    \u001b[32m'name'\u001b[0m: \u001b[32m'Extant_Leaves_family_10_512_minus_PNAS_family_100_512'\u001b[0m,\n",
       "                    \u001b[32m'val_split'\u001b[0m: \u001b[1;36m0.2\u001b[0m,\n",
       "                    \u001b[32m'test_split'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "                \u001b[1m}\u001b[0m,\n",
       "                \u001b[32m'task_1'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                    \u001b[32m'name'\u001b[0m: \u001b[32m'PNAS_family_100_512_minus_Extant_Leaves_family_10_512'\u001b[0m,\n",
       "                    \u001b[32m'val_split'\u001b[0m: \u001b[1;36m0.2\u001b[0m,\n",
       "                    \u001b[32m'test_split'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "                \u001b[1m}\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 59s, sys: 37.9 s, total: 3min 37s\n",
      "Wall time: 4min 22s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 792x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "valid_strategies = (\"finetuning_unfreeze_layers_on_plateau\",)\n",
    "# pool_types = (\"avg\", \"avgdrop\")#, \"avgmax\", \"max\", \"avgmaxdrop\")\n",
    "\n",
    "# finetuning_strategy=\"feature_extractor\"\n",
    "# finetuning_strategy=\"feature_extractor_+_bn.eval()\"\n",
    "\n",
    "# pool_type='avgdrop'\n",
    "# pool_type='avgmaxdrop'\n",
    "pool_type=\"avg\"\n",
    "dropout_p = 0.3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for strategy in valid_strategies:\n",
    "\n",
    "    print(f\"BEGINNING STRATEGY: {strategy}\")\n",
    "    overrides = ['model/backbone=resnet50',\n",
    "                 \"data=extant_to_pnas\",\n",
    "                 \"trainer.max_epochs=1\",\n",
    "                 \"trainer.auto_lr_find=true\",\n",
    "                 \"trainer.precision=16\",\n",
    "                 \"trainer.gpus=[0]\",\n",
    "                 \"trainer.resume_from_checkpoint=null\",\n",
    "                 \"data.batch_size=16\",\n",
    "                 \"logger.wandb.project=finetuning_on_plateau\"]\n",
    "\n",
    "    config, datamodule = get_config_and_load_data(overrides = overrides,\n",
    "                                                  task_id=1,\n",
    "                                                  pool_type=pool_type,\n",
    "                                                  finetuning_strategy=strategy, #\"feature_extractor_+_bn.eval()\",\n",
    "                                                  lr=2e-03,\n",
    "                                                  dropout_p=dropout_p)#,\n",
    "#                                                   max_epochs=config.trainer.max_epochs)\n",
    "    ckpt_paths = os.listdir(os.path.join(config.checkpoint_dir))\n",
    "    if len(ckpt_paths) and os.path.exists(ckpt_paths[-1]):\n",
    "        print(f\"Found {ckpt_paths[-1]}\")\n",
    "        config.resume_from_checkpoint = ckpt_paths[-1]\n",
    "\n",
    "\n",
    "    model, results = test_model_freeze_strategy(config, datamodule)\n",
    "    model.cpu()\n",
    "    del model\n",
    "\n",
    "    results['model_config'] = OmegaConf.to_container(config.model, resolve=True)\n",
    "    results['data_config'] = OmegaConf.to_container(config.data, resolve=True)\n",
    "    \n",
    "    ETL.config2yaml(results, os.path.join(config.results_dir, \"results.yaml\"))\n",
    "    print(f\"[SAVED TRIAL RESULTS] Location: {os.path.join(config.results_dir, 'results.yaml')}\")\n",
    "    pp(results)\n",
    "    \n",
    "    all_results[strategy] = results\n",
    "\n",
    "print(f\"ALL FINISHED!!! RESULTS:\")\n",
    "pp(all_results)\n",
    "\n",
    "\n",
    "ETL.config2yaml(all_results, os.path.join(config.root_dir, \"results.yaml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConfigAttributeError",
     "evalue": "Missing key max_epochs\n    full_key: max_epochs\n    object_type=dict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConfigAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2326/1906452917.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/omegaconf/dictconfig.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_DEFAULT_MARKER_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mConfigKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m             self._format_and_raise(\n\u001b[0m\u001b[1;32m    352\u001b[0m                 \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_override\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mConfigAttributeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             )\n",
      "\u001b[0;32m/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/omegaconf/base.py\u001b[0m in \u001b[0;36m_format_and_raise\u001b[0;34m(self, key, value, cause, type_override)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcause\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_override\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     ) -> None:\n\u001b[0;32m--> 189\u001b[0;31m         format_and_raise(\n\u001b[0m\u001b[1;32m    190\u001b[0m             \u001b[0mnode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/omegaconf/_utils.py\u001b[0m in \u001b[0;36mformat_and_raise\u001b[0;34m(node, key, value, msg, cause, type_override)\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0mex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref_type_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mref_type_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m     \u001b[0m_raise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/omegaconf/_utils.py\u001b[0m in \u001b[0;36m_raise\u001b[0;34m(ex, cause)\u001b[0m\n\u001b[1;32m    597\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0mex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cause__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# set end OC_CAUSE=1 for full backtrace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/omegaconf/dictconfig.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_DEFAULT_MARKER_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mConfigKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             self._format_and_raise(\n",
      "\u001b[0;32m/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/omegaconf/dictconfig.py\u001b[0m in \u001b[0;36m_get_impl\u001b[0;34m(self, key, default_value)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDictKeyType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_value\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthrow_on_missing_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mConfigAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConfigKeyError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdefault_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_DEFAULT_MARKER_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/omegaconf/dictconfig.py\u001b[0m in \u001b[0;36m_get_node\u001b[0;34m(self, key, validate_access, throw_on_missing_value, throw_on_missing_key)\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mthrow_on_missing_key\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mConfigKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Missing key {key}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mthrow_on_missing_value\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mMissingMandatoryValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Missing mandatory value\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConfigAttributeError\u001b[0m: Missing key max_epochs\n    full_key: max_epochs\n    object_type=dict"
     ]
    }
   ],
   "source": [
    "test_logs/avg/finetuning_unfreeze_layers_on_plateau-PNAS-19_classes-res_512-bsz_16-resnet50-p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ckpt_path = '/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/finetuning_unfreeze_layers_on_plateau-PNAS-19_classes-res_512-bsz_16-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/epoch=00-val_loss=1.102-val_acc=0.475.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "## scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning_hydra_classifiers.utils.common_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset_counts_df.T.plot(kind='bar', figsize=(16,9), multiple='stack')\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"ticks\", color_codes=True)\n",
    "# sns.displot(data=subset_counts_df.T, kind='bar', figsize=(16,9), multiple='stack')\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "available_palettes = ['Accent', 'Accent_r', 'Blues', 'Blues_r', 'BrBG', 'BrBG_r', 'BuGn', 'BuGn_r', 'BuPu', 'BuPu_r', 'CMRmap', 'CMRmap_r', 'Dark2', 'Dark2_r', 'GnBu', 'GnBu_r', 'Greens', 'Greens_r', 'Greys', 'Greys_r', 'OrRd', 'OrRd_r', 'Oranges', 'Oranges_r', 'PRGn', 'PRGn_r', 'Paired', 'Paired_r', 'Pastel1', 'Pastel1_r', 'Pastel2', 'Pastel2_r', 'PiYG', 'PiYG_r', 'PuBu', 'PuBuGn', 'PuBuGn_r', 'PuBu_r', 'PuOr', 'PuOr_r', 'PuRd', 'PuRd_r', 'Purples', 'Purples_r', 'RdBu', 'RdBu_r', 'RdGy', 'RdGy_r', 'RdPu', 'RdPu_r', 'RdYlBu', 'RdYlBu_r', 'RdYlGn', 'RdYlGn_r', 'Reds', 'Reds_r', 'Set1', 'Set1_r', 'Set2', 'Set2_r', 'Set3', 'Set3_r', 'Spectral', 'Spectral_r', 'Wistia', 'Wistia_r', 'YlGn', 'YlGnBu', 'YlGnBu_r', 'YlGn_r', 'YlOrBr', 'YlOrBr_r', 'YlOrRd', 'YlOrRd_r', 'afmhot', 'afmhot_r', 'autumn', 'autumn_r', 'binary', 'binary_r', 'bone', 'bone_r', 'brg', 'brg_r', 'bwr', 'bwr_r', 'cividis', 'cividis_r', 'cool', 'cool_r', 'coolwarm', 'coolwarm_r', 'copper', 'copper_r', 'crest', 'crest_r', 'cubehelix', 'cubehelix_r', 'flag', 'flag_r', 'flare', 'flare_r', 'gist_earth', 'gist_earth_r', 'gist_gray', 'gist_gray_r', 'gist_heat', 'gist_heat_r', 'gist_ncar', 'gist_ncar_r', 'gist_rainbow', 'gist_rainbow_r', 'gist_stern', 'gist_stern_r', 'gist_yarg', 'gist_yarg_r', 'gnuplot', 'gnuplot2', 'gnuplot2_r', 'gnuplot_r', 'gray', 'gray_r', 'hot', 'hot_r', 'hsv', 'hsv_r', 'icefire', 'icefire_r', 'inferno', 'inferno_r', 'magma', 'magma_r', 'mako', 'mako_r', 'nipy_spectral', 'nipy_spectral_r', 'ocean', 'ocean_r', 'pink', 'pink_r', 'plasma', 'plasma_r', 'prism', 'prism_r', 'rainbow', 'rainbow_r', 'rocket', 'rocket_r', 'seismic', 'seismic_r', 'spring', 'spring_r', 'summer', 'summer_r', 'tab10', 'tab10_r', 'tab20', 'tab20_r', 'tab20b', 'tab20b_r', 'tab20c', 'tab20c_r', 'terrain', 'terrain_r', 'twilight', 'twilight_r', 'twilight_shifted', 'twilight_shifted_r', 'viridis', 'viridis_r', 'vlag', 'vlag_r', 'winter', 'winter_r']\n",
    "\n",
    "for p in available_palettes:\n",
    "    print(p)\n",
    "    display(sns.color_palette(p))\n",
    "\n",
    "datamodule.current_task\n",
    "\n",
    "data_splits=datamodule.current_task\n",
    "\n",
    "train_key = [\"train\"]\n",
    "sort_by = compute_class_counts(data_splits[train_key[0]].targets,\n",
    "                               sort_by=\"count\")\n",
    "\n",
    "subset_counts_df = {}\n",
    "for subset, values in data_splits.items():\n",
    "    print(subset)\n",
    "    values = compute_class_counts(data_splits[subset].targets,\n",
    "                                  sort_by=sort_by)\n",
    "    subset_counts_df[subset] = values\n",
    "\n",
    "subset_counts_df = pd.DataFrame.from_dict(subset_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = subset_counts_df.T.stack().reset_index().rename(columns={0:\"counts\"})#.set_index(\"subset\")\n",
    "\n",
    "# df.index.name = \"subset\"\n",
    "# df.columns.name = \"target\"\n",
    "\n",
    "\n",
    "df\n",
    "\n",
    "subset_counts_df.T#.unstack(\"target\")\n",
    "\n",
    "df_like = next(iter(df.groupby(\"subset\")))[1]\n",
    "\n",
    "totals = df_like[[\"target\", \"counts\"]].assign(counts=df_like[\"counts\"]*0).set_index(\"target\")\n",
    "\n",
    "# totals = df_like.set_index(\"subset\").assign(count=df[\"count\"]*0)\n",
    "previous_totals = totals.copy()\n",
    "\n",
    "previous_totals.counts + data_subset.set_index(\"target\").counts\n",
    "\n",
    "totals#.set_index(\"target\")\n",
    "previous_totals\n",
    "# data_subset.set_index(\"target\")\n",
    "\n",
    "#     totals[\"count\"] = previous_totals[\"count\"] + data_subset[\"count\"]\n",
    "\n",
    "# totals[\"count\"]\n",
    "# previous_totals[\"count\"] + \n",
    "data_subset[\"count\"]\n",
    "\n",
    "colors\n",
    "\n",
    "df\n",
    "\n",
    "df.stack(\"subset\")\n",
    "\n",
    "# gb = df.reset_index().groupby(\"subset\").unstack()\n",
    "\n",
    "df = df.reset_index().set_index(\"target\")#, \"target\"))\n",
    "# gb = df.unstack((\"subset\",\"target\"))\n",
    "df.plot(y=\"counts\", hue=\"subset\", kind=\"bar\", stacked=True)\n",
    "\n",
    "# gb.columns\n",
    "\n",
    "gb#.set_index(keys=(\"subset\", \"target\"))\n",
    "\n",
    "help(gb.plot)\n",
    "\n",
    "final_sum = df.groupby(\"target\").agg(sum).sort_values(\"counts\")\n",
    "\n",
    "final_sum\n",
    "\n",
    "data = totals.counts / final_sum\n",
    "\n",
    "totals\n",
    "\n",
    "# data\n",
    "final_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = sns.color_palette(\"Set2\")\n",
    "i=0\n",
    "\n",
    "for subset_name, data_subset in df.groupby(\"subset\"):\n",
    "    print(subset_name)\n",
    "    \n",
    "    totals.counts = previous_totals.counts + data_subset.set_index(\"target\").counts\n",
    "    previous_totals.counts = totals.counts\n",
    "    \n",
    "    data = totals.counts / final_sum\n",
    "#     display(totals)\n",
    "    bar = sns.barplot(data=totals.reset_index(), y=\"counts\",x=\"target\", label=subset_name, color=colors[i], alpha=0.3)#, kind='bar', palette=\"tab10_r\")\n",
    "#     bar = sns.barplot(data=totals, y=\"count\",x=\"target\", hue=\"subset\", kind='bar', palette=\"tab10_r\")\n",
    "    i+=1\n",
    "plt.legend()\n",
    "\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(16,9))\n",
    "# bar = sns.catplot(data=df, x=\"target\", y=\"count\", hue=\"subset\", kind='bar', ax=ax, palette=\"tab10_r\")#, multiple='stack')\n",
    "# bar = sns.catplot(data=df, x=\"target\", y=\"count\", hue=\"subset\", kind='bar', figsize=(16,9), palette=\"tab10_r\")\n",
    "\n",
    "# for c in colors:\n",
    "# data_bar_totals = pd.DataFrame.\n",
    "# dir(pd.DataFrame)\n",
    "\n",
    "\n",
    "for subset_name, data_subset in df.groupby(\"subset\"):\n",
    "    print(subset_name, data_subset)\n",
    "    bar = sns.barplot(data=data_subset, y=\"count\",x=\"target\", hue=\"subset\", kind='bar', palette=\"tab10_r\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# cat = sns.catplot(data=df, y=\"count\",x=\"target\", hue=\"subset\", kind='bar', palette=\"tab10_r\", height=5, aspect=3, multiple='stack')\n",
    "# ax = plt.gca()\n",
    "# ax.set_xticklabels(ax.get_xticklabels(), fontsize=14, rotation=30, ha=\"right\");\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sns.catplot(data=df, multiple='stack',  kind='bar')#, figsize=(16,9), multiple='stack')\n",
    "\n",
    "# a = df.set_index(df.columns.tolist())\n",
    "a = df.set_index([\"subset\", \"target\"])\n",
    "\n",
    "a.index\n",
    "\n",
    "# df.T.index.name\n",
    "\n",
    "\n",
    "df.index#columns\n",
    "\n",
    "df.T.reset_index()\n",
    "\n",
    "df.melt(id_vars=[\"subset\", \"target\"])\n",
    "\n",
    "penguins = sns.load_dataset(\"penguins\")\n",
    "sns.displot(penguins, x=\"flipper_length_mm\")\n",
    "\n",
    "penguins\n",
    "\n",
    "# # pd.DataFrame({\"labels\": [() for subset, values in data_splits.items()})\n",
    "\n",
    "# data_splits_cat = []\n",
    "\n",
    "# for subset, values in data_splits.items():\n",
    "#     print(subset)\n",
    "#     data_splits_cat.extend([(subset, v) for v in values])\n",
    "    \n",
    "    \n",
    "# data_splits_cat = pd.DataFrame.from_records(data_splits_cat, columns=[\"subset\",\"target\"])\n",
    "\n",
    "# data_splits_cat\n",
    "\n",
    "\n",
    "\n",
    "sns.set_palette(\"Set2\")\n",
    "\n",
    "fig, ax = plot_split_distributions(data_splits=datamodule.current_task,\n",
    "                                   use_one_axis=True,\n",
    "                                   hist_kwargs={\"alpha\":0.4,\n",
    "                                                \"multiple\":\"fill\"})\n",
    "plt.legend()\n",
    "\n",
    "display(ax[0])\n",
    "\n",
    "ax[0].legend()\n",
    "\n",
    "dir(datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overrides = ['model/backbone=efficientnet_b3',\"data=extant_to_fossil\", \"trainer.max_epochs=2\", \"data.batch_size=16\", \"trainer.precision=16\"]\n",
    "# overrides = ['model/backbone=resnet50',\"data=extant_to_pnas\", \"trainer.max_epochs=20\", \"data.batch_size=32\", \"trainer.precision=16\", \"trainer.gpus=[7]\"]\n",
    "# config = ETL.load_hydra_config(config_name = \"config\",\n",
    "#                               config_path = \"/media/data/jacob/GitHub/lightning-hydra-classifiers/configs\",\n",
    "#                               overrides=overrides)\n",
    "\n",
    "# valid_strategies : Tuple[str] = (\"feature_extractor\",\n",
    "#                              \"feature_extractor_+_bn.eval()\",\n",
    "#                              \"feature_extractor_+_except_bn\")\n",
    "            \n",
    "######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "## Evaluate multiple strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGINNING STRATEGY: feature_extractor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/hydra/experimental/initialize.py:98: UserWarning: hydra.experimental.initialize_config_dir() is no longer experimental. Use hydra.initialize_config_dir().\n",
      "  deprecation_warning(\n",
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/hydra/experimental/compose.py:18: UserWarning: hydra.experimental.compose() is no longer experimental. Use hydra.compose()\n",
      "  deprecation_warning(\n",
      "2021-10-18 10:50:16,248 lightning_hydra_classifiers.experiments.multitask.datamodules INFO     set_task(task_id=1)\n",
      "2021-10-18 10:50:16,251 lightning_hydra_classifiers.experiments.multitask.datamodules INFO     Task_1 (None): datamodule.setup(stage=fit)\n",
      "2021-10-18 10:50:16,252 lightning_hydra_classifiers.experiments.multitask.datamodules INFO     Task_1: datamodule.setup(stage=test)\n",
      "2021-10-18 10:50:16,401 lightning_hydra_classifiers.scripts.multitask.train INFO     Instantiating callback <pytorch_lightning.callbacks.early_stopping.EarlyStopping>\n",
      "2021-10-18 10:50:16,407 lightning_hydra_classifiers.scripts.multitask.train INFO     Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>\n",
      "2021-10-18 10:50:16,412 lightning_hydra_classifiers.scripts.multitask.train INFO     Instantiating callback <lightning_hydra_classifiers.callbacks.wandb_callbacks.LogPerClassMetricsToWandb>\n",
      "2021-10-18 10:50:16,420 lightning_hydra_classifiers.scripts.multitask.train INFO     Instantiating callback <lightning_hydra_classifiers.utils.callback_utils.ImagePredictionLogger>\n",
      "2021-10-18 10:50:16,422 lightning_hydra_classifiers.scripts.multitask.train INFO     Instantiating callback <lightning_hydra_classifiers.callbacks.wandb_callbacks.WatchModelWithWandb>\n",
      "2021-10-18 10:50:16,423 lightning_hydra_classifiers.scripts.multitask.train INFO     Instantiating callback <pl_bolts.callbacks.ModuleDataMonitor>\n",
      "2021-10-18 10:50:16,425 lightning_hydra_classifiers.scripts.multitask.train INFO     Instantiating logger <pytorch_lightning.loggers.wandb.WandbLogger>\n",
      "2021-10-18 10:50:16,427 lightning_hydra_classifiers.scripts.multitask.train INFO     Instantiating logger <pytorch_lightning.loggers.csv_logs.CSVLogger>\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "Global seed set to 98\n",
      "Global seed set to 98\n",
      "2021-10-18 10:50:18,283 lightning_hydra_classifiers.scripts.pretrain.lr_tuner INFO     Proceeding with overrides merged with default parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set current model training strategy to: feature_extractor\n",
      "self.num_classes=19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjrose\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.4 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.26<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">fresh-oath-29</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/jrose/default\" target=\"_blank\">https://wandb.ai/jrose/default</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/jrose/default/runs/2pt3wuet\" target=\"_blank\">https://wandb.ai/jrose/default/runs/2pt3wuet</a><br/>\n",
       "                Run data is saved locally in <code>/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/wandb/run-20211018_105018-2pt3wuet</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-18 10:50:20,425 lightning_hydra_classifiers.scripts.pretrain.lr_tuner INFO     [Initiating Stage] lr_tuner\n",
      "2021-10-18 10:50:20,914 lightning_hydra_classifiers.experiments.multitask.datamodules INFO     Task_1 (None): datamodule.setup(stage=fit)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name                    | Type             | Params\n",
      "-------------------------------------------------------------\n",
      "0 | model                   | Sequential       | 23.5 M\n",
      "1 | criterion               | CrossEntropyLoss | 0     \n",
      "2 | metrics_train           | MetricCollection | 0     \n",
      "3 | metrics_train_per_class | MetricCollection | 0     \n",
      "4 | metrics_val             | MetricCollection | 0     \n",
      "5 | metrics_val_per_class   | MetricCollection | 0     \n",
      "6 | metrics_test            | MetricCollection | 0     \n",
      "7 | metrics_test_per_class  | MetricCollection | 0     \n",
      "-------------------------------------------------------------\n",
      "38.9 K    Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.188    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.hparams=\"backbone\":            {'backbone_name': 'resnet50'}\n",
      "\"backbone_lr_mult\":    0.1\n",
      "\"backbone_name\":       resnet50\n",
      "\"dropout_p\":           0.3\n",
      "\"finetuning_strategy\": feature_extractor\n",
      "\"head_type\":           linear\n",
      "\"hidden_size\":         None\n",
      "\"lr\":                  0.002\n",
      "\"num_classes\":         19\n",
      "\"pool_size\":           1\n",
      "\"pool_type\":           avg\n",
      "\"pretrained\":          True\n",
      "\"seed\":                98\n",
      "\"weight_decay\":        0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 98\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8266bfff47b44796bea5e08b64f552d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During: self.training_step\n",
      "is_training:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'True'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">49</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'False'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'True'\u001b[0m: \u001b[1;36m49\u001b[0m, \u001b[32m'False'\u001b[0m: \u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requires_grad:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'True'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'False'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">98</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'True'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'False'\u001b[0m: \u001b[1;36m98\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{'val_acc': 0.055973269045352936,\n",
      " 'val_acc_epoch': 0.055973269045352936,\n",
      " 'val_loss': 2.5580384731292725,\n",
      " 'val_loss_epoch': 2.5580384731292725}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint file at /media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor-PNAS-19_classes-res_512-bsz_32-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/lr_find_temp_model.ckpt\n",
      "Restored all states from the checkpoint file at /media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor-PNAS-19_classes-res_512-bsz_32-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/lr_find_temp_model.ckpt\n",
      "2021-10-18 10:51:28,708 lightning_hydra_classifiers.scripts.pretrain.lr_tuner INFO     Saved best lr value (along w/ batch_size, image_size) to file located at: /media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor-PNAS-19_classes-res_512-bsz_32-resnet50-pretrained_True-pool_avg/replicate_1/results/task_1/lr_tuner/hparams.yaml\n",
      "2021-10-18 10:51:28,712 lightning_hydra_classifiers.scripts.pretrain.lr_tuner INFO     File contents expected to contain: \n",
      "{'optimized_hparam_key': 'lr', 'lr': 0.036307805477010104, 'batch_size': 32, 'image_size': 512, 'lr_tuner_config': {'min_lr': 1e-08, 'max_lr': 1, 'num_training': 100, 'mode': 'exponential', 'early_stop_threshold': 4.0}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 10296<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.78MB of 0.78MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/wandb/run-20211018_105018-2pt3wuet/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/wandb/run-20211018_105018-2pt3wuet/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>71</td></tr><tr><td>_timestamp</td><td>1634568689</td></tr><tr><td>_step</td><td>6</td></tr><tr><td>lr_finder/best/loss</td><td>2.63223</td></tr><tr><td>lr_finder/best/lr</td><td>0.03631</td></tr><tr><td>lr_finder/batch_size</td><td>32</td></tr><tr><td>image_size</td><td>512</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>_step</td><td>▁▂▃▅▆▇█</td></tr><tr><td>lr_finder/best/loss</td><td>▁</td></tr><tr><td>lr_finder/best/lr</td><td>▁</td></tr><tr><td>lr_finder/batch_size</td><td>▁</td></tr><tr><td>image_size</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 2 media file(s), 1 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">fresh-oath-29</strong>: <a href=\"https://wandb.ai/jrose/default/runs/2pt3wuet\" target=\"_blank\">https://wandb.ai/jrose/default/runs/2pt3wuet</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-18 10:51:35,115 lightning_hydra_classifiers.scripts.pretrain.lr_tuner INFO     FINISHED: `run_lr_tuner(config)`\n",
      "2021-10-18 10:51:35,116 lightning_hydra_classifiers.scripts.pretrain.lr_tuner INFO     Proceeding with:\n",
      "\n",
      "2021-10-18 10:51:35,117 lightning_hydra_classifiers.scripts.pretrain.lr_tuner INFO     Learning rate = 3.631e-02\n",
      "2021-10-18 10:51:35,118 lightning_hydra_classifiers.scripts.pretrain.lr_tuner INFO     Batch size = 32\n",
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.\n",
      "  rank_zero_deprecation(\n",
      "2021-10-18 10:51:35,124 lightning_hydra_classifiers.experiments.multitask.datamodules INFO     Task_1 (None): datamodule.setup(stage=fit)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.hparams=\"backbone\":            {'backbone_name': 'resnet50'}\n",
      "\"backbone_lr_mult\":    0.1\n",
      "\"backbone_name\":       resnet50\n",
      "\"dropout_p\":           0.3\n",
      "\"finetuning_strategy\": feature_extractor\n",
      "\"head_type\":           linear\n",
      "\"hidden_size\":         None\n",
      "\"lr\":                  0.036307805477010104\n",
      "\"num_classes\":         19\n",
      "\"pool_size\":           1\n",
      "\"pool_type\":           avg\n",
      "\"pretrained\":          True\n",
      "\"seed\":                98\n",
      "\"weight_decay\":        0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.4 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.26<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">restful-snowflake-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/jrose/bn_global_pool_trials\" target=\"_blank\">https://wandb.ai/jrose/bn_global_pool_trials</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/jrose/bn_global_pool_trials/runs/2bp6mkpz\" target=\"_blank\">https://wandb.ai/jrose/bn_global_pool_trials/runs/2bp6mkpz</a><br/>\n",
       "                Run data is saved locally in <code>/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/wandb/run-20211018_105135-2bp6mkpz</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name                    | Type             | Params\n",
      "-------------------------------------------------------------\n",
      "0 | model                   | Sequential       | 23.5 M\n",
      "1 | criterion               | CrossEntropyLoss | 0     \n",
      "2 | metrics_train           | MetricCollection | 0     \n",
      "3 | metrics_train_per_class | MetricCollection | 0     \n",
      "4 | metrics_val             | MetricCollection | 0     \n",
      "5 | metrics_val_per_class   | MetricCollection | 0     \n",
      "6 | metrics_test            | MetricCollection | 0     \n",
      "7 | metrics_test_per_class  | MetricCollection | 0     \n",
      "-------------------------------------------------------------\n",
      "38.9 K    Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.188    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 98\n",
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/pl_bolts/callbacks/data_monitor.py:104: UserWarning: ModuleDataMonitor does not support logging with LoggerCollection. Supported loggers are: TensorBoardLogger, WandbLogger\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b71e3ae821f84793aa73e8bcf231446c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 37it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/per_class/F1_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Precision_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Recall_distributions: metric_data[0].shape=(1,)\n",
      "val/confusion_matrix/restful-snowflake-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc improved. New best score: 0.336\n",
      "Epoch 0, global step 62: val_acc reached 0.33645 (best 0.33645), saving model to \"/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor-PNAS-19_classes-res_512-bsz_32-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/epoch=00-val_loss=2.540-val_acc=0.336.ckpt\" as top 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/per_class/F1_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Precision_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Recall_distributions: metric_data[0].shape=(1,)\n",
      "val/confusion_matrix/restful-snowflake-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc improved by 0.087 >= min_delta = 0.05. New best score: 0.424\n",
      "Epoch 1, global step 124: val_acc reached 0.42364 (best 0.42364), saving model to \"/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor-PNAS-19_classes-res_512-bsz_32-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/epoch=01-val_loss=2.167-val_acc=0.424.ckpt\" as top 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/per_class/F1_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Precision_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Recall_distributions: metric_data[0].shape=(1,)\n",
      "val/confusion_matrix/restful-snowflake-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 186: val_acc reached 0.43238 (best 0.43238), saving model to \"/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor-PNAS-19_classes-res_512-bsz_32-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/epoch=02-val_loss=1.748-val_acc=0.432.ckpt\" as top 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/per_class/F1_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Precision_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Recall_distributions: metric_data[0].shape=(1,)\n",
      "val/confusion_matrix/restful-snowflake-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 248: val_acc was not in top 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/per_class/F1_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Precision_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Recall_distributions: metric_data[0].shape=(1,)\n",
      "val/confusion_matrix/restful-snowflake-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 310: val_acc reached 0.44332 (best 0.44332), saving model to \"/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor-PNAS-19_classes-res_512-bsz_32-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/epoch=04-val_loss=2.468-val_acc=0.443.ckpt\" as top 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/per_class/F1_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Precision_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Recall_distributions: metric_data[0].shape=(1,)\n",
      "val/confusion_matrix/restful-snowflake-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 372: val_acc was not in top 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/per_class/F1_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Precision_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Recall_distributions: metric_data[0].shape=(1,)\n",
      "val/confusion_matrix/restful-snowflake-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc improved by 0.067 >= min_delta = 0.05. New best score: 0.491\n",
      "Epoch 6, global step 434: val_acc reached 0.49078 (best 0.49078), saving model to \"/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor-PNAS-19_classes-res_512-bsz_32-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/epoch=06-val_loss=1.956-val_acc=0.491.ckpt\" as top 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/per_class/F1_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Precision_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Recall_distributions: metric_data[0].shape=(1,)\n",
      "val/confusion_matrix/restful-snowflake-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 496: val_acc was not in top 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/per_class/F1_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Precision_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Recall_distributions: metric_data[0].shape=(1,)\n",
      "val/confusion_matrix/restful-snowflake-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 558: val_acc reached 0.47410 (best 0.49078), saving model to \"/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor-PNAS-19_classes-res_512-bsz_32-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/epoch=08-val_loss=2.080-val_acc=0.474.ckpt\" as top 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/per_class/F1_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Precision_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Recall_distributions: metric_data[0].shape=(1,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/utils/plot_utils.py:73: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots(1,1, figsize=figsize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/confusion_matrix/restful-snowflake-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 620: val_acc reached 0.48993 (best 0.49078), saving model to \"/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor-PNAS-19_classes-res_512-bsz_32-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/epoch=09-val_loss=2.481-val_acc=0.490.ckpt\" as top 2\n",
      "Saving latest checkpoint...\n",
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/pytorch_lightning/trainer/deprecated_api.py:32: LightningDeprecationWarning: `Trainer.train_loop` has been renamed to `Trainer.fit_loop` and will be removed in v1.6.\n",
      "  rank_zero_deprecation(\n",
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.teardown has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.teardown.\n",
      "  rank_zero_deprecation(\n",
      "Global seed set to 98\n",
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:679: LightningDeprecationWarning: `trainer.test(test_dataloaders)` is deprecated in v1.4 and will be removed in v1.6. Use `trainer.test(dataloaders)` instead.\n",
      "  rank_zero_deprecation(\n",
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.\n",
      "  rank_zero_deprecation(\n",
      "2021-10-18 11:03:52,768 lightning_hydra_classifiers.experiments.multitask.datamodules INFO     Task_1: datamodule.setup(stage=test)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set current model training strategy to: feature_extractor\n",
      "self.num_classes=19\n",
      "Best checkpoint saved to: /media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor-PNAS-19_classes-res_512-bsz_32-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/epoch=06-val_loss=1.956-val_acc=0.491.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "519cea55865b4b48820ee0d9fd835d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-18 11:03:59,820 lightning_hydra_classifiers.experiments.multitask.datamodules INFO     Task_1: datamodule.setup(stage=test)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3949712a28d145a68b6b7eb6c5d0dc0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED TRIAL RESULTS] Location: /media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor-PNAS-19_classes-res_512-bsz_32-resnet50-pretrained_True-pool_avg/replicate_1/results/results.yaml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'test_acc'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2617359757423401</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'val_acc'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4907832741737366</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ckpt_path'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">_logs/avg/feature_extractor-PNAS-19_classes-res_512-bsz_32-resnet50-pretrained_True-pool_avg/</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">replicate_1/results/checkpoints/epoch=06-val_loss=1.956-val_acc=0.491.ckpt'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_config'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'backbone'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'backbone_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'resnet50'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'backbone_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'resnet50'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'pretrained'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'num_classes'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'pool_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'avg'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'head_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'linear'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'hidden_size'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'dropout_p'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'lr'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.036307805477010104</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'backbone_lr_mult'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'finetuning_strategy'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'feature_extractor'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'weight_decay'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'seed'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">98</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'data_config'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'_target_'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'lightning_hydra_classifiers.experiments.multitask.datamodules.MultiTaskDataModule'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'image_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'image_buffer_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'batch_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'num_workers'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'pin_memory'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'dataset_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Extant-PNAS_to_PNAS'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'experiment'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'source_root_dir'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/media/data_cifs/projects/prj_fossils/users/jacob/experiments</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">/July2021-Nov2021/csv_datasets/leavesdb-v1_0'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'experiment_root_dir'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/media/data_cifs/projects/prj_fossils/users/jacob/experim</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ents/July2021-Nov2021/csv_datasets/experimental_datasets'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'experiment_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Extant-to-PNAS-512-transfer_benchmark'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'seed'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">96857</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'task_0'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Extant_Leaves_family_10_512_minus_PNAS_family_100_512'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'val_split'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'test_split'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'task_1'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'PNAS_family_100_512_minus_Extant_Leaves_family_10_512'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'val_split'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'test_split'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'test_acc'\u001b[0m: \u001b[1;36m0.2617359757423401\u001b[0m,\n",
       "    \u001b[32m'val_acc'\u001b[0m: \u001b[1;36m0.4907832741737366\u001b[0m,\n",
       "    \u001b[32m'ckpt_path'\u001b[0m: \u001b[32m'/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test\u001b[0m\n",
       "\u001b[32m_logs/avg/feature_extractor-PNAS-19_classes-res_512-bsz_32-resnet50-pretrained_True-pool_avg/\u001b[0m\n",
       "\u001b[32mreplicate_1/results/checkpoints/\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m06\u001b[0m\u001b[32m-\u001b[0m\u001b[32mval_loss\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1\u001b[0m\u001b[32m.956-\u001b[0m\u001b[32mval_acc\u001b[0m\u001b[32m=\u001b[0m\u001b[32m0\u001b[0m\u001b[32m.491.ckpt'\u001b[0m,\n",
       "    \u001b[32m'model_config'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'backbone'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'backbone_name'\u001b[0m: \u001b[32m'resnet50'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'backbone_name'\u001b[0m: \u001b[32m'resnet50'\u001b[0m,\n",
       "        \u001b[32m'pretrained'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "        \u001b[32m'num_classes'\u001b[0m: \u001b[1;36m19\u001b[0m,\n",
       "        \u001b[32m'pool_type'\u001b[0m: \u001b[32m'avg'\u001b[0m,\n",
       "        \u001b[32m'head_type'\u001b[0m: \u001b[32m'linear'\u001b[0m,\n",
       "        \u001b[32m'hidden_size'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'dropout_p'\u001b[0m: \u001b[1;36m0.3\u001b[0m,\n",
       "        \u001b[32m'lr'\u001b[0m: \u001b[1;36m0.036307805477010104\u001b[0m,\n",
       "        \u001b[32m'backbone_lr_mult'\u001b[0m: \u001b[1;36m0.1\u001b[0m,\n",
       "        \u001b[32m'finetuning_strategy'\u001b[0m: \u001b[32m'feature_extractor'\u001b[0m,\n",
       "        \u001b[32m'weight_decay'\u001b[0m: \u001b[1;36m0.01\u001b[0m,\n",
       "        \u001b[32m'seed'\u001b[0m: \u001b[1;36m98\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'data_config'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'_target_'\u001b[0m: \n",
       "\u001b[32m'lightning_hydra_classifiers.experiments.multitask.datamodules.MultiTaskDataModule'\u001b[0m,\n",
       "        \u001b[32m'image_size'\u001b[0m: \u001b[1;36m512\u001b[0m,\n",
       "        \u001b[32m'image_buffer_size'\u001b[0m: \u001b[1;36m32\u001b[0m,\n",
       "        \u001b[32m'batch_size'\u001b[0m: \u001b[1;36m32\u001b[0m,\n",
       "        \u001b[32m'num_workers'\u001b[0m: \u001b[1;36m4\u001b[0m,\n",
       "        \u001b[32m'pin_memory'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "        \u001b[32m'dataset_name'\u001b[0m: \u001b[32m'Extant-PNAS_to_PNAS'\u001b[0m,\n",
       "        \u001b[32m'experiment'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'source_root_dir'\u001b[0m: \u001b[32m'/media/data_cifs/projects/prj_fossils/users/jacob/experiments\u001b[0m\n",
       "\u001b[32m/July2021-Nov2021/csv_datasets/leavesdb-v1_0'\u001b[0m,\n",
       "            \u001b[32m'experiment_root_dir'\u001b[0m: \u001b[32m'/media/data_cifs/projects/prj_fossils/users/jacob/experim\u001b[0m\n",
       "\u001b[32ments/July2021-Nov2021/csv_datasets/experimental_datasets'\u001b[0m,\n",
       "            \u001b[32m'experiment_name'\u001b[0m: \u001b[32m'Extant-to-PNAS-512-transfer_benchmark'\u001b[0m,\n",
       "            \u001b[32m'seed'\u001b[0m: \u001b[1;36m96857\u001b[0m,\n",
       "            \u001b[32m'task_0'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'name'\u001b[0m: \u001b[32m'Extant_Leaves_family_10_512_minus_PNAS_family_100_512'\u001b[0m,\n",
       "                \u001b[32m'val_split'\u001b[0m: \u001b[1;36m0.2\u001b[0m,\n",
       "                \u001b[32m'test_split'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'task_1'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'name'\u001b[0m: \u001b[32m'PNAS_family_100_512_minus_Extant_Leaves_family_10_512'\u001b[0m,\n",
       "                \u001b[32m'val_split'\u001b[0m: \u001b[1;36m0.2\u001b[0m,\n",
       "                \u001b[32m'test_split'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGINNING STRATEGY: feature_extractor_+_bn.eval()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/hydra/experimental/initialize.py:98: UserWarning: hydra.experimental.initialize_config_dir() is no longer experimental. Use hydra.initialize_config_dir().\n",
      "  deprecation_warning(\n",
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/hydra/experimental/compose.py:18: UserWarning: hydra.experimental.compose() is no longer experimental. Use hydra.compose()\n",
      "  deprecation_warning(\n",
      "2021-10-18 11:04:45,931 lightning_hydra_classifiers.experiments.multitask.datamodules INFO     set_task(task_id=1)\n",
      "2021-10-18 11:04:45,938 lightning_hydra_classifiers.experiments.multitask.datamodules INFO     Task_1 (None): datamodule.setup(stage=fit)\n",
      "2021-10-18 11:04:45,939 lightning_hydra_classifiers.experiments.multitask.datamodules INFO     Task_1: datamodule.setup(stage=test)\n",
      "2021-10-18 11:04:46,081 lightning_hydra_classifiers.scripts.multitask.train INFO     Instantiating callback <pytorch_lightning.callbacks.early_stopping.EarlyStopping>\n",
      "2021-10-18 11:04:46,085 lightning_hydra_classifiers.scripts.multitask.train INFO     Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>\n",
      "2021-10-18 11:04:46,090 lightning_hydra_classifiers.scripts.multitask.train INFO     Instantiating callback <lightning_hydra_classifiers.callbacks.wandb_callbacks.LogPerClassMetricsToWandb>\n",
      "2021-10-18 11:04:46,097 lightning_hydra_classifiers.scripts.multitask.train INFO     Instantiating callback <lightning_hydra_classifiers.utils.callback_utils.ImagePredictionLogger>\n",
      "2021-10-18 11:04:46,099 lightning_hydra_classifiers.scripts.multitask.train INFO     Instantiating callback <lightning_hydra_classifiers.callbacks.wandb_callbacks.WatchModelWithWandb>\n",
      "2021-10-18 11:04:46,102 lightning_hydra_classifiers.scripts.multitask.train INFO     Instantiating callback <pl_bolts.callbacks.ModuleDataMonitor>\n",
      "2021-10-18 11:04:46,105 lightning_hydra_classifiers.scripts.multitask.train INFO     Instantiating logger <pytorch_lightning.loggers.wandb.WandbLogger>\n",
      "2021-10-18 11:04:46,108 lightning_hydra_classifiers.scripts.multitask.train INFO     Instantiating logger <pytorch_lightning.loggers.csv_logs.CSVLogger>\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "Global seed set to 98\n",
      "Global seed set to 98\n",
      "2021-10-18 11:04:47,186 lightning_hydra_classifiers.scripts.pretrain.lr_tuner INFO     Proceeding with overrides merged with default parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set current model training strategy to: feature_extractor_+_bn.eval()\n",
      "self.num_classes=19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2bp6mkpz) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 10990<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 93.38MB of 93.38MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/wandb/run-20211018_105135-2bp6mkpz/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/wandb/run-20211018_105135-2bp6mkpz/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_acc_step</td><td>0.65357</td></tr><tr><td>train_loss_step</td><td>0.81871</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>trainer/global_step</td><td>621</td></tr><tr><td>_runtime</td><td>774</td></tr><tr><td>_timestamp</td><td>1634569469</td></tr><tr><td>_step</td><td>203</td></tr><tr><td>val_acc_step</td><td>0.51515</td></tr><tr><td>val_loss_step</td><td>2.96418</td></tr><tr><td>val_acc_epoch</td><td>0.48993</td></tr><tr><td>val_loss_epoch</td><td>2.48073</td></tr><tr><td>train_acc_epoch</td><td>0.67315</td></tr><tr><td>train_loss_epoch</td><td>0.99161</td></tr><tr><td>test_acc</td><td>0.26174</td></tr><tr><td>test_loss</td><td>5.46278</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_acc_step</td><td>▁▆▁▄▆▃▄▅▆▅█▆</td></tr><tr><td>train_loss_step</td><td>█▅▅▃▂▆▅▅▁▄▃▂</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▄▂▂▂▅▂▂▂▆▂▂▂▇▃▃▃▇▃▃▃█</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc_step</td><td>▃▃▄▁▄▂▃▅▄▇█▄▄▃▆▅▃▅▆▄▅▄▂▆▆▅▄▆█▆▇▅▆▆▆▄▆▃▃▅</td></tr><tr><td>val_loss_step</td><td>▅▅▃█▄▄▂▅▃▃▁▄▄▄▃▅▆▄▃▇▇▅▅▅▅▃▂▅▄▄▃▆▄▃▂▄▅▄▄▇</td></tr><tr><td>val_acc_epoch</td><td>▁▅▅▅▆▅█▅▇█</td></tr><tr><td>val_loss_epoch</td><td>▆▄▁▃▅█▂▅▃▅</td></tr><tr><td>train_acc_epoch</td><td>▁▄▅▆▆▆▇▇██</td></tr><tr><td>train_loss_epoch</td><td>█▃▃▂▂▂▂▂▂▁</td></tr><tr><td>test_acc</td><td>█▁</td></tr><tr><td>test_loss</td><td>▁█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 381 media file(s), 40 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">restful-snowflake-1</strong>: <a href=\"https://wandb.ai/jrose/bn_global_pool_trials/runs/2bp6mkpz\" target=\"_blank\">https://wandb.ai/jrose/bn_global_pool_trials/runs/2bp6mkpz</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:2bp6mkpz). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.4 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.26<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">soft-paper-30</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/jrose/default\" target=\"_blank\">https://wandb.ai/jrose/default</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/jrose/default/runs/2mknsffw\" target=\"_blank\">https://wandb.ai/jrose/default/runs/2mknsffw</a><br/>\n",
       "                Run data is saved locally in <code>/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/wandb/run-20211018_110447-2mknsffw</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-18 11:04:52,243 lightning_hydra_classifiers.scripts.pretrain.lr_tuner INFO     [Initiating Stage] lr_tuner\n",
      "2021-10-18 11:04:52,623 lightning_hydra_classifiers.experiments.multitask.datamodules INFO     Task_1 (None): datamodule.setup(stage=fit)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name                    | Type             | Params\n",
      "-------------------------------------------------------------\n",
      "0 | model                   | Sequential       | 23.5 M\n",
      "1 | criterion               | CrossEntropyLoss | 0     \n",
      "2 | metrics_train           | MetricCollection | 0     \n",
      "3 | metrics_train_per_class | MetricCollection | 0     \n",
      "4 | metrics_val             | MetricCollection | 0     \n",
      "5 | metrics_val_per_class   | MetricCollection | 0     \n",
      "6 | metrics_test            | MetricCollection | 0     \n",
      "7 | metrics_test_per_class  | MetricCollection | 0     \n",
      "-------------------------------------------------------------\n",
      "38.9 K    Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.188    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.hparams=\"backbone\":            {'backbone_name': 'resnet50'}\n",
      "\"backbone_lr_mult\":    0.1\n",
      "\"backbone_name\":       resnet50\n",
      "\"dropout_p\":           0.3\n",
      "\"finetuning_strategy\": feature_extractor_+_bn.eval()\n",
      "\"head_type\":           linear\n",
      "\"hidden_size\":         None\n",
      "\"lr\":                  0.002\n",
      "\"num_classes\":         19\n",
      "\"pool_size\":           1\n",
      "\"pool_type\":           avg\n",
      "\"pretrained\":          True\n",
      "\"seed\":                98\n",
      "\"weight_decay\":        0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 98\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d994e78083c64c28af886e8e694f2d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During: self.training_step\n",
      "is_training:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'True'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'False'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">49</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'True'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'False'\u001b[0m: \u001b[1;36m49\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requires_grad:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'True'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'False'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">98</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'True'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'False'\u001b[0m: \u001b[1;36m98\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{'val_acc': 0.07444898784160614,\n",
      " 'val_acc_epoch': 0.07444898784160614,\n",
      " 'val_loss': 2.543883800506592,\n",
      " 'val_loss_epoch': 2.543883800506592}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint file at /media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor_+_bn.eval()-PNAS-19_classes-res_512-bsz_32-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/lr_find_temp_model.ckpt\n",
      "Restored all states from the checkpoint file at /media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor_+_bn.eval()-PNAS-19_classes-res_512-bsz_32-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/lr_find_temp_model.ckpt\n",
      "2021-10-18 11:05:56,848 lightning_hydra_classifiers.scripts.pretrain.lr_tuner INFO     Saved best lr value (along w/ batch_size, image_size) to file located at: /media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor_+_bn.eval()-PNAS-19_classes-res_512-bsz_32-resnet50-pretrained_True-pool_avg/replicate_1/results/task_1/lr_tuner/hparams.yaml\n",
      "2021-10-18 11:05:56,852 lightning_hydra_classifiers.scripts.pretrain.lr_tuner INFO     File contents expected to contain: \n",
      "{'optimized_hparam_key': 'lr', 'lr': 0.036307805477010104, 'batch_size': 32, 'image_size': 512, 'lr_tuner_config': {'min_lr': 1e-08, 'max_lr': 1, 'num_training': 100, 'mode': 'exponential', 'early_stop_threshold': 4.0}}\n",
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/pytorch_lightning/tuner/lr_finder.py:154: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 18097<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.45MB of 0.45MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/wandb/run-20211018_110447-2mknsffw/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/wandb/run-20211018_110447-2mknsffw/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>67</td></tr><tr><td>_timestamp</td><td>1634569557</td></tr><tr><td>_step</td><td>6</td></tr><tr><td>lr_finder/best/loss</td><td>2.6062</td></tr><tr><td>lr_finder/best/lr</td><td>0.03631</td></tr><tr><td>lr_finder/batch_size</td><td>32</td></tr><tr><td>image_size</td><td>512</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>_step</td><td>▁▂▃▅▆▇█</td></tr><tr><td>lr_finder/best/loss</td><td>▁</td></tr><tr><td>lr_finder/best/lr</td><td>▁</td></tr><tr><td>lr_finder/batch_size</td><td>▁</td></tr><tr><td>image_size</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 2 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">soft-paper-30</strong>: <a href=\"https://wandb.ai/jrose/default/runs/2mknsffw\" target=\"_blank\">https://wandb.ai/jrose/default/runs/2mknsffw</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-18 11:06:01,787 lightning_hydra_classifiers.scripts.pretrain.lr_tuner INFO     FINISHED: `run_lr_tuner(config)`\n",
      "2021-10-18 11:06:01,788 lightning_hydra_classifiers.scripts.pretrain.lr_tuner INFO     Proceeding with:\n",
      "\n",
      "2021-10-18 11:06:01,791 lightning_hydra_classifiers.scripts.pretrain.lr_tuner INFO     Learning rate = 3.631e-02\n",
      "2021-10-18 11:06:01,792 lightning_hydra_classifiers.scripts.pretrain.lr_tuner INFO     Batch size = 32\n",
      "2021-10-18 11:06:01,798 lightning_hydra_classifiers.experiments.multitask.datamodules INFO     Task_1 (None): datamodule.setup(stage=fit)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.hparams=\"backbone\":            {'backbone_name': 'resnet50'}\n",
      "\"backbone_lr_mult\":    0.1\n",
      "\"backbone_name\":       resnet50\n",
      "\"dropout_p\":           0.3\n",
      "\"finetuning_strategy\": feature_extractor_+_bn.eval()\n",
      "\"head_type\":           linear\n",
      "\"hidden_size\":         None\n",
      "\"lr\":                  0.036307805477010104\n",
      "\"num_classes\":         19\n",
      "\"pool_size\":           1\n",
      "\"pool_type\":           avg\n",
      "\"pretrained\":          True\n",
      "\"seed\":                98\n",
      "\"weight_decay\":        0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.4 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.26<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">glad-plant-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/jrose/bn_global_pool_trials\" target=\"_blank\">https://wandb.ai/jrose/bn_global_pool_trials</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/jrose/bn_global_pool_trials/runs/1pst3w78\" target=\"_blank\">https://wandb.ai/jrose/bn_global_pool_trials/runs/1pst3w78</a><br/>\n",
       "                Run data is saved locally in <code>/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/wandb/run-20211018_110601-1pst3w78</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name                    | Type             | Params\n",
      "-------------------------------------------------------------\n",
      "0 | model                   | Sequential       | 23.5 M\n",
      "1 | criterion               | CrossEntropyLoss | 0     \n",
      "2 | metrics_train           | MetricCollection | 0     \n",
      "3 | metrics_train_per_class | MetricCollection | 0     \n",
      "4 | metrics_val             | MetricCollection | 0     \n",
      "5 | metrics_val_per_class   | MetricCollection | 0     \n",
      "6 | metrics_test            | MetricCollection | 0     \n",
      "7 | metrics_test_per_class  | MetricCollection | 0     \n",
      "-------------------------------------------------------------\n",
      "38.9 K    Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.188    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 98\n",
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/pl_bolts/callbacks/data_monitor.py:104: UserWarning: ModuleDataMonitor does not support logging with LoggerCollection. Supported loggers are: TensorBoardLogger, WandbLogger\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e0e268183a64b54af0fd36571a6aa9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 37it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/callbacks/wandb_callbacks.py:344: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(w, h))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/per_class/F1_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Precision_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Recall_distributions: metric_data[0].shape=(1,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/utils/plot_utils.py:73: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots(1,1, figsize=figsize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/confusion_matrix/glad-plant-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc improved. New best score: 0.388\n",
      "Epoch 0, global step 62: val_acc reached 0.38761 (best 0.38761), saving model to \"/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor_+_bn.eval()-PNAS-19_classes-res_512-bsz_32-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/epoch=00-val_loss=1.782-val_acc=0.388.ckpt\" as top 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/callbacks/wandb_callbacks.py:344: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(w, h))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/per_class/F1_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Precision_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Recall_distributions: metric_data[0].shape=(1,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/utils/plot_utils.py:73: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots(1,1, figsize=figsize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/confusion_matrix/glad-plant-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 124: val_acc reached 0.38270 (best 0.38761), saving model to \"/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor_+_bn.eval()-PNAS-19_classes-res_512-bsz_32-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/epoch=01-val_loss=2.117-val_acc=0.383.ckpt\" as top 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/callbacks/wandb_callbacks.py:344: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(w, h))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/per_class/F1_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Precision_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Recall_distributions: metric_data[0].shape=(1,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/utils/plot_utils.py:73: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots(1,1, figsize=figsize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/confusion_matrix/glad-plant-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 186: val_acc reached 0.43712 (best 0.43712), saving model to \"/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor_+_bn.eval()-PNAS-19_classes-res_512-bsz_32-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/epoch=02-val_loss=1.509-val_acc=0.437.ckpt\" as top 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/callbacks/wandb_callbacks.py:344: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(w, h))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/per_class/F1_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Precision_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Recall_distributions: metric_data[0].shape=(1,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/utils/plot_utils.py:73: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots(1,1, figsize=figsize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/confusion_matrix/glad-plant-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 248: val_acc reached 0.40773 (best 0.43712), saving model to \"/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor_+_bn.eval()-PNAS-19_classes-res_512-bsz_32-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/epoch=03-val_loss=1.941-val_acc=0.408.ckpt\" as top 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/callbacks/wandb_callbacks.py:344: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(w, h))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/per_class/F1_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Precision_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Recall_distributions: metric_data[0].shape=(1,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/utils/plot_utils.py:73: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots(1,1, figsize=figsize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/confusion_matrix/glad-plant-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc improved by 0.107 >= min_delta = 0.05. New best score: 0.495\n",
      "Epoch 4, global step 310: val_acc reached 0.49473 (best 0.49473), saving model to \"/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor_+_bn.eval()-PNAS-19_classes-res_512-bsz_32-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/epoch=04-val_loss=1.585-val_acc=0.495.ckpt\" as top 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/callbacks/wandb_callbacks.py:344: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(w, h))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/per_class/F1_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Precision_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Recall_distributions: metric_data[0].shape=(1,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/utils/plot_utils.py:73: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots(1,1, figsize=figsize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/confusion_matrix/glad-plant-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 372: val_acc reached 0.45669 (best 0.49473), saving model to \"/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor_+_bn.eval()-PNAS-19_classes-res_512-bsz_32-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/epoch=05-val_loss=1.931-val_acc=0.457.ckpt\" as top 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/callbacks/wandb_callbacks.py:344: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(w, h))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/per_class/F1_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Precision_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Recall_distributions: metric_data[0].shape=(1,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/utils/plot_utils.py:73: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots(1,1, figsize=figsize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/confusion_matrix/glad-plant-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 434: val_acc reached 0.46350 (best 0.49473), saving model to \"/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor_+_bn.eval()-PNAS-19_classes-res_512-bsz_32-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/epoch=06-val_loss=1.765-val_acc=0.463.ckpt\" as top 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/callbacks/wandb_callbacks.py:344: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(w, h))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/per_class/F1_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Precision_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Recall_distributions: metric_data[0].shape=(1,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/utils/plot_utils.py:73: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots(1,1, figsize=figsize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/confusion_matrix/glad-plant-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 496: val_acc was not in top 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/callbacks/wandb_callbacks.py:344: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(w, h))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/per_class/F1_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Precision_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Recall_distributions: metric_data[0].shape=(1,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/utils/plot_utils.py:73: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots(1,1, figsize=figsize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/confusion_matrix/glad-plant-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 558: val_acc reached 0.47088 (best 0.49473), saving model to \"/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor_+_bn.eval()-PNAS-19_classes-res_512-bsz_32-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/epoch=08-val_loss=1.832-val_acc=0.471.ckpt\" as top 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/callbacks/wandb_callbacks.py:344: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(w, h))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/per_class/F1_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Precision_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Recall_distributions: metric_data[0].shape=(1,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/utils/plot_utils.py:73: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots(1,1, figsize=figsize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/confusion_matrix/glad-plant-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 620: val_acc was not in top 2\n",
      "Saving latest checkpoint...\n",
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/pytorch_lightning/trainer/deprecated_api.py:32: LightningDeprecationWarning: `Trainer.train_loop` has been renamed to `Trainer.fit_loop` and will be removed in v1.6.\n",
      "  rank_zero_deprecation(\n",
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.teardown has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.teardown.\n",
      "  rank_zero_deprecation(\n",
      "Global seed set to 98\n",
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:679: LightningDeprecationWarning: `trainer.test(test_dataloaders)` is deprecated in v1.4 and will be removed in v1.6. Use `trainer.test(dataloaders)` instead.\n",
      "  rank_zero_deprecation(\n",
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.\n",
      "  rank_zero_deprecation(\n",
      "2021-10-18 11:18:32,334 lightning_hydra_classifiers.experiments.multitask.datamodules INFO     Task_1: datamodule.setup(stage=test)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set current model training strategy to: feature_extractor_+_bn.eval()\n",
      "self.num_classes=19\n",
      "Best checkpoint saved to: /media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor_+_bn.eval()-PNAS-19_classes-res_512-bsz_32-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/epoch=04-val_loss=1.585-val_acc=0.495.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c2da35741fc455b8fe83947994b7365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-18 11:18:39,476 lightning_hydra_classifiers.experiments.multitask.datamodules INFO     Task_1: datamodule.setup(stage=test)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1552937529d049719db86a455b1ab3f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED TRIAL RESULTS] Location: /media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor_+_bn.eval()-PNAS-19_classes-res_512-bsz_32-resnet50-pretrained_True-pool_avg/replicate_1/results/results.yaml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'test_acc'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2662663757801056</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'val_acc'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4947287440299988</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ckpt_path'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">_logs/avg/feature_extractor_+_bn.eval()-PNAS-19_classes-res_512-bsz_32-resnet50-pretrained_Tr</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ue-pool_avg/replicate_1/results/checkpoints/epoch=04-val_loss=1.585-val_acc=0.495.ckpt'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_config'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'backbone'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'backbone_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'resnet50'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'backbone_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'resnet50'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'pretrained'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'num_classes'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'pool_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'avg'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'head_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'linear'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'hidden_size'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'dropout_p'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'lr'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.036307805477010104</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'backbone_lr_mult'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'finetuning_strategy'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'feature_extractor_+_bn.eval()'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'weight_decay'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'seed'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">98</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'data_config'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'_target_'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'lightning_hydra_classifiers.experiments.multitask.datamodules.MultiTaskDataModule'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'image_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'image_buffer_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'batch_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'num_workers'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'pin_memory'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'dataset_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Extant-PNAS_to_PNAS'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'experiment'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'source_root_dir'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/media/data_cifs/projects/prj_fossils/users/jacob/experiments</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">/July2021-Nov2021/csv_datasets/leavesdb-v1_0'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'experiment_root_dir'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/media/data_cifs/projects/prj_fossils/users/jacob/experim</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ents/July2021-Nov2021/csv_datasets/experimental_datasets'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'experiment_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Extant-to-PNAS-512-transfer_benchmark'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'seed'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">96857</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'task_0'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Extant_Leaves_family_10_512_minus_PNAS_family_100_512'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'val_split'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'test_split'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'task_1'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'PNAS_family_100_512_minus_Extant_Leaves_family_10_512'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'val_split'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'test_split'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'test_acc'\u001b[0m: \u001b[1;36m0.2662663757801056\u001b[0m,\n",
       "    \u001b[32m'val_acc'\u001b[0m: \u001b[1;36m0.4947287440299988\u001b[0m,\n",
       "    \u001b[32m'ckpt_path'\u001b[0m: \u001b[32m'/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test\u001b[0m\n",
       "\u001b[32m_logs/avg/feature_extractor_+_bn.eval\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m-PNAS-19_classes-res_512-bsz_32-resnet50-pretrained_Tr\u001b[0m\n",
       "\u001b[32mue-pool_avg/replicate_1/results/checkpoints/\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m04\u001b[0m\u001b[32m-\u001b[0m\u001b[32mval_loss\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1\u001b[0m\u001b[32m.585-\u001b[0m\u001b[32mval_acc\u001b[0m\u001b[32m=\u001b[0m\u001b[32m0\u001b[0m\u001b[32m.495.ckpt'\u001b[0m,\n",
       "    \u001b[32m'model_config'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'backbone'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'backbone_name'\u001b[0m: \u001b[32m'resnet50'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'backbone_name'\u001b[0m: \u001b[32m'resnet50'\u001b[0m,\n",
       "        \u001b[32m'pretrained'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "        \u001b[32m'num_classes'\u001b[0m: \u001b[1;36m19\u001b[0m,\n",
       "        \u001b[32m'pool_type'\u001b[0m: \u001b[32m'avg'\u001b[0m,\n",
       "        \u001b[32m'head_type'\u001b[0m: \u001b[32m'linear'\u001b[0m,\n",
       "        \u001b[32m'hidden_size'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'dropout_p'\u001b[0m: \u001b[1;36m0.3\u001b[0m,\n",
       "        \u001b[32m'lr'\u001b[0m: \u001b[1;36m0.036307805477010104\u001b[0m,\n",
       "        \u001b[32m'backbone_lr_mult'\u001b[0m: \u001b[1;36m0.1\u001b[0m,\n",
       "        \u001b[32m'finetuning_strategy'\u001b[0m: \u001b[32m'feature_extractor_+_bn.eval\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\n",
       "        \u001b[32m'weight_decay'\u001b[0m: \u001b[1;36m0.01\u001b[0m,\n",
       "        \u001b[32m'seed'\u001b[0m: \u001b[1;36m98\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'data_config'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'_target_'\u001b[0m: \n",
       "\u001b[32m'lightning_hydra_classifiers.experiments.multitask.datamodules.MultiTaskDataModule'\u001b[0m,\n",
       "        \u001b[32m'image_size'\u001b[0m: \u001b[1;36m512\u001b[0m,\n",
       "        \u001b[32m'image_buffer_size'\u001b[0m: \u001b[1;36m32\u001b[0m,\n",
       "        \u001b[32m'batch_size'\u001b[0m: \u001b[1;36m32\u001b[0m,\n",
       "        \u001b[32m'num_workers'\u001b[0m: \u001b[1;36m4\u001b[0m,\n",
       "        \u001b[32m'pin_memory'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "        \u001b[32m'dataset_name'\u001b[0m: \u001b[32m'Extant-PNAS_to_PNAS'\u001b[0m,\n",
       "        \u001b[32m'experiment'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'source_root_dir'\u001b[0m: \u001b[32m'/media/data_cifs/projects/prj_fossils/users/jacob/experiments\u001b[0m\n",
       "\u001b[32m/July2021-Nov2021/csv_datasets/leavesdb-v1_0'\u001b[0m,\n",
       "            \u001b[32m'experiment_root_dir'\u001b[0m: \u001b[32m'/media/data_cifs/projects/prj_fossils/users/jacob/experim\u001b[0m\n",
       "\u001b[32ments/July2021-Nov2021/csv_datasets/experimental_datasets'\u001b[0m,\n",
       "            \u001b[32m'experiment_name'\u001b[0m: \u001b[32m'Extant-to-PNAS-512-transfer_benchmark'\u001b[0m,\n",
       "            \u001b[32m'seed'\u001b[0m: \u001b[1;36m96857\u001b[0m,\n",
       "            \u001b[32m'task_0'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'name'\u001b[0m: \u001b[32m'Extant_Leaves_family_10_512_minus_PNAS_family_100_512'\u001b[0m,\n",
       "                \u001b[32m'val_split'\u001b[0m: \u001b[1;36m0.2\u001b[0m,\n",
       "                \u001b[32m'test_split'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'task_1'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'name'\u001b[0m: \u001b[32m'PNAS_family_100_512_minus_Extant_Leaves_family_10_512'\u001b[0m,\n",
       "                \u001b[32m'val_split'\u001b[0m: \u001b[1;36m0.2\u001b[0m,\n",
       "                \u001b[32m'test_split'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGINNING STRATEGY: feature_extractor_+_except_bn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/hydra/experimental/initialize.py:98: UserWarning: hydra.experimental.initialize_config_dir() is no longer experimental. Use hydra.initialize_config_dir().\n",
      "  deprecation_warning(\n",
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/hydra/experimental/compose.py:18: UserWarning: hydra.experimental.compose() is no longer experimental. Use hydra.compose()\n",
      "  deprecation_warning(\n",
      "2021-10-18 11:19:24,925 lightning_hydra_classifiers.experiments.multitask.datamodules INFO     set_task(task_id=1)\n",
      "2021-10-18 11:19:24,931 lightning_hydra_classifiers.experiments.multitask.datamodules INFO     Task_1 (None): datamodule.setup(stage=fit)\n",
      "2021-10-18 11:19:24,933 lightning_hydra_classifiers.experiments.multitask.datamodules INFO     Task_1: datamodule.setup(stage=test)\n",
      "2021-10-18 11:19:25,074 lightning_hydra_classifiers.scripts.multitask.train INFO     Instantiating callback <pytorch_lightning.callbacks.early_stopping.EarlyStopping>\n",
      "2021-10-18 11:19:25,078 lightning_hydra_classifiers.scripts.multitask.train INFO     Instantiating callback <pytorch_lightning.callbacks.ModelCheckpoint>\n",
      "2021-10-18 11:19:25,082 lightning_hydra_classifiers.scripts.multitask.train INFO     Instantiating callback <lightning_hydra_classifiers.callbacks.wandb_callbacks.LogPerClassMetricsToWandb>\n",
      "2021-10-18 11:19:25,089 lightning_hydra_classifiers.scripts.multitask.train INFO     Instantiating callback <lightning_hydra_classifiers.utils.callback_utils.ImagePredictionLogger>\n",
      "2021-10-18 11:19:25,092 lightning_hydra_classifiers.scripts.multitask.train INFO     Instantiating callback <lightning_hydra_classifiers.callbacks.wandb_callbacks.WatchModelWithWandb>\n",
      "2021-10-18 11:19:25,095 lightning_hydra_classifiers.scripts.multitask.train INFO     Instantiating callback <pl_bolts.callbacks.ModuleDataMonitor>\n",
      "2021-10-18 11:19:25,098 lightning_hydra_classifiers.scripts.multitask.train INFO     Instantiating logger <pytorch_lightning.loggers.wandb.WandbLogger>\n",
      "2021-10-18 11:19:25,100 lightning_hydra_classifiers.scripts.multitask.train INFO     Instantiating logger <pytorch_lightning.loggers.csv_logs.CSVLogger>\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "Global seed set to 98\n",
      "Global seed set to 98\n",
      "2021-10-18 11:19:26,058 lightning_hydra_classifiers.scripts.pretrain.lr_tuner INFO     Proceeding with overrides merged with default parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set current model training strategy to: feature_extractor_+_except_bn\n",
      "self.num_classes=19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1pst3w78) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 18725<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 97.77MB of 97.77MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/wandb/run-20211018_110601-1pst3w78/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/wandb/run-20211018_110601-1pst3w78/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_acc_step</td><td>0.8</td></tr><tr><td>train_loss_step</td><td>0.63374</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>trainer/global_step</td><td>621</td></tr><tr><td>_runtime</td><td>786</td></tr><tr><td>_timestamp</td><td>1634570348</td></tr><tr><td>_step</td><td>203</td></tr><tr><td>val_acc_step</td><td>0.56061</td></tr><tr><td>val_loss_step</td><td>2.10756</td></tr><tr><td>val_acc_epoch</td><td>0.46277</td></tr><tr><td>val_loss_epoch</td><td>2.18639</td></tr><tr><td>train_acc_epoch</td><td>0.67129</td></tr><tr><td>train_loss_epoch</td><td>1.00759</td></tr><tr><td>test_acc</td><td>0.26627</td></tr><tr><td>test_loss</td><td>3.89126</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_acc_step</td><td>▁▄▅▃▄▅▅▅█▇▆▇</td></tr><tr><td>train_loss_step</td><td>█▄▂▅▃▅▂▃▁▂▃▂</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▄▂▂▂▅▂▂▂▆▂▂▂▇▃▃▃▇▃▃▃█</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc_step</td><td>▃▃▄▃▁▁▅▄▃█▇▄▃▅▅▄▃▄█▅▃▃▄▆▄▆▄▄▃▅▆▅▂▅▃▄▃▄▅▅</td></tr><tr><td>val_loss_step</td><td>▄▃▂▅▇▅▂▇▅▂▁▅▄▄▃█▆▄▁▅▇▅▃▇▇▃▂▇▅▃▂▇▆▃▄▆▆▄▄▆</td></tr><tr><td>val_acc_epoch</td><td>▁▁▄▃█▆▆▅▇▆</td></tr><tr><td>val_loss_epoch</td><td>▄▇▁▅▂▅▄▅▄█</td></tr><tr><td>train_acc_epoch</td><td>▁▄▅▆▆▇████</td></tr><tr><td>train_loss_epoch</td><td>█▃▃▃▂▂▂▁▁▂</td></tr><tr><td>test_acc</td><td>█▁</td></tr><tr><td>test_loss</td><td>▁█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 381 media file(s), 40 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">glad-plant-2</strong>: <a href=\"https://wandb.ai/jrose/bn_global_pool_trials/runs/1pst3w78\" target=\"_blank\">https://wandb.ai/jrose/bn_global_pool_trials/runs/1pst3w78</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:1pst3w78). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.4 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.26<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">eternal-gorge-31</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/jrose/default\" target=\"_blank\">https://wandb.ai/jrose/default</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/jrose/default/runs/32fhboud\" target=\"_blank\">https://wandb.ai/jrose/default/runs/32fhboud</a><br/>\n",
       "                Run data is saved locally in <code>/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/wandb/run-20211018_111926-32fhboud</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-18 11:19:30,857 lightning_hydra_classifiers.scripts.pretrain.lr_tuner INFO     [Initiating Stage] lr_tuner\n",
      "2021-10-18 11:19:31,758 lightning_hydra_classifiers.experiments.multitask.datamodules INFO     Task_1 (None): datamodule.setup(stage=fit)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name                    | Type             | Params\n",
      "-------------------------------------------------------------\n",
      "0 | model                   | Sequential       | 23.5 M\n",
      "1 | criterion               | CrossEntropyLoss | 0     \n",
      "2 | metrics_train           | MetricCollection | 0     \n",
      "3 | metrics_train_per_class | MetricCollection | 0     \n",
      "4 | metrics_val             | MetricCollection | 0     \n",
      "5 | metrics_val_per_class   | MetricCollection | 0     \n",
      "6 | metrics_test            | MetricCollection | 0     \n",
      "7 | metrics_test_per_class  | MetricCollection | 0     \n",
      "-------------------------------------------------------------\n",
      "84.4 K    Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.188    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.hparams=\"backbone\":            {'backbone_name': 'resnet50'}\n",
      "\"backbone_lr_mult\":    0.1\n",
      "\"backbone_name\":       resnet50\n",
      "\"dropout_p\":           0.3\n",
      "\"finetuning_strategy\": feature_extractor_+_except_bn\n",
      "\"head_type\":           linear\n",
      "\"hidden_size\":         None\n",
      "\"lr\":                  0.002\n",
      "\"num_classes\":         19\n",
      "\"pool_size\":           1\n",
      "\"pool_type\":           avg\n",
      "\"pretrained\":          True\n",
      "\"seed\":                98\n",
      "\"weight_decay\":        0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 98\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dca18ab0455245ef971fe77cec4ed670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During: self.training_step\n",
      "is_training:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'True'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">49</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'False'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'True'\u001b[0m: \u001b[1;36m49\u001b[0m, \u001b[32m'False'\u001b[0m: \u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requires_grad:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'True'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">98</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'False'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'True'\u001b[0m: \u001b[1;36m98\u001b[0m, \u001b[32m'False'\u001b[0m: \u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint file at /media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor_+_except_bn-PNAS-19_classes-res_512-bsz_16-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/lr_find_temp_model.ckpt\n",
      "Restored all states from the checkpoint file at /media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor_+_except_bn-PNAS-19_classes-res_512-bsz_16-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/lr_find_temp_model.ckpt\n",
      "2021-10-18 11:20:10,724 lightning_hydra_classifiers.scripts.pretrain.lr_tuner INFO     Saved best lr value (along w/ batch_size, image_size) to file located at: /media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor_+_except_bn-PNAS-19_classes-res_512-bsz_16-resnet50-pretrained_True-pool_avg/replicate_1/results/task_1/lr_tuner/hparams.yaml\n",
      "2021-10-18 11:20:10,727 lightning_hydra_classifiers.scripts.pretrain.lr_tuner INFO     File contents expected to contain: \n",
      "{'optimized_hparam_key': 'lr', 'lr': 0.025118864315095822, 'batch_size': 16, 'image_size': 512, 'lr_tuner_config': {'min_lr': 1e-08, 'max_lr': 1, 'num_training': 100, 'mode': 'exponential', 'early_stop_threshold': 4.0}}\n",
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/pytorch_lightning/tuner/lr_finder.py:154: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 25463<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.54MB of 0.54MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/wandb/run-20211018_111926-32fhboud/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/wandb/run-20211018_111926-32fhboud/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>42</td></tr><tr><td>_timestamp</td><td>1634570411</td></tr><tr><td>_step</td><td>6</td></tr><tr><td>lr_finder/best/loss</td><td>2.6996</td></tr><tr><td>lr_finder/best/lr</td><td>0.02512</td></tr><tr><td>lr_finder/batch_size</td><td>16</td></tr><tr><td>image_size</td><td>512</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▁▁▁</td></tr><tr><td>_step</td><td>▁▂▃▅▆▇█</td></tr><tr><td>lr_finder/best/loss</td><td>▁</td></tr><tr><td>lr_finder/best/lr</td><td>▁</td></tr><tr><td>lr_finder/batch_size</td><td>▁</td></tr><tr><td>image_size</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 2 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">eternal-gorge-31</strong>: <a href=\"https://wandb.ai/jrose/default/runs/32fhboud\" target=\"_blank\">https://wandb.ai/jrose/default/runs/32fhboud</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-18 11:20:15,446 lightning_hydra_classifiers.scripts.pretrain.lr_tuner INFO     FINISHED: `run_lr_tuner(config)`\n",
      "2021-10-18 11:20:15,447 lightning_hydra_classifiers.scripts.pretrain.lr_tuner INFO     Proceeding with:\n",
      "\n",
      "2021-10-18 11:20:15,448 lightning_hydra_classifiers.scripts.pretrain.lr_tuner INFO     Learning rate = 2.512e-02\n",
      "2021-10-18 11:20:15,448 lightning_hydra_classifiers.scripts.pretrain.lr_tuner INFO     Batch size = 16\n",
      "2021-10-18 11:20:15,455 lightning_hydra_classifiers.experiments.multitask.datamodules INFO     Task_1 (None): datamodule.setup(stage=fit)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.hparams=\"backbone\":            {'backbone_name': 'resnet50'}\n",
      "\"backbone_lr_mult\":    0.1\n",
      "\"backbone_name\":       resnet50\n",
      "\"dropout_p\":           0.3\n",
      "\"finetuning_strategy\": feature_extractor_+_except_bn\n",
      "\"head_type\":           linear\n",
      "\"hidden_size\":         None\n",
      "\"lr\":                  0.025118864315095822\n",
      "\"num_classes\":         19\n",
      "\"pool_size\":           1\n",
      "\"pool_type\":           avg\n",
      "\"pretrained\":          True\n",
      "\"seed\":                98\n",
      "\"weight_decay\":        0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.4 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.26<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">royal-forest-3</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/jrose/bn_global_pool_trials\" target=\"_blank\">https://wandb.ai/jrose/bn_global_pool_trials</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/jrose/bn_global_pool_trials/runs/nlshvwfk\" target=\"_blank\">https://wandb.ai/jrose/bn_global_pool_trials/runs/nlshvwfk</a><br/>\n",
       "                Run data is saved locally in <code>/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/wandb/run-20211018_112015-nlshvwfk</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name                    | Type             | Params\n",
      "-------------------------------------------------------------\n",
      "0 | model                   | Sequential       | 23.5 M\n",
      "1 | criterion               | CrossEntropyLoss | 0     \n",
      "2 | metrics_train           | MetricCollection | 0     \n",
      "3 | metrics_train_per_class | MetricCollection | 0     \n",
      "4 | metrics_val             | MetricCollection | 0     \n",
      "5 | metrics_val_per_class   | MetricCollection | 0     \n",
      "6 | metrics_test            | MetricCollection | 0     \n",
      "7 | metrics_test_per_class  | MetricCollection | 0     \n",
      "-------------------------------------------------------------\n",
      "84.4 K    Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.188    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 98\n",
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/pl_bolts/callbacks/data_monitor.py:104: UserWarning: ModuleDataMonitor does not support logging with LoggerCollection. Supported loggers are: TensorBoardLogger, WandbLogger\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a61f4f72702c46109a1175f6f64bd118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 99it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/callbacks/wandb_callbacks.py:344: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(w, h))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/per_class/F1_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Precision_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Recall_distributions: metric_data[0].shape=(1,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/utils/plot_utils.py:73: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots(1,1, figsize=figsize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/confusion_matrix/royal-forest-3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc improved. New best score: 0.475\n",
      "Epoch 0, global step 125: val_acc reached 0.47490 (best 0.47490), saving model to \"/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor_+_except_bn-PNAS-19_classes-res_512-bsz_16-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/epoch=00-val_loss=1.124-val_acc=0.475.ckpt\" as top 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/callbacks/wandb_callbacks.py:344: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(w, h))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/per_class/F1_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Precision_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Recall_distributions: metric_data[0].shape=(1,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/utils/plot_utils.py:73: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots(1,1, figsize=figsize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/confusion_matrix/royal-forest-3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc improved by 0.106 >= min_delta = 0.05. New best score: 0.581\n",
      "Epoch 1, global step 250: val_acc reached 0.58081 (best 0.58081), saving model to \"/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor_+_except_bn-PNAS-19_classes-res_512-bsz_16-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/epoch=01-val_loss=0.913-val_acc=0.581.ckpt\" as top 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/callbacks/wandb_callbacks.py:344: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(w, h))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/per_class/F1_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Precision_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Recall_distributions: metric_data[0].shape=(1,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/utils/plot_utils.py:73: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots(1,1, figsize=figsize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/confusion_matrix/royal-forest-3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 375: val_acc reached 0.51311 (best 0.58081), saving model to \"/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor_+_except_bn-PNAS-19_classes-res_512-bsz_16-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/epoch=02-val_loss=0.989-val_acc=0.513.ckpt\" as top 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/callbacks/wandb_callbacks.py:344: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(w, h))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/per_class/F1_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Precision_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Recall_distributions: metric_data[0].shape=(1,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/utils/plot_utils.py:73: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots(1,1, figsize=figsize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/confusion_matrix/royal-forest-3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 500: val_acc reached 0.59269 (best 0.59269), saving model to \"/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor_+_except_bn-PNAS-19_classes-res_512-bsz_16-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/epoch=03-val_loss=0.930-val_acc=0.593.ckpt\" as top 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/callbacks/wandb_callbacks.py:344: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(w, h))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/per_class/F1_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Precision_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Recall_distributions: metric_data[0].shape=(1,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/utils/plot_utils.py:73: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots(1,1, figsize=figsize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/confusion_matrix/royal-forest-3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 625: val_acc reached 0.61748 (best 0.61748), saving model to \"/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor_+_except_bn-PNAS-19_classes-res_512-bsz_16-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/epoch=04-val_loss=0.878-val_acc=0.617.ckpt\" as top 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/callbacks/wandb_callbacks.py:344: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(w, h))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/per_class/F1_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Precision_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Recall_distributions: metric_data[0].shape=(1,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/utils/plot_utils.py:73: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots(1,1, figsize=figsize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/confusion_matrix/royal-forest-3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 750: val_acc reached 0.62468 (best 0.62468), saving model to \"/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor_+_except_bn-PNAS-19_classes-res_512-bsz_16-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/epoch=05-val_loss=0.899-val_acc=0.625.ckpt\" as top 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/callbacks/wandb_callbacks.py:344: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(w, h))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/per_class/F1_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Precision_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Recall_distributions: metric_data[0].shape=(1,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/utils/plot_utils.py:73: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots(1,1, figsize=figsize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/confusion_matrix/royal-forest-3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 875: val_acc was not in top 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/callbacks/wandb_callbacks.py:344: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(w, h))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/per_class/F1_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Precision_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Recall_distributions: metric_data[0].shape=(1,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/utils/plot_utils.py:73: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots(1,1, figsize=figsize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/confusion_matrix/royal-forest-3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 1000: val_acc reached 0.61791 (best 0.62468), saving model to \"/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor_+_except_bn-PNAS-19_classes-res_512-bsz_16-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/epoch=07-val_loss=0.819-val_acc=0.618.ckpt\" as top 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/callbacks/wandb_callbacks.py:344: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(w, h))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/per_class/F1_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Precision_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Recall_distributions: metric_data[0].shape=(1,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/utils/plot_utils.py:73: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots(1,1, figsize=figsize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/confusion_matrix/royal-forest-3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc improved by 0.055 >= min_delta = 0.05. New best score: 0.636\n",
      "Epoch 8, global step 1125: val_acc reached 0.63592 (best 0.63592), saving model to \"/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor_+_except_bn-PNAS-19_classes-res_512-bsz_16-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/epoch=08-val_loss=0.893-val_acc=0.636.ckpt\" as top 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/callbacks/wandb_callbacks.py:344: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(w, h))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/per_class/F1_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Precision_distributions: metric_data[0].shape=(1,)\n",
      "val/per_class/Recall_distributions: metric_data[0].shape=(1,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/jacob/GitHub/lightning-hydra-classifiers/lightning_hydra_classifiers/utils/plot_utils.py:73: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, ax = plt.subplots(1,1, figsize=figsize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val/confusion_matrix/royal-forest-3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 1250: val_acc reached 0.63780 (best 0.63780), saving model to \"/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor_+_except_bn-PNAS-19_classes-res_512-bsz_16-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/epoch=09-val_loss=0.910-val_acc=0.638.ckpt\" as top 2\n",
      "Saving latest checkpoint...\n",
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/pytorch_lightning/trainer/deprecated_api.py:32: LightningDeprecationWarning: `Trainer.train_loop` has been renamed to `Trainer.fit_loop` and will be removed in v1.6.\n",
      "  rank_zero_deprecation(\n",
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.teardown has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.teardown.\n",
      "  rank_zero_deprecation(\n",
      "Global seed set to 98\n",
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:679: LightningDeprecationWarning: `trainer.test(test_dataloaders)` is deprecated in v1.4 and will be removed in v1.6. Use `trainer.test(dataloaders)` instead.\n",
      "  rank_zero_deprecation(\n",
      "/media/data/conda/jrose3/envs/sequoia/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.\n",
      "  rank_zero_deprecation(\n",
      "2021-10-18 11:39:36,201 lightning_hydra_classifiers.experiments.multitask.datamodules INFO     Task_1: datamodule.setup(stage=test)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set current model training strategy to: feature_extractor_+_except_bn\n",
      "self.num_classes=19\n",
      "Best checkpoint saved to: /media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor_+_except_bn-PNAS-19_classes-res_512-bsz_16-resnet50-pretrained_True-pool_avg/replicate_1/results/checkpoints/epoch=09-val_loss=0.910-val_acc=0.638.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac914e6ea394439fb7d91e3058ab1170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-18 11:39:42,636 lightning_hydra_classifiers.experiments.multitask.datamodules INFO     Task_1: datamodule.setup(stage=test)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ea17b19493446b4b1ace4319fe901b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED TRIAL RESULTS] Location: /media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/feature_extractor_+_except_bn-PNAS-19_classes-res_512-bsz_16-resnet50-pretrained_True-pool_avg/replicate_1/results/results.yaml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'test_acc'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3675265908241272</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'val_acc'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6377972364425659</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'ckpt_path'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">_logs/avg/feature_extractor_+_except_bn-PNAS-19_classes-res_512-bsz_16-resnet50-pretrained_Tr</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ue-pool_avg/replicate_1/results/checkpoints/epoch=09-val_loss=0.910-val_acc=0.638.ckpt'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_config'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'backbone'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'backbone_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'resnet50'</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'backbone_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'resnet50'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'pretrained'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'num_classes'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'pool_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'avg'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'head_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'linear'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'hidden_size'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'dropout_p'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'lr'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.025118864315095822</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'backbone_lr_mult'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'finetuning_strategy'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'feature_extractor_+_except_bn'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'weight_decay'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'seed'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">98</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'data_config'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'_target_'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'lightning_hydra_classifiers.experiments.multitask.datamodules.MultiTaskDataModule'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'image_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'image_buffer_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'batch_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'num_workers'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'pin_memory'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'dataset_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Extant-PNAS_to_PNAS'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'experiment'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'source_root_dir'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/media/data_cifs/projects/prj_fossils/users/jacob/experiments</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">/July2021-Nov2021/csv_datasets/leavesdb-v1_0'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'experiment_root_dir'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/media/data_cifs/projects/prj_fossils/users/jacob/experim</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ents/July2021-Nov2021/csv_datasets/experimental_datasets'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'experiment_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Extant-to-PNAS-512-transfer_benchmark'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'seed'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">96857</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'task_0'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Extant_Leaves_family_10_512_minus_PNAS_family_100_512'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'val_split'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'test_split'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'task_1'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'PNAS_family_100_512_minus_Extant_Leaves_family_10_512'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'val_split'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'test_split'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'test_acc'\u001b[0m: \u001b[1;36m0.3675265908241272\u001b[0m,\n",
       "    \u001b[32m'val_acc'\u001b[0m: \u001b[1;36m0.6377972364425659\u001b[0m,\n",
       "    \u001b[32m'ckpt_path'\u001b[0m: \u001b[32m'/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test\u001b[0m\n",
       "\u001b[32m_logs/avg/feature_extractor_+_except_bn-PNAS-19_classes-res_512-bsz_16-resnet50-pretrained_Tr\u001b[0m\n",
       "\u001b[32mue-pool_avg/replicate_1/results/checkpoints/\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m09\u001b[0m\u001b[32m-\u001b[0m\u001b[32mval_loss\u001b[0m\u001b[32m=\u001b[0m\u001b[32m0\u001b[0m\u001b[32m.910-\u001b[0m\u001b[32mval_acc\u001b[0m\u001b[32m=\u001b[0m\u001b[32m0\u001b[0m\u001b[32m.638.ckpt'\u001b[0m,\n",
       "    \u001b[32m'model_config'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'backbone'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'backbone_name'\u001b[0m: \u001b[32m'resnet50'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'backbone_name'\u001b[0m: \u001b[32m'resnet50'\u001b[0m,\n",
       "        \u001b[32m'pretrained'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "        \u001b[32m'num_classes'\u001b[0m: \u001b[1;36m19\u001b[0m,\n",
       "        \u001b[32m'pool_type'\u001b[0m: \u001b[32m'avg'\u001b[0m,\n",
       "        \u001b[32m'head_type'\u001b[0m: \u001b[32m'linear'\u001b[0m,\n",
       "        \u001b[32m'hidden_size'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'dropout_p'\u001b[0m: \u001b[1;36m0.3\u001b[0m,\n",
       "        \u001b[32m'lr'\u001b[0m: \u001b[1;36m0.025118864315095822\u001b[0m,\n",
       "        \u001b[32m'backbone_lr_mult'\u001b[0m: \u001b[1;36m0.1\u001b[0m,\n",
       "        \u001b[32m'finetuning_strategy'\u001b[0m: \u001b[32m'feature_extractor_+_except_bn'\u001b[0m,\n",
       "        \u001b[32m'weight_decay'\u001b[0m: \u001b[1;36m0.01\u001b[0m,\n",
       "        \u001b[32m'seed'\u001b[0m: \u001b[1;36m98\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'data_config'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'_target_'\u001b[0m: \n",
       "\u001b[32m'lightning_hydra_classifiers.experiments.multitask.datamodules.MultiTaskDataModule'\u001b[0m,\n",
       "        \u001b[32m'image_size'\u001b[0m: \u001b[1;36m512\u001b[0m,\n",
       "        \u001b[32m'image_buffer_size'\u001b[0m: \u001b[1;36m32\u001b[0m,\n",
       "        \u001b[32m'batch_size'\u001b[0m: \u001b[1;36m16\u001b[0m,\n",
       "        \u001b[32m'num_workers'\u001b[0m: \u001b[1;36m4\u001b[0m,\n",
       "        \u001b[32m'pin_memory'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "        \u001b[32m'dataset_name'\u001b[0m: \u001b[32m'Extant-PNAS_to_PNAS'\u001b[0m,\n",
       "        \u001b[32m'experiment'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'source_root_dir'\u001b[0m: \u001b[32m'/media/data_cifs/projects/prj_fossils/users/jacob/experiments\u001b[0m\n",
       "\u001b[32m/July2021-Nov2021/csv_datasets/leavesdb-v1_0'\u001b[0m,\n",
       "            \u001b[32m'experiment_root_dir'\u001b[0m: \u001b[32m'/media/data_cifs/projects/prj_fossils/users/jacob/experim\u001b[0m\n",
       "\u001b[32ments/July2021-Nov2021/csv_datasets/experimental_datasets'\u001b[0m,\n",
       "            \u001b[32m'experiment_name'\u001b[0m: \u001b[32m'Extant-to-PNAS-512-transfer_benchmark'\u001b[0m,\n",
       "            \u001b[32m'seed'\u001b[0m: \u001b[1;36m96857\u001b[0m,\n",
       "            \u001b[32m'task_0'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'name'\u001b[0m: \u001b[32m'Extant_Leaves_family_10_512_minus_PNAS_family_100_512'\u001b[0m,\n",
       "                \u001b[32m'val_split'\u001b[0m: \u001b[1;36m0.2\u001b[0m,\n",
       "                \u001b[32m'test_split'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'task_1'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'name'\u001b[0m: \u001b[32m'PNAS_family_100_512_minus_Extant_Leaves_family_10_512'\u001b[0m,\n",
       "                \u001b[32m'val_split'\u001b[0m: \u001b[1;36m0.2\u001b[0m,\n",
       "                \u001b[32m'test_split'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL FINISHED!!! RESULTS:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'feature_extractor'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'test_acc'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2617359757423401</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'val_acc'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4907832741737366</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'ckpt_path'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">test_logs/avg/feature_extractor-PNAS-19_classes-res_512-bsz_32-resnet50-pretrained_True-pool_</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">avg/replicate_1/results/checkpoints/epoch=06-val_loss=1.956-val_acc=0.491.ckpt'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model_config'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'backbone'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'backbone_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'resnet50'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'backbone_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'resnet50'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'pretrained'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'num_classes'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'pool_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'avg'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'head_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'linear'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'hidden_size'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'dropout_p'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'lr'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.036307805477010104</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'backbone_lr_mult'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'finetuning_strategy'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'feature_extractor'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'weight_decay'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'seed'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">98</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'data_config'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'_target_'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'lightning_hydra_classifiers.experiments.multitask.datamodules.MultiTaskDataModule'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'image_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'image_buffer_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'batch_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'num_workers'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'pin_memory'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'dataset_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Extant-PNAS_to_PNAS'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'experiment'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'source_root_dir'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/media/data_cifs/projects/prj_fossils/users/jacob/experim</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ents/July2021-Nov2021/csv_datasets/leavesdb-v1_0'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'experiment_root_dir'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/media/data_cifs/projects/prj_fossils/users/jacob/exp</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">eriments/July2021-Nov2021/csv_datasets/experimental_datasets'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'experiment_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Extant-to-PNAS-512-transfer_benchmark'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'seed'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">96857</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'task_0'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Extant_Leaves_family_10_512_minus_PNAS_family_100_512'</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'val_split'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'test_split'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "                <span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'task_1'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'PNAS_family_100_512_minus_Extant_Leaves_family_10_512'</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'val_split'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'test_split'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "                <span style=\"font-weight: bold\">}</span>\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'feature_extractor_+_bn.eval()'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'test_acc'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2662663757801056</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'val_acc'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4947287440299988</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'ckpt_path'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">test_logs/avg/feature_extractor_+_bn.eval()-PNAS-19_classes-res_512-bsz_32-resnet50-pretraine</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">d_True-pool_avg/replicate_1/results/checkpoints/epoch=04-val_loss=1.585-val_acc=0.495.ckpt'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model_config'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'backbone'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'backbone_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'resnet50'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'backbone_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'resnet50'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'pretrained'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'num_classes'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'pool_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'avg'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'head_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'linear'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'hidden_size'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'dropout_p'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'lr'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.036307805477010104</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'backbone_lr_mult'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'finetuning_strategy'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'feature_extractor_+_bn.eval()'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'weight_decay'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'seed'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">98</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'data_config'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'_target_'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'lightning_hydra_classifiers.experiments.multitask.datamodules.MultiTaskDataModule'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'image_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'image_buffer_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'batch_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'num_workers'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'pin_memory'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'dataset_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Extant-PNAS_to_PNAS'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'experiment'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'source_root_dir'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/media/data_cifs/projects/prj_fossils/users/jacob/experim</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ents/July2021-Nov2021/csv_datasets/leavesdb-v1_0'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'experiment_root_dir'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/media/data_cifs/projects/prj_fossils/users/jacob/exp</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">eriments/July2021-Nov2021/csv_datasets/experimental_datasets'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'experiment_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Extant-to-PNAS-512-transfer_benchmark'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'seed'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">96857</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'task_0'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Extant_Leaves_family_10_512_minus_PNAS_family_100_512'</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'val_split'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'test_split'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "                <span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'task_1'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'PNAS_family_100_512_minus_Extant_Leaves_family_10_512'</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'val_split'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'test_split'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "                <span style=\"font-weight: bold\">}</span>\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'feature_extractor_+_except_bn'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'test_acc'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3675265908241272</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'val_acc'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6377972364425659</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'ckpt_path'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">test_logs/avg/feature_extractor_+_except_bn-PNAS-19_classes-res_512-bsz_16-resnet50-pretraine</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">d_True-pool_avg/replicate_1/results/checkpoints/epoch=09-val_loss=0.910-val_acc=0.638.ckpt'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model_config'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'backbone'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'backbone_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'resnet50'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'backbone_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'resnet50'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'pretrained'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'num_classes'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'pool_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'avg'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'head_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'linear'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'hidden_size'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'dropout_p'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'lr'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.025118864315095822</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'backbone_lr_mult'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'finetuning_strategy'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'feature_extractor_+_except_bn'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'weight_decay'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'seed'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">98</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'data_config'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'_target_'</span>: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'lightning_hydra_classifiers.experiments.multitask.datamodules.MultiTaskDataModule'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'image_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'image_buffer_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'batch_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'num_workers'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'pin_memory'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'dataset_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Extant-PNAS_to_PNAS'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'experiment'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'source_root_dir'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/media/data_cifs/projects/prj_fossils/users/jacob/experim</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ents/July2021-Nov2021/csv_datasets/leavesdb-v1_0'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'experiment_root_dir'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/media/data_cifs/projects/prj_fossils/users/jacob/exp</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">eriments/July2021-Nov2021/csv_datasets/experimental_datasets'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'experiment_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Extant-to-PNAS-512-transfer_benchmark'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'seed'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">96857</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'task_0'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Extant_Leaves_family_10_512_minus_PNAS_family_100_512'</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'val_split'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'test_split'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "                <span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'task_1'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'PNAS_family_100_512_minus_Extant_Leaves_family_10_512'</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'val_split'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'test_split'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "                <span style=\"font-weight: bold\">}</span>\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'feature_extractor'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'test_acc'\u001b[0m: \u001b[1;36m0.2617359757423401\u001b[0m,\n",
       "        \u001b[32m'val_acc'\u001b[0m: \u001b[1;36m0.4907832741737366\u001b[0m,\n",
       "        \u001b[32m'ckpt_path'\u001b[0m: \u001b[32m'/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_\u001b[0m\n",
       "\u001b[32mtest_logs/avg/feature_extractor-PNAS-19_classes-res_512-bsz_32-resnet50-pretrained_True-pool_\u001b[0m\n",
       "\u001b[32mavg/replicate_1/results/checkpoints/\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m06\u001b[0m\u001b[32m-\u001b[0m\u001b[32mval_loss\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1\u001b[0m\u001b[32m.956-\u001b[0m\u001b[32mval_acc\u001b[0m\u001b[32m=\u001b[0m\u001b[32m0\u001b[0m\u001b[32m.491.ckpt'\u001b[0m,\n",
       "        \u001b[32m'model_config'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'backbone'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'backbone_name'\u001b[0m: \u001b[32m'resnet50'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'backbone_name'\u001b[0m: \u001b[32m'resnet50'\u001b[0m,\n",
       "            \u001b[32m'pretrained'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "            \u001b[32m'num_classes'\u001b[0m: \u001b[1;36m19\u001b[0m,\n",
       "            \u001b[32m'pool_type'\u001b[0m: \u001b[32m'avg'\u001b[0m,\n",
       "            \u001b[32m'head_type'\u001b[0m: \u001b[32m'linear'\u001b[0m,\n",
       "            \u001b[32m'hidden_size'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[32m'dropout_p'\u001b[0m: \u001b[1;36m0.3\u001b[0m,\n",
       "            \u001b[32m'lr'\u001b[0m: \u001b[1;36m0.036307805477010104\u001b[0m,\n",
       "            \u001b[32m'backbone_lr_mult'\u001b[0m: \u001b[1;36m0.1\u001b[0m,\n",
       "            \u001b[32m'finetuning_strategy'\u001b[0m: \u001b[32m'feature_extractor'\u001b[0m,\n",
       "            \u001b[32m'weight_decay'\u001b[0m: \u001b[1;36m0.01\u001b[0m,\n",
       "            \u001b[32m'seed'\u001b[0m: \u001b[1;36m98\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'data_config'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'_target_'\u001b[0m: \n",
       "\u001b[32m'lightning_hydra_classifiers.experiments.multitask.datamodules.MultiTaskDataModule'\u001b[0m,\n",
       "            \u001b[32m'image_size'\u001b[0m: \u001b[1;36m512\u001b[0m,\n",
       "            \u001b[32m'image_buffer_size'\u001b[0m: \u001b[1;36m32\u001b[0m,\n",
       "            \u001b[32m'batch_size'\u001b[0m: \u001b[1;36m32\u001b[0m,\n",
       "            \u001b[32m'num_workers'\u001b[0m: \u001b[1;36m4\u001b[0m,\n",
       "            \u001b[32m'pin_memory'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "            \u001b[32m'dataset_name'\u001b[0m: \u001b[32m'Extant-PNAS_to_PNAS'\u001b[0m,\n",
       "            \u001b[32m'experiment'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'source_root_dir'\u001b[0m: \u001b[32m'/media/data_cifs/projects/prj_fossils/users/jacob/experim\u001b[0m\n",
       "\u001b[32ments/July2021-Nov2021/csv_datasets/leavesdb-v1_0'\u001b[0m,\n",
       "                \u001b[32m'experiment_root_dir'\u001b[0m: \u001b[32m'/media/data_cifs/projects/prj_fossils/users/jacob/exp\u001b[0m\n",
       "\u001b[32meriments/July2021-Nov2021/csv_datasets/experimental_datasets'\u001b[0m,\n",
       "                \u001b[32m'experiment_name'\u001b[0m: \u001b[32m'Extant-to-PNAS-512-transfer_benchmark'\u001b[0m,\n",
       "                \u001b[32m'seed'\u001b[0m: \u001b[1;36m96857\u001b[0m,\n",
       "                \u001b[32m'task_0'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                    \u001b[32m'name'\u001b[0m: \u001b[32m'Extant_Leaves_family_10_512_minus_PNAS_family_100_512'\u001b[0m,\n",
       "                    \u001b[32m'val_split'\u001b[0m: \u001b[1;36m0.2\u001b[0m,\n",
       "                    \u001b[32m'test_split'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "                \u001b[1m}\u001b[0m,\n",
       "                \u001b[32m'task_1'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                    \u001b[32m'name'\u001b[0m: \u001b[32m'PNAS_family_100_512_minus_Extant_Leaves_family_10_512'\u001b[0m,\n",
       "                    \u001b[32m'val_split'\u001b[0m: \u001b[1;36m0.2\u001b[0m,\n",
       "                    \u001b[32m'test_split'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "                \u001b[1m}\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'feature_extractor_+_bn.eval\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'test_acc'\u001b[0m: \u001b[1;36m0.2662663757801056\u001b[0m,\n",
       "        \u001b[32m'val_acc'\u001b[0m: \u001b[1;36m0.4947287440299988\u001b[0m,\n",
       "        \u001b[32m'ckpt_path'\u001b[0m: \u001b[32m'/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_\u001b[0m\n",
       "\u001b[32mtest_logs/avg/feature_extractor_+_bn.eval\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m-PNAS-19_classes-res_512-bsz_32-resnet50-pretraine\u001b[0m\n",
       "\u001b[32md_True-pool_avg/replicate_1/results/checkpoints/\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m04\u001b[0m\u001b[32m-\u001b[0m\u001b[32mval_loss\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1\u001b[0m\u001b[32m.585-\u001b[0m\u001b[32mval_acc\u001b[0m\u001b[32m=\u001b[0m\u001b[32m0\u001b[0m\u001b[32m.495.ckpt'\u001b[0m,\n",
       "        \u001b[32m'model_config'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'backbone'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'backbone_name'\u001b[0m: \u001b[32m'resnet50'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'backbone_name'\u001b[0m: \u001b[32m'resnet50'\u001b[0m,\n",
       "            \u001b[32m'pretrained'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "            \u001b[32m'num_classes'\u001b[0m: \u001b[1;36m19\u001b[0m,\n",
       "            \u001b[32m'pool_type'\u001b[0m: \u001b[32m'avg'\u001b[0m,\n",
       "            \u001b[32m'head_type'\u001b[0m: \u001b[32m'linear'\u001b[0m,\n",
       "            \u001b[32m'hidden_size'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[32m'dropout_p'\u001b[0m: \u001b[1;36m0.3\u001b[0m,\n",
       "            \u001b[32m'lr'\u001b[0m: \u001b[1;36m0.036307805477010104\u001b[0m,\n",
       "            \u001b[32m'backbone_lr_mult'\u001b[0m: \u001b[1;36m0.1\u001b[0m,\n",
       "            \u001b[32m'finetuning_strategy'\u001b[0m: \u001b[32m'feature_extractor_+_bn.eval\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\n",
       "            \u001b[32m'weight_decay'\u001b[0m: \u001b[1;36m0.01\u001b[0m,\n",
       "            \u001b[32m'seed'\u001b[0m: \u001b[1;36m98\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'data_config'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'_target_'\u001b[0m: \n",
       "\u001b[32m'lightning_hydra_classifiers.experiments.multitask.datamodules.MultiTaskDataModule'\u001b[0m,\n",
       "            \u001b[32m'image_size'\u001b[0m: \u001b[1;36m512\u001b[0m,\n",
       "            \u001b[32m'image_buffer_size'\u001b[0m: \u001b[1;36m32\u001b[0m,\n",
       "            \u001b[32m'batch_size'\u001b[0m: \u001b[1;36m32\u001b[0m,\n",
       "            \u001b[32m'num_workers'\u001b[0m: \u001b[1;36m4\u001b[0m,\n",
       "            \u001b[32m'pin_memory'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "            \u001b[32m'dataset_name'\u001b[0m: \u001b[32m'Extant-PNAS_to_PNAS'\u001b[0m,\n",
       "            \u001b[32m'experiment'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'source_root_dir'\u001b[0m: \u001b[32m'/media/data_cifs/projects/prj_fossils/users/jacob/experim\u001b[0m\n",
       "\u001b[32ments/July2021-Nov2021/csv_datasets/leavesdb-v1_0'\u001b[0m,\n",
       "                \u001b[32m'experiment_root_dir'\u001b[0m: \u001b[32m'/media/data_cifs/projects/prj_fossils/users/jacob/exp\u001b[0m\n",
       "\u001b[32meriments/July2021-Nov2021/csv_datasets/experimental_datasets'\u001b[0m,\n",
       "                \u001b[32m'experiment_name'\u001b[0m: \u001b[32m'Extant-to-PNAS-512-transfer_benchmark'\u001b[0m,\n",
       "                \u001b[32m'seed'\u001b[0m: \u001b[1;36m96857\u001b[0m,\n",
       "                \u001b[32m'task_0'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                    \u001b[32m'name'\u001b[0m: \u001b[32m'Extant_Leaves_family_10_512_minus_PNAS_family_100_512'\u001b[0m,\n",
       "                    \u001b[32m'val_split'\u001b[0m: \u001b[1;36m0.2\u001b[0m,\n",
       "                    \u001b[32m'test_split'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "                \u001b[1m}\u001b[0m,\n",
       "                \u001b[32m'task_1'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                    \u001b[32m'name'\u001b[0m: \u001b[32m'PNAS_family_100_512_minus_Extant_Leaves_family_10_512'\u001b[0m,\n",
       "                    \u001b[32m'val_split'\u001b[0m: \u001b[1;36m0.2\u001b[0m,\n",
       "                    \u001b[32m'test_split'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "                \u001b[1m}\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'feature_extractor_+_except_bn'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'test_acc'\u001b[0m: \u001b[1;36m0.3675265908241272\u001b[0m,\n",
       "        \u001b[32m'val_acc'\u001b[0m: \u001b[1;36m0.6377972364425659\u001b[0m,\n",
       "        \u001b[32m'ckpt_path'\u001b[0m: \u001b[32m'/media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_\u001b[0m\n",
       "\u001b[32mtest_logs/avg/feature_extractor_+_except_bn-PNAS-19_classes-res_512-bsz_16-resnet50-pretraine\u001b[0m\n",
       "\u001b[32md_True-pool_avg/replicate_1/results/checkpoints/\u001b[0m\u001b[32mepoch\u001b[0m\u001b[32m=\u001b[0m\u001b[32m09\u001b[0m\u001b[32m-\u001b[0m\u001b[32mval_loss\u001b[0m\u001b[32m=\u001b[0m\u001b[32m0\u001b[0m\u001b[32m.910-\u001b[0m\u001b[32mval_acc\u001b[0m\u001b[32m=\u001b[0m\u001b[32m0\u001b[0m\u001b[32m.638.ckpt'\u001b[0m,\n",
       "        \u001b[32m'model_config'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'backbone'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'backbone_name'\u001b[0m: \u001b[32m'resnet50'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'backbone_name'\u001b[0m: \u001b[32m'resnet50'\u001b[0m,\n",
       "            \u001b[32m'pretrained'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "            \u001b[32m'num_classes'\u001b[0m: \u001b[1;36m19\u001b[0m,\n",
       "            \u001b[32m'pool_type'\u001b[0m: \u001b[32m'avg'\u001b[0m,\n",
       "            \u001b[32m'head_type'\u001b[0m: \u001b[32m'linear'\u001b[0m,\n",
       "            \u001b[32m'hidden_size'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[32m'dropout_p'\u001b[0m: \u001b[1;36m0.3\u001b[0m,\n",
       "            \u001b[32m'lr'\u001b[0m: \u001b[1;36m0.025118864315095822\u001b[0m,\n",
       "            \u001b[32m'backbone_lr_mult'\u001b[0m: \u001b[1;36m0.1\u001b[0m,\n",
       "            \u001b[32m'finetuning_strategy'\u001b[0m: \u001b[32m'feature_extractor_+_except_bn'\u001b[0m,\n",
       "            \u001b[32m'weight_decay'\u001b[0m: \u001b[1;36m0.01\u001b[0m,\n",
       "            \u001b[32m'seed'\u001b[0m: \u001b[1;36m98\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'data_config'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'_target_'\u001b[0m: \n",
       "\u001b[32m'lightning_hydra_classifiers.experiments.multitask.datamodules.MultiTaskDataModule'\u001b[0m,\n",
       "            \u001b[32m'image_size'\u001b[0m: \u001b[1;36m512\u001b[0m,\n",
       "            \u001b[32m'image_buffer_size'\u001b[0m: \u001b[1;36m32\u001b[0m,\n",
       "            \u001b[32m'batch_size'\u001b[0m: \u001b[1;36m16\u001b[0m,\n",
       "            \u001b[32m'num_workers'\u001b[0m: \u001b[1;36m4\u001b[0m,\n",
       "            \u001b[32m'pin_memory'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "            \u001b[32m'dataset_name'\u001b[0m: \u001b[32m'Extant-PNAS_to_PNAS'\u001b[0m,\n",
       "            \u001b[32m'experiment'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'source_root_dir'\u001b[0m: \u001b[32m'/media/data_cifs/projects/prj_fossils/users/jacob/experim\u001b[0m\n",
       "\u001b[32ments/July2021-Nov2021/csv_datasets/leavesdb-v1_0'\u001b[0m,\n",
       "                \u001b[32m'experiment_root_dir'\u001b[0m: \u001b[32m'/media/data_cifs/projects/prj_fossils/users/jacob/exp\u001b[0m\n",
       "\u001b[32meriments/July2021-Nov2021/csv_datasets/experimental_datasets'\u001b[0m,\n",
       "                \u001b[32m'experiment_name'\u001b[0m: \u001b[32m'Extant-to-PNAS-512-transfer_benchmark'\u001b[0m,\n",
       "                \u001b[32m'seed'\u001b[0m: \u001b[1;36m96857\u001b[0m,\n",
       "                \u001b[32m'task_0'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                    \u001b[32m'name'\u001b[0m: \u001b[32m'Extant_Leaves_family_10_512_minus_PNAS_family_100_512'\u001b[0m,\n",
       "                    \u001b[32m'val_split'\u001b[0m: \u001b[1;36m0.2\u001b[0m,\n",
       "                    \u001b[32m'test_split'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "                \u001b[1m}\u001b[0m,\n",
       "                \u001b[32m'task_1'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                    \u001b[32m'name'\u001b[0m: \u001b[32m'PNAS_family_100_512_minus_Extant_Leaves_family_10_512'\u001b[0m,\n",
       "                    \u001b[32m'val_split'\u001b[0m: \u001b[1;36m0.2\u001b[0m,\n",
       "                    \u001b[32m'test_split'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "                \u001b[1m}\u001b[0m\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35min 40s, sys: 7min 30s, total: 43min 10s\n",
      "Wall time: 50min 13s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 792x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 792x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 792x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 792x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 792x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 792x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 792x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 792x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 792x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 792x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 792x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 792x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 792x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 792x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 792x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 792x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 792x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 792x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 792x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 792x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 792x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 792x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 792x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 792x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 792x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 792x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 792x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 792x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 792x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 792x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "valid_strategies = (\"feature_extractor\",\n",
    "                    \"feature_extractor_+_bn.eval()\",\n",
    "                    \"feature_extractor_+_except_bn\")\n",
    "pool_types = (\"avg\", \"avgdrop\", \"avgmax\", \"max\", \"avgmaxdrop\")\n",
    "\n",
    "# finetuning_strategy=\"feature_extractor\"\n",
    "# finetuning_strategy=\"feature_extractor_+_bn.eval()\"\n",
    "\n",
    "# pool_type='avgdrop'\n",
    "# pool_type='avgmaxdrop'\n",
    "pool_type=\"avg\"\n",
    "dropout_p = 0.3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for strategy in valid_strategies:\n",
    "\n",
    "    print(f\"BEGINNING STRATEGY: {strategy}\")\n",
    "    overrides = ['model/backbone=resnet50',\n",
    "                 \"data=extant_to_pnas\",\n",
    "                 \"trainer.max_epochs=10\",\n",
    "                 \"trainer.auto_lr_find=true\",\n",
    "                 \"trainer.precision=16\",\n",
    "                 \"trainer.gpus=[7]\",\n",
    "                 \"trainer.resume_from_checkpoint=null\",\n",
    "                 \"logger.wandb.project=bn_global_pool_trials\"]\n",
    "    if strategy in [\"feature_extractor_+_except_bn\"]:\n",
    "        overrides.append(\"data.batch_size=16\")\n",
    "    else:\n",
    "        overrides.append(\"data.batch_size=32\")\n",
    "\n",
    "\n",
    "    config, datamodule = get_config_and_load_data(overrides = overrides,\n",
    "                                                  task_id=1,\n",
    "                                                  pool_type=pool_type,\n",
    "                                                  finetuning_strategy=strategy, #\"feature_extractor_+_bn.eval()\",\n",
    "                                                  lr=2e-03,\n",
    "                                                  dropout_p=dropout_p)#,\n",
    "#                                                   max_epochs=config.trainer.max_epochs)\n",
    "    ckpt_paths = os.listdir(os.path.join(config.checkpoint_dir))\n",
    "    if len(ckpt_paths) and os.path.exists(ckpt_paths[-1]):\n",
    "        print(f\"Found {ckpt_paths[-1]}\")\n",
    "        config.resume_from_checkpoint = ckpt_paths[-1]\n",
    "\n",
    "\n",
    "    model, results = test_model_freeze_strategy(config, datamodule)\n",
    "    model.cpu()\n",
    "    del model\n",
    "\n",
    "    results['model_config'] = OmegaConf.to_container(config.model, resolve=True)\n",
    "    results['data_config'] = OmegaConf.to_container(config.data, resolve=True)\n",
    "    \n",
    "    ETL.config2yaml(results, os.path.join(config.results_dir, \"results.yaml\"))\n",
    "    print(f\"[SAVED TRIAL RESULTS] Location: {os.path.join(config.results_dir, 'results.yaml')}\")\n",
    "    pp(results)\n",
    "    \n",
    "    all_results[strategy] = results\n",
    "\n",
    "print(f\"ALL FINISHED!!! RESULTS:\")\n",
    "pp(all_results)\n",
    "\n",
    "\n",
    "ETL.config2yaml(all_results, os.path.join(config.root_dir, \"results.yaml\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "### plot strategy results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strategy</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>feature_extractor</td>\n",
       "      <td>0.490783</td>\n",
       "      <td>0.261736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feature_extractor_+_bn.eval()</td>\n",
       "      <td>0.494729</td>\n",
       "      <td>0.266266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>feature_extractor_+_except_bn</td>\n",
       "      <td>0.637797</td>\n",
       "      <td>0.367527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        strategy   val_acc  test_acc\n",
       "0              feature_extractor  0.490783  0.261736\n",
       "1  feature_extractor_+_bn.eval()  0.494729  0.266266\n",
       "2  feature_extractor_+_except_bn  0.637797  0.367527"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 3 artists>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 3 artists>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'finetuning strategy')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Macro avg acc')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x7fa8f09c0d00>,\n",
       "  <matplotlib.axis.XTick at 0x7fa8f09c0040>,\n",
       "  <matplotlib.axis.XTick at 0x7fa8e55e9eb0>],\n",
       " [Text(0, 0, 'feature_extractor'),\n",
       "  Text(0, 0, 'feature_extractor_+_bn.eval()'),\n",
       "  Text(0, 0, 'feature_extractor_+_except_bn')])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, 'resnet50 with global_pool=avg.\\n Classifier head trained on PNAS for <=10 epochs')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results saved to /media/data/jacob/GitHub/lightning-hydra-classifiers/notebooks/bn_unit_test_logs/avg/final_results_plot.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "strategies_x = []\n",
    "val_accs = []\n",
    "test_accs = []\n",
    "for k,v in all_results.items():\n",
    "    strategies_x.append(k)\n",
    "    try:\n",
    "        val_accs.append(v['val_acc'])\n",
    "        test_accs.append(v['test_acc'])\n",
    "    except:\n",
    "        val_accs.append(v['val'])\n",
    "        test_accs.append(v['test'])\n",
    "        \n",
    "        \n",
    "        \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame({\"strategy\":strategies_x,\n",
    "                           \"val_acc\":val_accs,\n",
    "                           \"test_acc\":test_accs})\n",
    "results_df\n",
    "\n",
    "barWidth = 0.25\n",
    "\n",
    "r1 = np.arange(len(strategies_x))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "r3 = [x + barWidth for x in r2]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.bar(r1, val_accs, color='#7f6d5f', width=barWidth, edgecolor='white', label='val')\n",
    "plt.bar(r2, test_accs, color='#557f2d', width=barWidth, edgecolor='white', label='test')\n",
    "\n",
    " \n",
    "# Add xticks on the middle of the group bars\n",
    "plt.xlabel('finetuning strategy', fontweight='bold')\n",
    "plt.ylabel(\"Macro avg acc\")\n",
    "plt.xticks([r + barWidth for r in range(len(strategies_x))], strategies_x, rotation=10)\n",
    "plt.suptitle(f\"{config.model.backbone_name} with global_pool={config.model.pool_type}.\" + \"\\n Classifier head trained on PNAS for <=10 epochs\")\n",
    "plt.tight_layout(rect=[0.0, 0.05, 1.0, 0.95])\n",
    "plt.savefig(os.path.join(config.root_dir, \"final_results_plot.png\"))\n",
    "print(f\"Final results saved to\", os.path.join(config.root_dir, \"final_results_plot.png\"))\n",
    "# sns.barplot(data=results_df, x='strategy', y='val_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Next: Add specific tests for different freeze strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "## Training script development\n",
    "(10-17-21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial5/Inception_ResNet_DenseNet.html\n",
    "\n",
    "def train_model(model_name, save_name=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        model_name - Name of the model you want to run. Is used to look up the class in \"model_dict\"\n",
    "        save_name (optional) - If specified, this name will be used for creating the checkpoint and logging directory.\n",
    "    \"\"\"\n",
    "    if save_name is None:\n",
    "        save_name = model_name\n",
    "\n",
    "    # Create a PyTorch Lightning trainer with the generation callback\n",
    "    trainer = pl.Trainer(default_root_dir=os.path.join(CHECKPOINT_PATH, save_name),                          # Where to save models\n",
    "                         gpus=1 if str(device)==\"cuda:0\" else 0,                                             # We run on a single GPU (if possible)\n",
    "                         max_epochs=180,                                                                     # How many epochs to train for if no patience is set\n",
    "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\"),  # Save the best checkpoint based on the maximum val_acc recorded. Saves only weights and not optimizer\n",
    "                                    LearningRateMonitor(\"epoch\")],                                           # Log learning rate every epoch\n",
    "                         progress_bar_refresh_rate=1)                                                        # In case your notebook crashes due to the progress bar, consider increasing the refresh rate\n",
    "    trainer.logger._log_graph = True         # If True, we plot the computation graph in tensorboard\n",
    "    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    pretrained_filename = os.path.join(CHECKPOINT_PATH, save_name + \".ckpt\")\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(f\"Found pretrained model at {pretrained_filename}, loading...\")\n",
    "        model = CIFARModule.load_from_checkpoint(pretrained_filename) # Automatically loads the model with the saved hyperparameters\n",
    "    else:\n",
    "        pl.seed_everything(42) # To be reproducable\n",
    "        model = CIFARModule(model_name=model_name, **kwargs)\n",
    "        trainer.fit(model, train_loader, val_loader)\n",
    "        model = CIFARModule.load_from_checkpoint(trainer.checkpoint_callback.best_model_path) # Load best checkpoint after training\n",
    "\n",
    "    # Test best model on validation and test set\n",
    "    val_result = trainer.test(model, test_dataloaders=val_loader, verbose=False)\n",
    "    test_result = trainer.test(model, test_dataloaders=test_loader, verbose=False)\n",
    "    result = {\"test\": test_result[0][\"test_acc\"], \"val\": val_result[0][\"test_acc\"]}\n",
    "\n",
    "    return model, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class LightningClassifier(BaseLightningModule):\n",
    "#     def __init__(self,\n",
    "#                  backbone_name='gluon_seresnext50_32x4d',\n",
    "#                  pretrained: Union[bool, str]=True,\n",
    "#                  num_classes: int=1000,\n",
    "#                  pool_size: int=1,\n",
    "#                  pool_type: str='avg',\n",
    "#                  head_type: str='linear',\n",
    "#                  hidden_size: Optional[int]=512,\n",
    "#                  lr: float=2e-03,\n",
    "#                  weight_decay: float=0.01,\n",
    "#                  seed: int=None):\n",
    "#         super().__init__(seed=seed)\n",
    "#         self.save_hyperparameters()\n",
    "        \n",
    "#         self.model = build_model(backbone_name=backbone_name,\n",
    "#                                       pretrained=pretrained,\n",
    "#                                       num_classes=num_classes,\n",
    "#                                       pool_size=pool_size,\n",
    "#                                       pool_type=pool_type,\n",
    "#                                       head_type=head_type,\n",
    "#                                       hidden_size=hidden_size)\n",
    "    \n",
    "#         self.criterion = nn.CrossEntropyLoss()\n",
    "#         self.metrics = self.init_metrics(stage='all')\n",
    "    \n",
    "#     def forward(self,x):\n",
    "#         return self.model(x)\n",
    "    \n",
    "    \n",
    "#     def get_lr(self, group: str=None):\n",
    "#         if group is None:\n",
    "#             return self.hparams.lr\n",
    "#         if group == \"backbone\":\n",
    "#             return self.hparams.lr * 0.1\n",
    "#         if group == \"head\":\n",
    "#             return self.hparams.lr\n",
    "    \n",
    "#     def configure_optimizers(self):\n",
    "#         print(f\"self.hparams={self.hparams}\")\n",
    "#         self.optimizer = torch.optim.AdamW([{\"params\":self.model.backbone.parameters(), \"lr\":self.get_lr(\"backbone\"), \"weight_decay\": self.hparams.weight_decay},\n",
    "#                                             {\"params\":self.model.head.parameters(), \"lr\":self.get_lr(\"head\"), \"weight_decay\": self.hparams.weight_decay}])\n",
    "# #         self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=self.config.t_max, eta_min=self.config.min_lr)\n",
    "\n",
    "#         return {'optimizer': self.optimizer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BnFreeze(Callback):\n",
    "# source: https://github.com/fastai/fastai/blob/master/fastai/callback/training.py#L55\n",
    "#     run_after=TrainEvalCallback\n",
    "#     \"Freeze moving average statistics in all non-trainable batchnorm layers.\"\n",
    "#     def before_train(self):\n",
    "#         set_bn_eval(self.model)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "# Experiments\n",
    "\n",
    "For each architecture, 3 different experimental training methods will be evaluated\n",
    "\n",
    "Training methods:  \n",
    "1. Feature Extractor  \n",
    "2. Feature Extractor + set batchnorm to eval()  \n",
    "3. Freeze backbone except for all batchnorm layers  \n",
    "\n",
    "\n",
    "\n",
    "Baseline:  \n",
    "   * Architecture 1. simple pretrained backbone -> `avg_pool` -> linear_classifier  \n",
    "    \n",
    "Next Comparisons:  \n",
    "* Architecture 2. simple pretrained backbone -> `max_pool` -> linear_classifier\n",
    "* Architecture 3. simple pretrained backbone -> `avgmax_pool` -> linear_classifier  \n",
    "\n",
    "Later:  \n",
    "* Architecture 4. simple pretrained backbone -> `avgdrop_pool` -> linear_classifier  \n",
    "* Architecture 5. simple pretrained backbone -> `maxdrop_pool` -> linear_classifier  \n",
    "* Architecture 6. simple pretrained backbone -> `avgmaxdrop_pool` -> linear_classifier  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = build_model(backbone_name='gluon_seresnext50_32x4d',\n",
    "#                     pretrained=True,\n",
    "#                     num_classes=19,\n",
    "#                     pool_size=1,\n",
    "#                     pool_type='avgmax',\n",
    "#                     head_type='linear',\n",
    "#                     hidden_size=None)\n",
    "# from torchinfo import summary\n",
    "\n",
    "\n",
    "#left off here 11 pm\n",
    "\n",
    "# model = LightningClassifier(backbone_name='gluon_seresnext50_32x4d',\n",
    "#                             pretrained=True,\n",
    "#                             num_classes=19,\n",
    "#                             pool_size=1,\n",
    "#                             pool_type='avgmax',\n",
    "#                             head_type='linear',\n",
    "#                             hidden_size=None,\n",
    "#                             lr=2e-03,\n",
    "#                             weight_decay=0.01,\n",
    "#                             seed=98)\n",
    "\n",
    "# pp(list(model.get_batchnorm_modules()))\n",
    "# # pp(list(model.get_conv_modules()))\n",
    "# pp(list(model.get_linear_modules()))\n",
    "# # pp(list(model.get_conv_modules()))\n",
    "# pp(list(model.get_named_modules()))\n",
    "\n",
    "# model.freeze_backbone(freeze_bn=False)\n",
    "# model.freeze_backbone(freeze_bn=True)\n",
    "# summary(model.model)\n",
    "\n",
    "# print(f\"trainable: {len(list(model.get_trainable_parameters()))}\")\n",
    "# print(f\"non-trainable: {len(list(model.get_nontrainable_parameters()))}\")\n",
    "\n",
    "# bn = {n:p.requires_grad for n, p in model.get_named_parameters(\"bn\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini test: Wrap all model hooks & display + verify for each parameter group the proper status of module.training & weight_tensors.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable batchnorm modules:49\n",
      "nontrainable batchnorm modules:0\n",
      "batchnorm params with requires_grad=True: :0\n",
      "batchnorm params with requires_grad=False:98\n",
      "Total Trainable Params: 77,843\n",
      "Total non-Trainable Params: 25,510,896\n"
     ]
    }
   ],
   "source": [
    "model.freeze_backbone(freeze_bn=True) #False)\n",
    "# model.set_bn_eval()\n",
    "# summary(model.model)\n",
    "model.count_trainable_batchnorm_layers()\n",
    "count_parameters(model.model, verbose=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "### 2. Feature extractor + BN set to Eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable batchnorm modules:0\n",
      "nontrainable batchnorm modules:49\n",
      "batchnorm params with requires_grad=True: :0\n",
      "batchnorm params with requires_grad=False:98\n",
      "Total Trainable Params: 77,843\n",
      "Total non-Trainable Params: 25,510,896\n"
     ]
    }
   ],
   "source": [
    "model.freeze_backbone(freeze_bn=True)\n",
    "model.set_bn_eval(model)\n",
    "# summary(model.model)\n",
    "model.count_trainable_batchnorm_layers()\n",
    "count_parameters(model.model, verbose=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Freeze backbone except for BN layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable batchnorm modules:49\n",
      "nontrainable batchnorm modules:0\n",
      "batchnorm params with requires_grad=True: :98\n",
      "batchnorm params with requires_grad=False:0\n",
      "Total Trainable Params: 138,387\n",
      "Total non-Trainable Params: 25,450,352\n"
     ]
    }
   ],
   "source": [
    "# model.unfreeze(model.model)\n",
    "model.freeze_backbone(freeze_bn=False)\n",
    "\n",
    "model.unfreeze(model.model,\n",
    "               filter_pattern=\"bn\")\n",
    "# summary(model.model)\n",
    "model.count_trainable_batchnorm_layers()\n",
    "count_parameters(model.model, verbose=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load data, model, trainer, callbacks, logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning_hydra_classifiers.scripts.multitask.train import MultiTaskDataModule, LitMultiTaskModule, ImagePredictionLogger, train_task,  CIFAR10DataModule, run_multitask_test, load_data_and_model, load_data, resolve_config, configure_callbacks, configure_loggers, configure_trainer\n",
    "from lightning_hydra_classifiers.data.datasets.common import toPIL\n",
    "from lightning_hydra_classifiers.utils.etl_utils import ETL\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "\n",
    "# overrides = ['model/backbone=efficientnet_b3',\"data=extant_to_fossil\", \"trainer.max_epochs=2\", \"data.batch_size=16\", \"trainer.precision=16\"]\n",
    "overrides = ['model/backbone=resnet50',\"data=extant_to_pnas\", \"trainer.max_epochs=20\", \"data.batch_size=32\", \"trainer.precision=16\", \"trainer.gpus=[7]\"]\n",
    "config = ETL.load_hydra_config(config_name = \"config\",\n",
    "                              config_path = \"/media/data/jacob/GitHub/lightning-hydra-classifiers/configs\",\n",
    "                              overrides=overrides)\n",
    "\n",
    "task_id = 1\n",
    "pp(config.data)\n",
    "datamodule = load_data(config,\n",
    "                       task_id=task_id)\n",
    "\n",
    "\n",
    "        \n",
    "# model_config = OmegaConf.create(dict(\n",
    "#                                 backbone_name=config.model.backbone.backbone_name, #'gluon_seresnext50_32x4d',\n",
    "#                                 pretrained=True,\n",
    "#                                 num_classes=datamodule.num_classes,\n",
    "#                                 pool_type='avg',\n",
    "#                                 head_type='linear',\n",
    "#                                 hidden_size=None,\n",
    "#                                 lr=2e-03,\n",
    "#                                 weight_decay=0.01,\n",
    "#                                 seed=98))\n",
    "\n",
    "# model_config = OmegaConf.create(dict(\n",
    "#                                 backbone_name=config.model.backbone.backbone_name, #'gluon_seresnext50_32x4d',\n",
    "#                                 pretrained=True,\n",
    "#                                 num_classes=datamodule.num_classes,\n",
    "#                                 pool_type='max',\n",
    "#                                 head_type='linear',\n",
    "#                                 hidden_size=None,\n",
    "#                                 lr=2e-03,\n",
    "#                                 weight_decay=0.01,\n",
    "#                                 seed=98))\n",
    "\n",
    "model_config = OmegaConf.create(dict(\n",
    "                                backbone_name=config.model.backbone.backbone_name, #'gluon_seresnext50_32x4d',\n",
    "                                pretrained=True,\n",
    "                                num_classes=datamodule.num_classes,\n",
    "                                pool_type='avgdrop',\n",
    "                                head_type='linear',\n",
    "                                hidden_size=None,\n",
    "                                lr=2e-03,\n",
    "                                backbone_lr_mult=0.1,\n",
    "                                finetuning_strategy=\"feature_extractor\",\n",
    "                                weight_decay=0.01,\n",
    "                                seed=98))\n",
    "\n",
    "\n",
    "\n",
    "config.model = model_config\n",
    "\n",
    "algorithm_name = \"feature_extractor\"\n",
    "config.experiment_name = f\"{algorithm_name}-PNAS-{datamodule.num_classes}_classes-res_{config.data.image_size}-bsz_{config.data.batch_size}-{config.model.backbone_name}-pretrained_{config.model.pretrained}-pool_{config.model.pool_type}\"\n",
    "\n",
    "\n",
    "experiment_dir = config.experiment_dir\n",
    "results_dir = config.results_dir\n",
    "results_dir\n",
    "\n",
    "model = LightningClassifier(**config.model)\n",
    "model.label_encoder = datamodule.label_encoder\n",
    "\n",
    "\n",
    "group = f'{config.model.backbone_name}__PNAS__experiment_0__feature_extractor'\n",
    "config.logger.wandb.group = group\n",
    "config.callbacks.log_per_class_metrics_to_wandb.class_names = datamodule.classes\n",
    "\n",
    "\n",
    "callbacks = configure_callbacks(config)\n",
    "logger = configure_loggers(config)\n",
    "\n",
    "trainer: pl.Trainer = configure_trainer(config, callbacks=callbacks, logger=logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "## Run lr_tune->fit->test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning_hydra_classifiers.scripts.pretrain import lr_tuner\n",
    "\n",
    "\n",
    "lr_tuner_results_dir = os.path.join(results_dir, f\"task_{task_id}\", \"lr_tuner\")\n",
    "lr_tune_output = lr_tuner.run_lr_tuner(trainer=trainer,\n",
    "                                       model=model,\n",
    "                                       datamodule=datamodule,\n",
    "                                       config=config,\n",
    "                                       results_dir=lr_tuner_results_dir,\n",
    "                                       group=group)\n",
    "\n",
    "## model.fit\n",
    "\n",
    "hist = trainer.fit(model, datamodule=datamodule)\n",
    "\n",
    "## model.test\n",
    "\n",
    "test_result = trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "# Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import logging\n",
    "from sklearn.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report\n",
    "\n",
    "\n",
    "# def predict_step(batch, batch_idx=None):\n",
    "#     out = self.step(batch, batch_idx)\n",
    "#     if hasattr(batch, \"metadata\"):\n",
    "#         if \"path\" in batch.metadata:\n",
    "#             out = [*out, batch.metadata[\"path\"]]\n",
    "#     return out\n",
    "\n",
    "# self=model\n",
    "# model.predict_step = predict_step\n",
    "# test_results = trainer.predict(dataloaders=datamodule.test_dataloader(), return_predictions=True)\n",
    "# results = collect_results(prediction_results)\n",
    "prediction_results = test_results\n",
    "results = collect_results(prediction_results)\n",
    "len(prediction_results[0])\n",
    "# len(results)\n",
    "\n",
    "def tensors2np(t: Union[torch.Tensor, list]) -> np.ndarray:\n",
    "    if isinstance(t, torch.Tensor):\n",
    "        t = t.cpu().numpy()\n",
    "    elif isinstance(t, list):\n",
    "        t = list(map(tensors2np, t))\n",
    "    if isinstance(t, np.ndarray):\n",
    "        return t\n",
    "    else:\n",
    "        raise TypeError(f\"type(t)={type(t)} is invalid for function tensors2np\" + '\\n' + 'tensors2np(t: Union[torch.Tensor, list]) -> np.ndarray:')\n",
    "        \n",
    "rows = []\n",
    "for result in list(prediction_results):\n",
    "    \n",
    "    y_logit.append(result[0])\n",
    "    y_true.append(result[1])\n",
    "    y_pred.append(result[2])\n",
    "    paths.extend(result[3])\n",
    "    \n",
    "y_logit = torch.cat(y_logit).cpu().numpy()\n",
    "y_true = torch.cat(y_true).cpu().numpy()\n",
    "y_pred = torch.cat(y_pred).cpu().numpy()\n",
    "# paths = torch.cat(paths).cpu().numpy()\n",
    "\n",
    "# [(r[0].device, r[0].shape, r[1].shape, r[2].shape) for r in test_results]\n",
    "\n",
    "print(y_logit.shape, y_true.shape, y_pred.shape, len(paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = model.label_encoder\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.functional import F\n",
    "\n",
    "\n",
    "\n",
    "# https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwji_bKG6cPzAhXJT98KHU0eCsg4HhAWegQIAhAB&url=https%3A%2F%2Fclear.ml%2Fdocs%2Flatest%2Fdocs%2Fguides%2Freporting%2Fexplicit_reporting%2F&usg=AOvVaw3tvUYT7fU3QHIwunDpE800\n",
    "labels = model.label_encoder.classes\n",
    "\n",
    "test_predictions_filepath = os.path.join(results_dir, f\"task_{task_id}\", \"test_predictions.csv\")\n",
    "\n",
    "\n",
    "class ImageInterpretation:\n",
    "    \n",
    "    def __init__(self, model, datamodule, trainer, y_col: str='family'):\n",
    "        self.model = model\n",
    "        self.dm = datamodule\n",
    "        self.trainer = trainer\n",
    "        self.y_col = y_col\n",
    "\n",
    "        \n",
    "    @property\n",
    "    def decoder(self):\n",
    "        return self.dm.label_encoder.idx2class\n",
    "        \n",
    "    def decode_label(y: int): #, labels: Union[Dict[int, str], List[str]]=None):\n",
    "        try:\n",
    "            return self.decoder[y]\n",
    "        except:\n",
    "            return y\n",
    "        \n",
    "    def log_image_predictions(self,\n",
    "                              results_path: str=None,\n",
    "                              sort_by_losses: bool=True,\n",
    "                              ascending: bool=True) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Save table of model predictions as csv\n",
    "        \n",
    "        |losses\t|y_true\t|y_pred\t|paths \t|per-class logits|\n",
    "        |---\t|---\t|---\t|---\t| ---\t |---\t |\n",
    "        |   \t|   \t|   \t|   \t|   \t |   \t |\n",
    "        |   \t|   \t|   \t|   \t|   \t |   \t |\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        pred_results = trainer.predict(dataloaders=datamodule.test_dataloader(), return_predictions=True)\n",
    "\n",
    "        results = collect_results(pred_results)\n",
    "\n",
    "        labels = list(self.decoder.values())\n",
    "        columns = [\"xEnt_loss\", f\"{self.y_col}_true\", f\"{self.y_col}_pred\", \"paths\", *[f\"{l}_logit\" for l in labels]]\n",
    "\n",
    "        y_logits = torch.from_numpy(results[0].astype(\"float32\"))\n",
    "        y_true = torch.from_numpy(results[1])\n",
    "        xEnt_loss = F.cross_entropy(y_logits, y_true, reduction=\"none\")\n",
    "\n",
    "        losses = xEnt_loss\n",
    "        y_true = results[1]\n",
    "        y_pred = results[2]\n",
    "        paths = results[3]\n",
    "        per_class_y_logits = np.hsplit(results[0], results[0].shape[1])\n",
    "\n",
    "        num_results = len(results[0])\n",
    "        rows = []\n",
    "        for i in range(num_results):\n",
    "            rows.append({k:v for k, v in zip(columns,\n",
    "                                             [losses,\n",
    "                                              self.decode_label(y=y_true[i]),\n",
    "                                              self.decode_label(y=y_pred[i]),\n",
    "                                              paths[i],\n",
    "                                              *(y[i].item() for y in per_class_y_logits)]\n",
    "                                            )\n",
    "                        })\n",
    "\n",
    "        data_df = pd.DataFrame.from_records(rows)\n",
    "        \n",
    "        if sort_by_losses:\n",
    "            data_df = data_df.sort_values(\"xEnt_loss\", ascending=ascending)\n",
    "        \n",
    "        ETL.df2csv(data_df, results_spath)\n",
    "        \n",
    "        return data_df\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "#         data = {\"xEnt_loss\":xEnt_loss,\n",
    "#                 f\"{self.y_col}_true\":results[1],\n",
    "#                 f\"{self.y_col}_pred\":results[2],\n",
    "#                 \"path\":results[3],\n",
    "#                 \"y_logits\":np.hsplit(results[0], results[0].shape[1])}    \n",
    "    \n",
    "    \n",
    "    \n",
    "#         rows = []\n",
    "#         for i in range(num_results):\n",
    "#             rows.append({k:v for k, v in zip(columns,\n",
    "#                                              [data[\"xEnt_loss\"][i], \n",
    "#                                               self.decode_label(y=data[f\"{self.y_col}_true\"][i]),\n",
    "#                                               self.decode_label(y=data[f\"{self.y_col}_pred\"][i]),\n",
    "#                                               data[\"path\"][i],\n",
    "#                                               *(y[i].item() for y in data[\"y_logits\"])]\n",
    "#                                             )\n",
    "#                         })\n",
    "\n",
    "#         data_df = pd.DataFrame.from_records(rows)\n",
    "#         ETL.df2csv(data_df, test_predictions_filepath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family_true</th>\n",
       "      <th>family_pred</th>\n",
       "      <th>paths</th>\n",
       "      <th>Anacardiaceae_logit</th>\n",
       "      <th>Annonaceae_logit</th>\n",
       "      <th>Apocynaceae_logit</th>\n",
       "      <th>Betulaceae_logit</th>\n",
       "      <th>Celastraceae_logit</th>\n",
       "      <th>Combretaceae_logit</th>\n",
       "      <th>Ericaceae_logit</th>\n",
       "      <th>Fabaceae_logit</th>\n",
       "      <th>Fagaceae_logit</th>\n",
       "      <th>Lauraceae_logit</th>\n",
       "      <th>Malvaceae_logit</th>\n",
       "      <th>Melastomataceae_logit</th>\n",
       "      <th>Myrtaceae_logit</th>\n",
       "      <th>Passifloraceae_logit</th>\n",
       "      <th>Phyllanthaceae_logit</th>\n",
       "      <th>Rosaceae_logit</th>\n",
       "      <th>Rubiaceae_logit</th>\n",
       "      <th>Salicaceae_logit</th>\n",
       "      <th>Sapindaceae_logit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2382</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/train/Betulaceae/Betulaceae_Corylus_sieboldiana_Wolfe_8505.jpg</td>\n",
       "      <td>-3.701172</td>\n",
       "      <td>-1.307617</td>\n",
       "      <td>-3.009766</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>-3.759766</td>\n",
       "      <td>-5.464844</td>\n",
       "      <td>-3.427734</td>\n",
       "      <td>-3.501953</td>\n",
       "      <td>2.558594</td>\n",
       "      <td>-2.662109</td>\n",
       "      <td>-0.223267</td>\n",
       "      <td>-5.761719</td>\n",
       "      <td>-5.398438</td>\n",
       "      <td>-5.808594</td>\n",
       "      <td>-5.355469</td>\n",
       "      <td>4.937500</td>\n",
       "      <td>0.086670</td>\n",
       "      <td>-2.923828</td>\n",
       "      <td>2.140625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2379</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/train/Betulaceae/Betulaceae_Carpinus_minutiserrata_Wolfe_8499.jpg</td>\n",
       "      <td>-3.636719</td>\n",
       "      <td>-0.404541</td>\n",
       "      <td>-3.140625</td>\n",
       "      <td>6.570312</td>\n",
       "      <td>-3.857422</td>\n",
       "      <td>-5.554688</td>\n",
       "      <td>-2.789062</td>\n",
       "      <td>-3.111328</td>\n",
       "      <td>2.324219</td>\n",
       "      <td>-1.705078</td>\n",
       "      <td>-0.510254</td>\n",
       "      <td>-4.355469</td>\n",
       "      <td>-4.910156</td>\n",
       "      <td>-6.250000</td>\n",
       "      <td>-5.363281</td>\n",
       "      <td>4.960938</td>\n",
       "      <td>-1.021484</td>\n",
       "      <td>-3.556641</td>\n",
       "      <td>1.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/train/Salicaceae/Salicaceae_Salix_paradoxa_Wolfe_18143.jpg</td>\n",
       "      <td>-3.542969</td>\n",
       "      <td>-0.666504</td>\n",
       "      <td>-0.868652</td>\n",
       "      <td>-4.914062</td>\n",
       "      <td>-1.795898</td>\n",
       "      <td>-0.714355</td>\n",
       "      <td>-3.437500</td>\n",
       "      <td>-1.461914</td>\n",
       "      <td>-1.703125</td>\n",
       "      <td>-0.938477</td>\n",
       "      <td>-1.060547</td>\n",
       "      <td>-4.484375</td>\n",
       "      <td>-1.119141</td>\n",
       "      <td>-2.339844</td>\n",
       "      <td>-0.384521</td>\n",
       "      <td>-2.453125</td>\n",
       "      <td>-0.583984</td>\n",
       "      <td>0.764648</td>\n",
       "      <td>-2.248047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/test/Melastomataceae/Melastomataceae_Miconia_candolleana_Wolfe_7579.jpg</td>\n",
       "      <td>-3.531250</td>\n",
       "      <td>-1.310547</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>-3.238281</td>\n",
       "      <td>-1.906250</td>\n",
       "      <td>-0.319824</td>\n",
       "      <td>-2.828125</td>\n",
       "      <td>-0.099548</td>\n",
       "      <td>-1.003906</td>\n",
       "      <td>-1.366211</td>\n",
       "      <td>-2.339844</td>\n",
       "      <td>-2.994141</td>\n",
       "      <td>-0.514160</td>\n",
       "      <td>-2.351562</td>\n",
       "      <td>-1.755859</td>\n",
       "      <td>-1.009766</td>\n",
       "      <td>0.995605</td>\n",
       "      <td>-0.788086</td>\n",
       "      <td>-1.653320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/train/Betulaceae/Betulaceae_Betula_delavayi_Wolfe_8515.jpg</td>\n",
       "      <td>-3.523438</td>\n",
       "      <td>-1.132812</td>\n",
       "      <td>-2.919922</td>\n",
       "      <td>5.539062</td>\n",
       "      <td>-3.652344</td>\n",
       "      <td>-5.593750</td>\n",
       "      <td>-3.361328</td>\n",
       "      <td>-3.464844</td>\n",
       "      <td>2.539062</td>\n",
       "      <td>-2.875000</td>\n",
       "      <td>-0.327637</td>\n",
       "      <td>-5.246094</td>\n",
       "      <td>-4.781250</td>\n",
       "      <td>-5.527344</td>\n",
       "      <td>-5.289062</td>\n",
       "      <td>4.582031</td>\n",
       "      <td>0.183960</td>\n",
       "      <td>-2.988281</td>\n",
       "      <td>2.130859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/train/Anacardiaceae/Anacardiaceae_Anacardium_microsepalum_Wolfe_4202.jpg</td>\n",
       "      <td>2.031250</td>\n",
       "      <td>2.220703</td>\n",
       "      <td>0.378418</td>\n",
       "      <td>-1.996094</td>\n",
       "      <td>-2.458984</td>\n",
       "      <td>-5.179688</td>\n",
       "      <td>-1.397461</td>\n",
       "      <td>-1.719727</td>\n",
       "      <td>-1.301758</td>\n",
       "      <td>-0.013664</td>\n",
       "      <td>-3.351562</td>\n",
       "      <td>-2.388672</td>\n",
       "      <td>-0.104553</td>\n",
       "      <td>-4.355469</td>\n",
       "      <td>-3.957031</td>\n",
       "      <td>-1.269531</td>\n",
       "      <td>-0.753418</td>\n",
       "      <td>-3.931641</td>\n",
       "      <td>0.276123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/test/Apocynaceae/Apocynaceae_Condylocarpon_amazonicum_Wolfe_9166.jpg</td>\n",
       "      <td>2.072266</td>\n",
       "      <td>1.169922</td>\n",
       "      <td>0.980957</td>\n",
       "      <td>-1.467773</td>\n",
       "      <td>-2.337891</td>\n",
       "      <td>-5.261719</td>\n",
       "      <td>-1.712891</td>\n",
       "      <td>-1.980469</td>\n",
       "      <td>-1.117188</td>\n",
       "      <td>-1.140625</td>\n",
       "      <td>-3.160156</td>\n",
       "      <td>-1.918945</td>\n",
       "      <td>0.444092</td>\n",
       "      <td>-3.927734</td>\n",
       "      <td>-4.417969</td>\n",
       "      <td>-1.185547</td>\n",
       "      <td>-0.756348</td>\n",
       "      <td>-3.855469</td>\n",
       "      <td>0.513184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/train/Anacardiaceae/Anacardiaceae_Anacardium_humile_Wolfe_12854.jpg</td>\n",
       "      <td>2.318359</td>\n",
       "      <td>2.531250</td>\n",
       "      <td>0.029694</td>\n",
       "      <td>-2.062500</td>\n",
       "      <td>-2.750000</td>\n",
       "      <td>-4.988281</td>\n",
       "      <td>-1.211914</td>\n",
       "      <td>-1.269531</td>\n",
       "      <td>-1.435547</td>\n",
       "      <td>-0.288818</td>\n",
       "      <td>-3.263672</td>\n",
       "      <td>-1.830078</td>\n",
       "      <td>-0.763672</td>\n",
       "      <td>-4.531250</td>\n",
       "      <td>-3.882812</td>\n",
       "      <td>-1.215820</td>\n",
       "      <td>-0.182251</td>\n",
       "      <td>-4.171875</td>\n",
       "      <td>-0.325928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2281</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/train/Annonaceae/Annonaceae_Cyathocalyx_pahangensis_Wolfe_7860.jpg</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>1.263672</td>\n",
       "      <td>0.446533</td>\n",
       "      <td>-1.714844</td>\n",
       "      <td>-2.597656</td>\n",
       "      <td>-5.339844</td>\n",
       "      <td>-1.846680</td>\n",
       "      <td>-1.754883</td>\n",
       "      <td>-1.322266</td>\n",
       "      <td>-0.888672</td>\n",
       "      <td>-2.570312</td>\n",
       "      <td>-2.365234</td>\n",
       "      <td>-0.152954</td>\n",
       "      <td>-3.791016</td>\n",
       "      <td>-4.105469</td>\n",
       "      <td>-1.630859</td>\n",
       "      <td>-0.832520</td>\n",
       "      <td>-3.966797</td>\n",
       "      <td>0.582031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/train/Apocynaceae/Apocynaceae_Dyera_lowii_Wolfe_8430.jpg</td>\n",
       "      <td>2.603516</td>\n",
       "      <td>1.859375</td>\n",
       "      <td>0.836426</td>\n",
       "      <td>-2.263672</td>\n",
       "      <td>-2.771484</td>\n",
       "      <td>-4.992188</td>\n",
       "      <td>-1.857422</td>\n",
       "      <td>-1.131836</td>\n",
       "      <td>-1.219727</td>\n",
       "      <td>-0.742188</td>\n",
       "      <td>-3.986328</td>\n",
       "      <td>-2.173828</td>\n",
       "      <td>0.757812</td>\n",
       "      <td>-4.257812</td>\n",
       "      <td>-4.199219</td>\n",
       "      <td>-2.175781</td>\n",
       "      <td>-0.663086</td>\n",
       "      <td>-4.609375</td>\n",
       "      <td>-0.463867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2797 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      family_true  family_pred  \\\n",
       "2382            3            3   \n",
       "2379            3            3   \n",
       "1310           17           17   \n",
       "2220           11           16   \n",
       "2388            3            3   \n",
       "...           ...          ...   \n",
       "1578            0            1   \n",
       "2503            2            0   \n",
       "703             0            1   \n",
       "2281            1            0   \n",
       "2362            2            0   \n",
       "\n",
       "                                                                                                                                                                   paths  \\\n",
       "2382            /media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/train/Betulaceae/Betulaceae_Corylus_sieboldiana_Wolfe_8505.jpg   \n",
       "2379         /media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/train/Betulaceae/Betulaceae_Carpinus_minutiserrata_Wolfe_8499.jpg   \n",
       "1310                /media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/train/Salicaceae/Salicaceae_Salix_paradoxa_Wolfe_18143.jpg   \n",
       "2220   /media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/test/Melastomataceae/Melastomataceae_Miconia_candolleana_Wolfe_7579.jpg   \n",
       "2388                /media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/train/Betulaceae/Betulaceae_Betula_delavayi_Wolfe_8515.jpg   \n",
       "...                                                                                                                                                                  ...   \n",
       "1578  /media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/train/Anacardiaceae/Anacardiaceae_Anacardium_microsepalum_Wolfe_4202.jpg   \n",
       "2503      /media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/test/Apocynaceae/Apocynaceae_Condylocarpon_amazonicum_Wolfe_9166.jpg   \n",
       "703        /media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/train/Anacardiaceae/Anacardiaceae_Anacardium_humile_Wolfe_12854.jpg   \n",
       "2281        /media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/train/Annonaceae/Annonaceae_Cyathocalyx_pahangensis_Wolfe_7860.jpg   \n",
       "2362                  /media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/train/Apocynaceae/Apocynaceae_Dyera_lowii_Wolfe_8430.jpg   \n",
       "\n",
       "      Anacardiaceae_logit  Annonaceae_logit  Apocynaceae_logit  \\\n",
       "2382            -3.701172         -1.307617          -3.009766   \n",
       "2379            -3.636719         -0.404541          -3.140625   \n",
       "1310            -3.542969         -0.666504          -0.868652   \n",
       "2220            -3.531250         -1.310547           0.375000   \n",
       "2388            -3.523438         -1.132812          -2.919922   \n",
       "...                   ...               ...                ...   \n",
       "1578             2.031250          2.220703           0.378418   \n",
       "2503             2.072266          1.169922           0.980957   \n",
       "703              2.318359          2.531250           0.029694   \n",
       "2281             2.400391          1.263672           0.446533   \n",
       "2362             2.603516          1.859375           0.836426   \n",
       "\n",
       "      Betulaceae_logit  Celastraceae_logit  Combretaceae_logit  \\\n",
       "2382          6.000000           -3.759766           -5.464844   \n",
       "2379          6.570312           -3.857422           -5.554688   \n",
       "1310         -4.914062           -1.795898           -0.714355   \n",
       "2220         -3.238281           -1.906250           -0.319824   \n",
       "2388          5.539062           -3.652344           -5.593750   \n",
       "...                ...                 ...                 ...   \n",
       "1578         -1.996094           -2.458984           -5.179688   \n",
       "2503         -1.467773           -2.337891           -5.261719   \n",
       "703          -2.062500           -2.750000           -4.988281   \n",
       "2281         -1.714844           -2.597656           -5.339844   \n",
       "2362         -2.263672           -2.771484           -4.992188   \n",
       "\n",
       "      Ericaceae_logit  Fabaceae_logit  Fagaceae_logit  Lauraceae_logit  \\\n",
       "2382        -3.427734       -3.501953        2.558594        -2.662109   \n",
       "2379        -2.789062       -3.111328        2.324219        -1.705078   \n",
       "1310        -3.437500       -1.461914       -1.703125        -0.938477   \n",
       "2220        -2.828125       -0.099548       -1.003906        -1.366211   \n",
       "2388        -3.361328       -3.464844        2.539062        -2.875000   \n",
       "...               ...             ...             ...              ...   \n",
       "1578        -1.397461       -1.719727       -1.301758        -0.013664   \n",
       "2503        -1.712891       -1.980469       -1.117188        -1.140625   \n",
       "703         -1.211914       -1.269531       -1.435547        -0.288818   \n",
       "2281        -1.846680       -1.754883       -1.322266        -0.888672   \n",
       "2362        -1.857422       -1.131836       -1.219727        -0.742188   \n",
       "\n",
       "      Malvaceae_logit  Melastomataceae_logit  Myrtaceae_logit  \\\n",
       "2382        -0.223267              -5.761719        -5.398438   \n",
       "2379        -0.510254              -4.355469        -4.910156   \n",
       "1310        -1.060547              -4.484375        -1.119141   \n",
       "2220        -2.339844              -2.994141        -0.514160   \n",
       "2388        -0.327637              -5.246094        -4.781250   \n",
       "...               ...                    ...              ...   \n",
       "1578        -3.351562              -2.388672        -0.104553   \n",
       "2503        -3.160156              -1.918945         0.444092   \n",
       "703         -3.263672              -1.830078        -0.763672   \n",
       "2281        -2.570312              -2.365234        -0.152954   \n",
       "2362        -3.986328              -2.173828         0.757812   \n",
       "\n",
       "      Passifloraceae_logit  Phyllanthaceae_logit  Rosaceae_logit  \\\n",
       "2382             -5.808594             -5.355469        4.937500   \n",
       "2379             -6.250000             -5.363281        4.960938   \n",
       "1310             -2.339844             -0.384521       -2.453125   \n",
       "2220             -2.351562             -1.755859       -1.009766   \n",
       "2388             -5.527344             -5.289062        4.582031   \n",
       "...                    ...                   ...             ...   \n",
       "1578             -4.355469             -3.957031       -1.269531   \n",
       "2503             -3.927734             -4.417969       -1.185547   \n",
       "703              -4.531250             -3.882812       -1.215820   \n",
       "2281             -3.791016             -4.105469       -1.630859   \n",
       "2362             -4.257812             -4.199219       -2.175781   \n",
       "\n",
       "      Rubiaceae_logit  Salicaceae_logit  Sapindaceae_logit  \n",
       "2382         0.086670         -2.923828           2.140625  \n",
       "2379        -1.021484         -3.556641           1.875000  \n",
       "1310        -0.583984          0.764648          -2.248047  \n",
       "2220         0.995605         -0.788086          -1.653320  \n",
       "2388         0.183960         -2.988281           2.130859  \n",
       "...               ...               ...                ...  \n",
       "1578        -0.753418         -3.931641           0.276123  \n",
       "2503        -0.756348         -3.855469           0.513184  \n",
       "703         -0.182251         -4.171875          -0.325928  \n",
       "2281        -0.832520         -3.966797           0.582031  \n",
       "2362        -0.663086         -4.609375          -0.463867  \n",
       "\n",
       "[2797 rows x 22 columns]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.sort_values(\"Anacardiaceae_logit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family_true</th>\n",
       "      <th>family_pred</th>\n",
       "      <th>paths</th>\n",
       "      <th>Anacardiaceae_logit</th>\n",
       "      <th>Annonaceae_logit</th>\n",
       "      <th>Apocynaceae_logit</th>\n",
       "      <th>Betulaceae_logit</th>\n",
       "      <th>Celastraceae_logit</th>\n",
       "      <th>Combretaceae_logit</th>\n",
       "      <th>Ericaceae_logit</th>\n",
       "      <th>Fabaceae_logit</th>\n",
       "      <th>Fagaceae_logit</th>\n",
       "      <th>Lauraceae_logit</th>\n",
       "      <th>Malvaceae_logit</th>\n",
       "      <th>Melastomataceae_logit</th>\n",
       "      <th>Myrtaceae_logit</th>\n",
       "      <th>Passifloraceae_logit</th>\n",
       "      <th>Phyllanthaceae_logit</th>\n",
       "      <th>Rosaceae_logit</th>\n",
       "      <th>Rubiaceae_logit</th>\n",
       "      <th>Salicaceae_logit</th>\n",
       "      <th>Sapindaceae_logit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/train/Fagaceae/Fagaceae_Lithocarpus_densiflora_Axelrod_105.jpg</td>\n",
       "      <td>-2.101562</td>\n",
       "      <td>0.946777</td>\n",
       "      <td>-2.197266</td>\n",
       "      <td>-5.257812</td>\n",
       "      <td>-1.637695</td>\n",
       "      <td>-4.351562</td>\n",
       "      <td>-0.747070</td>\n",
       "      <td>2.486328</td>\n",
       "      <td>-2.169922</td>\n",
       "      <td>1.900391</td>\n",
       "      <td>-2.886719</td>\n",
       "      <td>-4.980469</td>\n",
       "      <td>-2.761719</td>\n",
       "      <td>-3.220703</td>\n",
       "      <td>-2.039062</td>\n",
       "      <td>-2.855469</td>\n",
       "      <td>-1.358398</td>\n",
       "      <td>-2.119141</td>\n",
       "      <td>-1.598633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/test/Ericaceae/Ericaceae_Arctostaphylos_bicolor_Axelrod_1064.jpg</td>\n",
       "      <td>-1.948242</td>\n",
       "      <td>-0.208008</td>\n",
       "      <td>-1.406250</td>\n",
       "      <td>-2.642578</td>\n",
       "      <td>-0.841797</td>\n",
       "      <td>-3.482422</td>\n",
       "      <td>-1.020508</td>\n",
       "      <td>-0.872070</td>\n",
       "      <td>-1.964844</td>\n",
       "      <td>-1.522461</td>\n",
       "      <td>-0.915039</td>\n",
       "      <td>-5.437500</td>\n",
       "      <td>-3.214844</td>\n",
       "      <td>-2.896484</td>\n",
       "      <td>-1.683594</td>\n",
       "      <td>0.409424</td>\n",
       "      <td>-1.733398</td>\n",
       "      <td>1.350586</td>\n",
       "      <td>-0.226807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/test/Fabaceae/Fabaceae_Amorpha_californica_Axelrod_107.jpg</td>\n",
       "      <td>-1.899414</td>\n",
       "      <td>0.320557</td>\n",
       "      <td>-1.014648</td>\n",
       "      <td>-2.306641</td>\n",
       "      <td>-0.415283</td>\n",
       "      <td>-2.873047</td>\n",
       "      <td>0.164185</td>\n",
       "      <td>0.775391</td>\n",
       "      <td>-1.668945</td>\n",
       "      <td>-0.221802</td>\n",
       "      <td>-1.568359</td>\n",
       "      <td>-3.824219</td>\n",
       "      <td>-2.728516</td>\n",
       "      <td>-2.455078</td>\n",
       "      <td>-2.048828</td>\n",
       "      <td>0.622559</td>\n",
       "      <td>-1.046875</td>\n",
       "      <td>0.237793</td>\n",
       "      <td>-0.510742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/test/Anacardiaceae/Anacardiaceae_Rhus_scheidana_Axelrod_1083.jpg</td>\n",
       "      <td>-2.119141</td>\n",
       "      <td>0.247192</td>\n",
       "      <td>-0.884277</td>\n",
       "      <td>-3.435547</td>\n",
       "      <td>-0.860840</td>\n",
       "      <td>-2.496094</td>\n",
       "      <td>-0.708984</td>\n",
       "      <td>0.709961</td>\n",
       "      <td>-1.564453</td>\n",
       "      <td>-0.077454</td>\n",
       "      <td>-1.122070</td>\n",
       "      <td>-3.429688</td>\n",
       "      <td>-2.224609</td>\n",
       "      <td>-2.107422</td>\n",
       "      <td>-1.483398</td>\n",
       "      <td>-0.923340</td>\n",
       "      <td>-1.385742</td>\n",
       "      <td>0.063416</td>\n",
       "      <td>-0.836426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/train/Rosaceae/Rosaceae_Holodiscus_bousierii_Axelrod_11.jpg</td>\n",
       "      <td>-1.210938</td>\n",
       "      <td>-0.155151</td>\n",
       "      <td>-0.820312</td>\n",
       "      <td>-0.239014</td>\n",
       "      <td>-1.089844</td>\n",
       "      <td>-3.675781</td>\n",
       "      <td>-0.708984</td>\n",
       "      <td>-0.143677</td>\n",
       "      <td>-0.320557</td>\n",
       "      <td>-1.643555</td>\n",
       "      <td>-1.702148</td>\n",
       "      <td>-4.644531</td>\n",
       "      <td>-3.546875</td>\n",
       "      <td>-4.359375</td>\n",
       "      <td>-3.392578</td>\n",
       "      <td>1.975586</td>\n",
       "      <td>0.340088</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2.621094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2792</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/train/Fabaceae/Fabaceae_Spatholobus_sanguineus_Wolfe_9986.jpg</td>\n",
       "      <td>-1.414062</td>\n",
       "      <td>-0.408203</td>\n",
       "      <td>-1.287109</td>\n",
       "      <td>-1.636719</td>\n",
       "      <td>-1.176758</td>\n",
       "      <td>-3.201172</td>\n",
       "      <td>-1.117188</td>\n",
       "      <td>0.658691</td>\n",
       "      <td>-0.553223</td>\n",
       "      <td>-0.359619</td>\n",
       "      <td>-0.608398</td>\n",
       "      <td>-4.261719</td>\n",
       "      <td>-3.195312</td>\n",
       "      <td>-2.927734</td>\n",
       "      <td>-2.158203</td>\n",
       "      <td>-0.062805</td>\n",
       "      <td>-0.152954</td>\n",
       "      <td>-1.143555</td>\n",
       "      <td>0.043213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2793</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/test/Fabaceae/Fabaceae_Strongylodon_lucidus_Wolfe_9991.jpg</td>\n",
       "      <td>-1.657227</td>\n",
       "      <td>-0.341553</td>\n",
       "      <td>-1.412109</td>\n",
       "      <td>-2.822266</td>\n",
       "      <td>-1.095703</td>\n",
       "      <td>-2.773438</td>\n",
       "      <td>-0.649414</td>\n",
       "      <td>1.941406</td>\n",
       "      <td>-1.231445</td>\n",
       "      <td>-0.438477</td>\n",
       "      <td>-1.717773</td>\n",
       "      <td>-4.644531</td>\n",
       "      <td>-3.406250</td>\n",
       "      <td>-3.111328</td>\n",
       "      <td>-2.568359</td>\n",
       "      <td>-0.196289</td>\n",
       "      <td>-0.147827</td>\n",
       "      <td>-1.016602</td>\n",
       "      <td>-0.682617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2794</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/test/Fabaceae/Fabaceae_Sweetia_nitens_Wolfe_9994.jpg</td>\n",
       "      <td>-1.159180</td>\n",
       "      <td>0.910645</td>\n",
       "      <td>-1.306641</td>\n",
       "      <td>-3.710938</td>\n",
       "      <td>-1.150391</td>\n",
       "      <td>-4.042969</td>\n",
       "      <td>-0.448486</td>\n",
       "      <td>0.985352</td>\n",
       "      <td>-1.852539</td>\n",
       "      <td>0.742188</td>\n",
       "      <td>-2.884766</td>\n",
       "      <td>-3.646484</td>\n",
       "      <td>-1.609375</td>\n",
       "      <td>-2.974609</td>\n",
       "      <td>-2.533203</td>\n",
       "      <td>-1.801758</td>\n",
       "      <td>-1.070312</td>\n",
       "      <td>-1.525391</td>\n",
       "      <td>-0.565918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/train/Fabaceae/Fabaceae_Templetonia_retusa_Wolfe_9995.jpg</td>\n",
       "      <td>-1.577148</td>\n",
       "      <td>-1.782227</td>\n",
       "      <td>-1.040039</td>\n",
       "      <td>-3.068359</td>\n",
       "      <td>-2.150391</td>\n",
       "      <td>-1.496094</td>\n",
       "      <td>-1.236328</td>\n",
       "      <td>3.931641</td>\n",
       "      <td>-1.172852</td>\n",
       "      <td>-2.310547</td>\n",
       "      <td>-3.220703</td>\n",
       "      <td>-5.195312</td>\n",
       "      <td>-2.341797</td>\n",
       "      <td>-3.683594</td>\n",
       "      <td>-3.480469</td>\n",
       "      <td>-0.072754</td>\n",
       "      <td>0.024765</td>\n",
       "      <td>-1.898438</td>\n",
       "      <td>-1.231445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>/media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/train/Fabaceae/Fabaceae_Tessmannia_anomala_Wolfe_9998.jpg</td>\n",
       "      <td>-0.927734</td>\n",
       "      <td>-0.419189</td>\n",
       "      <td>-0.990234</td>\n",
       "      <td>-4.324219</td>\n",
       "      <td>-1.419922</td>\n",
       "      <td>-2.306641</td>\n",
       "      <td>-0.715332</td>\n",
       "      <td>4.031250</td>\n",
       "      <td>-1.281250</td>\n",
       "      <td>-1.117188</td>\n",
       "      <td>-3.248047</td>\n",
       "      <td>-5.554688</td>\n",
       "      <td>-1.846680</td>\n",
       "      <td>-3.681641</td>\n",
       "      <td>-2.121094</td>\n",
       "      <td>-1.324219</td>\n",
       "      <td>-0.002041</td>\n",
       "      <td>-2.394531</td>\n",
       "      <td>-2.003906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2797 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      family_true  family_pred  \\\n",
       "0               8            7   \n",
       "1               6           17   \n",
       "2               7            7   \n",
       "3               0            7   \n",
       "4              15           18   \n",
       "...           ...          ...   \n",
       "2792            7            7   \n",
       "2793            7            7   \n",
       "2794            7            7   \n",
       "2795            7            7   \n",
       "2796            7            7   \n",
       "\n",
       "                                                                                                                                                           paths  \\\n",
       "0       /media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/train/Fagaceae/Fagaceae_Lithocarpus_densiflora_Axelrod_105.jpg   \n",
       "1     /media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/test/Ericaceae/Ericaceae_Arctostaphylos_bicolor_Axelrod_1064.jpg   \n",
       "2           /media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/test/Fabaceae/Fabaceae_Amorpha_californica_Axelrod_107.jpg   \n",
       "3     /media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/test/Anacardiaceae/Anacardiaceae_Rhus_scheidana_Axelrod_1083.jpg   \n",
       "4          /media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/train/Rosaceae/Rosaceae_Holodiscus_bousierii_Axelrod_11.jpg   \n",
       "...                                                                                                                                                          ...   \n",
       "2792     /media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/train/Fabaceae/Fabaceae_Spatholobus_sanguineus_Wolfe_9986.jpg   \n",
       "2793        /media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/test/Fabaceae/Fabaceae_Strongylodon_lucidus_Wolfe_9991.jpg   \n",
       "2794              /media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/test/Fabaceae/Fabaceae_Sweetia_nitens_Wolfe_9994.jpg   \n",
       "2795         /media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/train/Fabaceae/Fabaceae_Templetonia_retusa_Wolfe_9995.jpg   \n",
       "2796         /media/data_cifs/projects/prj_fossils/data/processed_data/data_splits/PNAS_family_100_512/train/Fabaceae/Fabaceae_Tessmannia_anomala_Wolfe_9998.jpg   \n",
       "\n",
       "      Anacardiaceae_logit  Annonaceae_logit  Apocynaceae_logit  \\\n",
       "0               -2.101562          0.946777          -2.197266   \n",
       "1               -1.948242         -0.208008          -1.406250   \n",
       "2               -1.899414          0.320557          -1.014648   \n",
       "3               -2.119141          0.247192          -0.884277   \n",
       "4               -1.210938         -0.155151          -0.820312   \n",
       "...                   ...               ...                ...   \n",
       "2792            -1.414062         -0.408203          -1.287109   \n",
       "2793            -1.657227         -0.341553          -1.412109   \n",
       "2794            -1.159180          0.910645          -1.306641   \n",
       "2795            -1.577148         -1.782227          -1.040039   \n",
       "2796            -0.927734         -0.419189          -0.990234   \n",
       "\n",
       "      Betulaceae_logit  Celastraceae_logit  Combretaceae_logit  \\\n",
       "0            -5.257812           -1.637695           -4.351562   \n",
       "1            -2.642578           -0.841797           -3.482422   \n",
       "2            -2.306641           -0.415283           -2.873047   \n",
       "3            -3.435547           -0.860840           -2.496094   \n",
       "4            -0.239014           -1.089844           -3.675781   \n",
       "...                ...                 ...                 ...   \n",
       "2792         -1.636719           -1.176758           -3.201172   \n",
       "2793         -2.822266           -1.095703           -2.773438   \n",
       "2794         -3.710938           -1.150391           -4.042969   \n",
       "2795         -3.068359           -2.150391           -1.496094   \n",
       "2796         -4.324219           -1.419922           -2.306641   \n",
       "\n",
       "      Ericaceae_logit  Fabaceae_logit  Fagaceae_logit  Lauraceae_logit  \\\n",
       "0           -0.747070        2.486328       -2.169922         1.900391   \n",
       "1           -1.020508       -0.872070       -1.964844        -1.522461   \n",
       "2            0.164185        0.775391       -1.668945        -0.221802   \n",
       "3           -0.708984        0.709961       -1.564453        -0.077454   \n",
       "4           -0.708984       -0.143677       -0.320557        -1.643555   \n",
       "...               ...             ...             ...              ...   \n",
       "2792        -1.117188        0.658691       -0.553223        -0.359619   \n",
       "2793        -0.649414        1.941406       -1.231445        -0.438477   \n",
       "2794        -0.448486        0.985352       -1.852539         0.742188   \n",
       "2795        -1.236328        3.931641       -1.172852        -2.310547   \n",
       "2796        -0.715332        4.031250       -1.281250        -1.117188   \n",
       "\n",
       "      Malvaceae_logit  Melastomataceae_logit  Myrtaceae_logit  \\\n",
       "0           -2.886719              -4.980469        -2.761719   \n",
       "1           -0.915039              -5.437500        -3.214844   \n",
       "2           -1.568359              -3.824219        -2.728516   \n",
       "3           -1.122070              -3.429688        -2.224609   \n",
       "4           -1.702148              -4.644531        -3.546875   \n",
       "...               ...                    ...              ...   \n",
       "2792        -0.608398              -4.261719        -3.195312   \n",
       "2793        -1.717773              -4.644531        -3.406250   \n",
       "2794        -2.884766              -3.646484        -1.609375   \n",
       "2795        -3.220703              -5.195312        -2.341797   \n",
       "2796        -3.248047              -5.554688        -1.846680   \n",
       "\n",
       "      Passifloraceae_logit  Phyllanthaceae_logit  Rosaceae_logit  \\\n",
       "0                -3.220703             -2.039062       -2.855469   \n",
       "1                -2.896484             -1.683594        0.409424   \n",
       "2                -2.455078             -2.048828        0.622559   \n",
       "3                -2.107422             -1.483398       -0.923340   \n",
       "4                -4.359375             -3.392578        1.975586   \n",
       "...                    ...                   ...             ...   \n",
       "2792             -2.927734             -2.158203       -0.062805   \n",
       "2793             -3.111328             -2.568359       -0.196289   \n",
       "2794             -2.974609             -2.533203       -1.801758   \n",
       "2795             -3.683594             -3.480469       -0.072754   \n",
       "2796             -3.681641             -2.121094       -1.324219   \n",
       "\n",
       "      Rubiaceae_logit  Salicaceae_logit  Sapindaceae_logit  \n",
       "0           -1.358398         -2.119141          -1.598633  \n",
       "1           -1.733398          1.350586          -0.226807  \n",
       "2           -1.046875          0.237793          -0.510742  \n",
       "3           -1.385742          0.063416          -0.836426  \n",
       "4            0.340088         -1.000000           2.621094  \n",
       "...               ...               ...                ...  \n",
       "2792        -0.152954         -1.143555           0.043213  \n",
       "2793        -0.147827         -1.016602          -0.682617  \n",
       "2794        -1.070312         -1.525391          -0.565918  \n",
       "2795         0.024765         -1.898438          -1.231445  \n",
       "2796        -0.002041         -2.394531          -2.003906  \n",
       "\n",
       "[2797 rows x 22 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'/media/data_cifs/projects/prj_fossils/users/jacob/experiments/July2021-Nov2021/experiment_logs/Transfer_Experiments/feature_extractor-PNAS-19_classes-res_512-bsz_32-resnet50-pretrained_True-pool_avg/replicate_1/results/task_1/test_predictions.csv'"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df\n",
    "test_predictions_filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## generate report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastprogress                   1.0.0\n"
     ]
    }
   ],
   "source": [
    "from lightning_hydra_classifiers.utils.report_utils.pandas_embed_images import df_embed_paths2imgs\n",
    "\n",
    "\n",
    "\n",
    "df_embed_paths2imgs(df: pd.DataFrame,\n",
    "                        file_path: str, \n",
    "                        path_col: str=\"path\",\n",
    "                        display: bool=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2797"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[-2.102e+00,  9.468e-01, -2.197e+00, ..., -1.358e+00, -2.119e+00,\n",
       "        -1.599e+00],\n",
       "       [-1.948e+00, -2.080e-01, -1.406e+00, ..., -1.733e+00,  1.351e+00,\n",
       "        -2.268e-01],\n",
       "       [-1.899e+00,  3.206e-01, -1.015e+00, ..., -1.047e+00,  2.378e-01,\n",
       "        -5.107e-01],\n",
       "       ...,\n",
       "       [-1.159e+00,  9.106e-01, -1.307e+00, ..., -1.070e+00, -1.525e+00,\n",
       "        -5.659e-01],\n",
       "       [-1.577e+00, -1.782e+00, -1.040e+00, ...,  2.477e-02, -1.898e+00,\n",
       "        -1.231e+00],\n",
       "       [-9.277e-01, -4.192e-01, -9.902e-01, ..., -2.041e-03, -2.395e+00,\n",
       "        -2.004e+00]], dtype=float16)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paths)\n",
    "\n",
    "y_logit#.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fdaec2ebbe0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(y_logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger = logging.getLogger(__name__)\n",
    "\n",
    "def generate_report(y_pred,\n",
    "                    y_true, \n",
    "                    labels=None,\n",
    "                    results_dir: str=None):\n",
    "    \"\"\"Create a performance report for the current experiment and \n",
    "    consolidate the information to a general report of all runs \n",
    "    Parameters\n",
    "    ----------\n",
    "    opt : sklearn.model_selection.Object\n",
    "        A hyperparameter \n",
    "    X_test: numpy array or pandas Dataframe \n",
    "        Input test data\n",
    "    y_test: numpy array or pandas Dataframe \n",
    "        Target test data\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    logger.info(\"Generating Evaluation Report:\")\n",
    "    \n",
    "\n",
    "    res = classification_report(y_true, y_pred, labels=labels, output_dict=True)\n",
    "    res = pd.DataFrame(res)\n",
    "\n",
    "    logger.info(\"Test report:\")\n",
    "    logger.info('\\n \\t'+ res.to_string().replace('\\n', '\\n\\t'))\n",
    "    \n",
    "    f1 = f1_score(y_true, y_pred, labels=labels, average='macro')\n",
    "    \n",
    "    steps= [*pipeline.named_steps]\n",
    "\n",
    "    cv_mean ,cv_std = opt.best_score_,opt.cv_results_['std_test_score'][opt.best_index_]\n",
    "\n",
    "    tmp= pd.DataFrame({\"Scaling\":[steps[0]],\n",
    "                        \"Model\":[steps[1]],\n",
    "                        \"params\":[opt.best_params_],\n",
    "                        'CV Mean':[cv_mean],\n",
    "                        'CV Std':[cv_std],\n",
    "                        'Test dataset':f1,\n",
    "                        })\n",
    "\n",
    "    if os.path.exists(path+\"/results.csv\"):\n",
    "        current_csv =pd.read_csv(path+\"/results.csv\")\n",
    "        pd.concat([current_csv, tmp], \n",
    "                   ignore_index=True\n",
    "                 ).to_csv(path+\"/results.csv\",\n",
    "                          index=False)    \n",
    "    else:\n",
    "        tmp.to_csv(path+\"/results.csv\",\n",
    "                   index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = LightningClassifier(backbone_name='gluon_seresnext50_32x4d',\n",
    "                            pretrained=True,\n",
    "                            num_classes=19,\n",
    "                            pool_size=1,\n",
    "                            pool_type='avgmax',\n",
    "                            head_type='linear',\n",
    "                            hidden_size=None,\n",
    "                            lr=2e-03,\n",
    "                            weight_decay=0.01,\n",
    "                            seed=98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import bqplot.pyplot as plt\n",
    "# from dataclasses import dataclass\n",
    "# @dataclass\n",
    "# class LRTunerConfig:\n",
    "    \n",
    "#     min_lr: float = 1e-08\n",
    "#     max_lr: float = 1.0\n",
    "#     num_training: int = 50\n",
    "#     mode: str = 'exponential'\n",
    "#     early_stop_threshold: float = 4.0\n",
    "\n",
    "# cfg = OmegaConf.structured(LRTunerConfig())\n",
    "\n",
    "# lr_tuner = trainer.tuner.lr_find(model,\n",
    "#                                  data,\n",
    "#                                  **cfg)\n",
    "# lr_tuner_results = lr_tuner.results\n",
    "# best_lr = lr_tuner.suggestion()\n",
    "\n",
    "# suggestion = {\"lr\": best_lr,\n",
    "#               \"loss\":lr_tuner_results['loss'][lr_tuner._optimal_idx]}\n",
    "\n",
    "# plt.figure()\n",
    "# fig = lr_tuner.plot(suggest=True)\n",
    "# lr_tuner_results_dir = os.path.join(results_dir, f\"task_{task_id}\", \"lr_tuner\")\n",
    "\n",
    "# plot_fname = 'lr_tuner_results_loss-vs-lr.png'\n",
    "# plot_path = Path(lr_tuner_results_dir) / plot_fname\n",
    "# plt.title(f\"Suggested lr={best_lr:.4e} |\\n| Searched {lr_tuner.num_training} lr values $\\in$ [{lr_tuner.lr_min},{lr_tuner.lr_max}] |\\n| bsz = {config.data.batch_size}\", style={\"fontsize\":'small'})\n",
    "# fig.save_png(filename=str(plot_path))\n",
    "\n",
    "# fig = plt.figure()\n",
    "# plt.plot(x=lr_tuner.results['lr'],\n",
    "#          y=lr_tuner.results['loss'],\n",
    "#         figure=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Display available global pool types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Aside: Verify task_0 and task_1 label maps all agree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_0_labels = data.label_encoder\n",
    "\n",
    "data.setup(stage='fit', task_id=1)\n",
    "\n",
    "task_1_labels = data.label_encoder\n",
    "\n",
    "task_0_labels\n",
    "task_1_labels\n",
    "\n",
    "task_0_labels\n",
    "print(f\"label|task_0_idx|task_1_idx\")\n",
    "for label, idx in task_1_labels.class2idx.items():\n",
    "    print(f\"{label}|{task_0_labels.class2idx[label]}|{idx}\")\n",
    "    \n",
    "    assert task_0_labels.class2idx[label] == idx\n",
    "    \n",
    "print(f\"Success, all labels in task_1 have identical integer mappings to their corresponding values in task_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class2idx = data.label_encoder.class2idx\n",
    "family_counts = df.value_counts(\"family\").to_dict()\n",
    "\n",
    "df = df.assign(class_idx=df.family.apply(lambda x: class2idx[x]),\n",
    "               score = df.family.apply(lambda x: family_counts[x]))\n",
    "\n",
    "df#.clear_intent()\n",
    "\n",
    "df.groupby('class_idx').mean()\n",
    "\n",
    "# df.exported.keys()\n",
    "\n",
    "df.exported['Distribution']\n",
    "\n",
    "df.compute_metadata()\n",
    "\n",
    "df\n",
    "\n",
    "df.clear_intent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['backbone_name', 'pretrained', 'num_classes', 'pool_size', 'pool_type', 'head_type', 'hidden_size', 'backbone', 'feature_size'])\n",
      "dict_keys(['backbone_name', 'pretrained', 'num_classes', 'pool_size', 'pool_type', 'head_type', 'hidden_size', 'backbone', 'feature_size'])\n",
      "dict_keys(['backbone_name', 'pretrained', 'num_classes', 'pool_size', 'pool_type', 'head_type', 'hidden_size', 'backbone', 'feature_size'])\n",
      "backbone=gluon_seresnext50_32x4d|pretrained=True|num_classes=1000|head_type=linear|hidden_size=0\n",
      "pool_type=avg\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'classifier.weight'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4096</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'classifier.bias'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span><span style=\"font-weight: bold\">])}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'classifier.weight'\u001b[0m: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1000\u001b[0m, \u001b[1;36m4096\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[32m'classifier.bias'\u001b[0m: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pool_type=max\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'classifier.weight'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4096</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'classifier.bias'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span><span style=\"font-weight: bold\">])}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'classifier.weight'\u001b[0m: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1000\u001b[0m, \u001b[1;36m4096\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[32m'classifier.bias'\u001b[0m: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pool_type=avgmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'classifier.weight'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'classifier.bias'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span><span style=\"font-weight: bold\">])}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'classifier.weight'\u001b[0m: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1000\u001b[0m, \u001b[1;36m8192\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[32m'classifier.bias'\u001b[0m: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "backbone_name='gluon_seresnext50_32x4d'\n",
    "pretrained=True\n",
    "num_classes=1000\n",
    "\n",
    "head_type='linear'\n",
    "hidden_size=0\n",
    "\n",
    "pool_types = [\"avg\", \"max\", \"avgmax\"]\n",
    "\n",
    "models = OrderedDict({})\n",
    "\n",
    "for pool_type in pool_types:\n",
    "    models[pool_type] = build_model(backbone_name=backbone_name,\n",
    "                                    pretrained=pretrained,\n",
    "                                    num_classes=num_classes,\n",
    "                                    pool_size=1,\n",
    "                                    pool_type=pool_type,\n",
    "                                    head_type=head_type,\n",
    "                                    hidden_size=hidden_size)\n",
    "print(f\"backbone={backbone_name}|pretrained={pretrained}|num_classes={num_classes}|head_type={head_type}|hidden_size={hidden_size}\")\n",
    "for pool_type, model in models.items():\n",
    "    print(f\"pool_type={pool_type}\")\n",
    "    pp({k: v.shape for k,v in model.head.named_parameters()})\n",
    "#     pp(list(dict(model.head.named_parameters()).keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Display available head types (TBD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['backbone_name', 'pretrained', 'num_classes', 'pool_size', 'pool_type', 'head_type', 'hidden_size', 'backbone', 'feature_size'])\n",
      "dict_keys(['backbone_name', 'pretrained', 'num_classes', 'pool_size', 'pool_type', 'head_type', 'hidden_size', 'backbone', 'feature_size'])\n",
      "dict_keys(['backbone_name', 'pretrained', 'num_classes', 'pool_size', 'pool_type', 'head_type', 'hidden_size', 'backbone', 'feature_size'])\n",
      "backbone=gluon_seresnext50_32x4d|pretrained=True|num_classes=1000|head_type=linear|hidden_size=0\n",
      "pool_type=avg\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'classifier.weight'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4096</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'classifier.bias'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span><span style=\"font-weight: bold\">])}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'classifier.weight'\u001b[0m: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1000\u001b[0m, \u001b[1;36m4096\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[32m'classifier.bias'\u001b[0m: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pool_type=max\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'classifier.weight'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4096</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'classifier.bias'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span><span style=\"font-weight: bold\">])}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'classifier.weight'\u001b[0m: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1000\u001b[0m, \u001b[1;36m4096\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[32m'classifier.bias'\u001b[0m: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pool_type=avgmax\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'classifier.weight'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'classifier.bias'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span><span style=\"font-weight: bold\">])}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'classifier.weight'\u001b[0m: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1000\u001b[0m, \u001b[1;36m8192\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[32m'classifier.bias'\u001b[0m: \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "backbone_name='gluon_seresnext50_32x4d'\n",
    "pretrained=True\n",
    "num_classes=1000\n",
    "\n",
    "head_types=['linear', 'custom']\n",
    "hidden_size=0\n",
    "\n",
    "pool_types = [\"avg\", \"max\", \"avgmax\"]\n",
    "\n",
    "models = OrderedDict({})\n",
    "\n",
    "for pool_type in pool_types:\n",
    "    models[pool_type] = build_model(backbone_name=backbone_name,\n",
    "                                    pretrained=pretrained,\n",
    "                                    num_classes=num_classes,\n",
    "                                    pool_size=1,\n",
    "                                    pool_type=pool_type,\n",
    "                                    head_type=head_type,\n",
    "                                    hidden_size=hidden_size)\n",
    "print(f\"backbone={backbone_name}|pretrained={pretrained}|num_classes={num_classes}|head_type={head_type}|hidden_size={hidden_size}\")\n",
    "for pool_type, model in models.items():\n",
    "    print(f\"pool_type={pool_type}\")\n",
    "    pp({k: v.shape for k,v in model.head.named_parameters()})\n",
    "#     pp(list(dict(model.head.named_parameters()).keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creating fit method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Borrowed from fastai2 library\n",
    "\n",
    "bn_types = (torch.nn.modules.batchnorm.BatchNorm1d,torch.nn.modules.batchnorm.BatchNorm2d,torch.nn.modules.batchnorm.BatchNorm3d)\n",
    " \n",
    "def set_bn_eval(m:nn.Module)->None:\n",
    "    \"Set bn layers in eval mode for all recursive children of `m`.\"\n",
    "    for l in m.children():\n",
    "        if isinstance(l, bn_types) and not next(l.parameters()).requires_grad:\n",
    "            l.eval()\n",
    "        set_bn_eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs,model,train_dl,valid_dl,loss_fn,opt,device=None,bn_eval=False):\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    mb = master_bar(range(epochs))\n",
    "    mb.write(['epoch','train_loss','valid_loss','trn_acc','val_acc'],table=True)\n",
    "    model.to(device)\n",
    "\n",
    "    for i in mb:    \n",
    "        trn_loss,val_loss = 0.0,0.0\n",
    "        trn_acc,val_acc = 0,0\n",
    "        trn_n,val_n = len(train_dl.dataset),len(valid_dl.dataset)\n",
    "        model.train()\n",
    "        if bn_eval:set_bn_eval(model)\n",
    "        for xb,yb in progress_bar(train_dl,parent=mb):\n",
    "            xb,yb = xb.to(device), yb.to(device)\n",
    "            out = model(xb)\n",
    "            opt.zero_grad()\n",
    "            loss = loss_fn(out,yb)\n",
    "            _,pred = torch.max(out.data, 1)\n",
    "            trn_acc += (pred == yb).sum().item()\n",
    "            trn_loss += loss.item()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        trn_loss /= mb.child.total\n",
    "        trn_acc /= trn_n\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for xb,yb in progress_bar(valid_dl,parent=mb):\n",
    "                xb,yb = xb.to(device), yb.to(device)\n",
    "                out = model(xb)\n",
    "                loss = loss_fn(out,yb)\n",
    "                val_loss += loss.item()\n",
    "                _,pred = torch.max(out.data, 1)\n",
    "                val_acc += (pred == yb).sum().item()\n",
    "        val_loss /= mb.child.total\n",
    "        val_acc /= val_n\n",
    "\n",
    "        mb.write([i,f'{trn_loss:.6f}',f'{val_loss:.6f}',f'{trn_acc:.6f}',f'{val_acc:.6f}'],table=True)        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze(model,bn_freeze=True):\n",
    "    for name,param in model.named_parameters():\n",
    "        if bn_freeze:\n",
    "            param.requires_grad = False\n",
    "        elif name.find('bn') == -1:\n",
    "            param.requires_grad = False\n",
    "            \n",
    "def unfreeze(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "def get_model(lrs=[1e-3,1e-3],bn_freeze=True):\n",
    "    model = MyResNet()\n",
    "    freeze(model.body,bn_freeze=bn_freeze)\n",
    "    opt = optim.Adam([{'params': model.body.parameters(), 'lr':lrs[0]},\n",
    "                {'params': model.head.parameters(), 'lr': lrs[1]}])\n",
    "    return model,opt\n",
    "\n",
    "def update_lr(lr,opt):\n",
    "    opt.param_groups[0]['lr'] = lr/100\n",
    "    opt.param_groups[1]['lr'] = lr\n",
    "    \n",
    "\n",
    "### Freeze the complete resnet body\n",
    "\n",
    "lr = 1e-3\n",
    "model,opt = get_model(lrs=[lr,lr],bn_freeze=True)\n",
    "fit(2,model,trn_dl,valid_dl,loss_fn,opt)\n",
    "\n",
    "### Freeze the complete resnet body and place BN layers in eval mode.\n",
    "\n",
    "lr = 1e-3\n",
    "model,opt = get_model(lrs=[lr,lr],bn_freeze=True)\n",
    "fit(2,model,trn_dl,valid_dl,loss_fn,opt,bn_eval=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "### Freeze the complete resnet body and place BN layers in eval mode and train the body at a lesser learning rate for the second epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>trn_acc</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.115747</td>\n",
       "      <td>0.044909</td>\n",
       "      <td>0.964774</td>\n",
       "      <td>0.987107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "model,opt = get_model(lrs=[lr,lr],bn_freeze=True)\n",
    "fit(1,model,trn_dl,valid_dl,loss_fn,opt,bn_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>trn_acc</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.074065</td>\n",
       "      <td>0.024733</td>\n",
       "      <td>0.973581</td>\n",
       "      <td>0.991509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "update_lr(lr/2,opt)\n",
    "unfreeze(model)\n",
    "fit(1,model,trn_dl,valid_dl,loss_fn,opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "### Freeze the resnet body except fot BN layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>trn_acc</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.105815</td>\n",
       "      <td>0.032677</td>\n",
       "      <td>0.960843</td>\n",
       "      <td>0.988365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.052449</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.982151</td>\n",
       "      <td>0.990881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model,opt = get_model(lrs=[1e-3,1e-3],bn_freeze=False)\n",
    "fit(2,model,trn_dl,valid_dl,loss_fn,opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze the resnet body except fot BN layers and try smaller leraning rate for the resnet body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>trn_acc</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.145204</td>\n",
       "      <td>0.052064</td>\n",
       "      <td>0.951329</td>\n",
       "      <td>0.983648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>trn_acc</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.064199</td>\n",
       "      <td>0.020451</td>\n",
       "      <td>0.977669</td>\n",
       "      <td>0.993711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model,opt = get_model(lrs=[lr,lr],bn_freeze=False)\n",
    "fit(1,model,trn_dl,valid_dl,loss_fn,opt)\n",
    "update_lr(lr/2,opt)\n",
    "unfreeze(model)\n",
    "fit(1,model,trn_dl,valid_dl,loss_fn,opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try adjusting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveConcatPooling(nn.Module):\n",
    "    def forward(self,x):\n",
    "        avg_pool = F.adaptive_avg_pool2d(x,1)\n",
    "        max_pool = F.adaptive_max_pool2d(x,1)\n",
    "        return torch.cat([avg_pool,max_pool],dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        resnet = models.resnet34(pretrained=True)\n",
    "        self.body = nn.Sequential(*list(resnet.children())[:-2])\n",
    "        self.head = nn.Sequential(AdaptiveConcatPooling(),Flatten(),nn.Linear(512*2,2))\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.body(x)\n",
    "        return self.head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>trn_acc</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.124573</td>\n",
       "      <td>0.033491</td>\n",
       "      <td>0.952115</td>\n",
       "      <td>0.987421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>trn_acc</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.057533</td>\n",
       "      <td>0.032403</td>\n",
       "      <td>0.980893</td>\n",
       "      <td>0.990252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "model,opt = get_model(lrs=[lr,lr],bn_freeze=False)\n",
    "fit(1,model,trn_dl,valid_dl,loss_fn,opt)\n",
    "update_lr(lr/2,opt)\n",
    "unfreeze(model)\n",
    "fit(1,model,trn_dl,valid_dl,loss_fn,opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing the complexity of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        nf = 512*2\n",
    "        resnet = models.resnet34(pretrained=True)\n",
    "        self.body = nn.Sequential(*list(resnet.children())[:-2])\n",
    "        self.head = nn.Sequential(AdaptiveConcatPooling(),Flatten(),nn.BatchNorm1d(nf),nn.Dropout(p=0.25),\n",
    "                      nn.Linear(nf,nf//2,bias=False),nn.ReLU(inplace=True),nn.BatchNorm1d(nf//2),nn.Dropout(p=0.75),\n",
    "                      nn.Linear(nf//2,2,bias=False))\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.body(x)\n",
    "        return self.head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>trn_acc</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.097272</td>\n",
       "      <td>0.027744</td>\n",
       "      <td>0.966032</td>\n",
       "      <td>0.989308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>trn_acc</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.056163</td>\n",
       "      <td>0.023533</td>\n",
       "      <td>0.979557</td>\n",
       "      <td>0.992767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "model,opt = get_model(lrs=[lr,lr],bn_freeze=False)\n",
    "fit(1,model,trn_dl,valid_dl,loss_fn,opt)\n",
    "update_lr(lr/2,opt)\n",
    "unfreeze(model)\n",
    "fit(1,model,trn_dl,valid_dl,loss_fn,opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "## scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "                \n",
    "\n",
    "# ## WIP: display_layer_status\n",
    "#     @classmethod\n",
    "#     def display_layer_status(cls,\n",
    "#                              model: nn.Module,\n",
    "#                              max_depth: int=3):\n",
    "#         \"\"\"\n",
    "#         Return a formatted display of model's layers alongside relevant training status info.\n",
    "#         \"\"\"\n",
    "#         modules = []\n",
    "        \n",
    "# #         for name, module in model.named_modules():\n",
    "#         for name, module in model.named_children():\n",
    "# #             print(name, 'max_depth:', max_depth)\n",
    "#             if name==\"\": continue\n",
    "# #             if (max_depth>0) and (len(list(module.named_modules())) > 0):\n",
    "#             if (max_depth>0) and (len(list(module.named_children())) > 0):\n",
    "#                 modules.extend(cls.display_layer_status(module, max_depth=max_depth-1))\n",
    "#                 continue\n",
    "#             module_out = {\"name\":name,\n",
    "#                           \"training\":module.training,\n",
    "#                           \"type\":type(module),\n",
    "#                           \"params\":[]}\n",
    "#             for param_name, param in module.named_parameters():\n",
    "#                 module_out[\"params\"].append({\n",
    "#                     \"name\":param_name,\n",
    "#                     \"type\":type(param),\n",
    "#                     \"requires_grad\":param.requires_grad,\n",
    "#                     \"shape\":param.shape\n",
    "#                 })\n",
    "#             print(name)\n",
    "#             pp(module_out)\n",
    "#             modules.append(module_out)\n",
    "#         return modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for unfreeze_down_to in reversed(range(0,-8,-1)):\n",
    "# model.freeze_backbone(freeze_bn=False)\n",
    "# model.freeze_backbone(freeze_bn=True)\n",
    "# summary(model.model)\n",
    "# count_trainable_batchnorm_layers(model)\n",
    "\n",
    "# for unfreeze_down_to in range(0,-9,-1):\n",
    "#     print(unfreeze_down_to)\n",
    "#     print(f\"Unfreezing backbone down to layer: {unfreeze_down_to}\")\n",
    "#     model.unfreeze_backbone_top_layers(unfreeze_down_to=unfreeze_down_to)\n",
    "# #     summary(model.model)\n",
    "#     model.count_trainable_batchnorm_layers()\n",
    "# #     count_trainable_batchnorm_layers(model)\n",
    "\n",
    "#     print(f\"trainable parameters: {len(list(model.get_trainable_parameters()))}\")\n",
    "#     print(f\"non-trainable parameters: {len(list(model.get_nontrainable_parameters()))}\")\n",
    "\n",
    "# unfreeze_down_to = -2\n",
    "\n",
    "# model.unfreeze_backbone_top_layers(unfreeze_down_to=unfreeze_down_to)\n",
    "# summary(model.model)\n",
    "# count_trainable_batchnorm_layers(model)\n",
    "\n",
    "# print(f\"trainable parameters: {len(list(model.get_trainable_parameters()))}\")\n",
    "# print(f\"non-trainable parameters: {len(list(model.get_nontrainable_parameters()))}\")\n",
    "\n",
    "# unfreeze_down_to = -3\n",
    "\n",
    "# model.unfreeze_backbone_top_layers(unfreeze_down_to=unfreeze_down_to)\n",
    "# summary(model.model)\n",
    "# print(f\"trainable: {len(list(model.get_trainable_parameters()))}\")\n",
    "# print(f\"non-trainable: {len(list(model.get_nontrainable_parameters()))}\")\n",
    "\n",
    "# unfreeze_down_to = -4\n",
    "\n",
    "# model.unfreeze_backbone_top_layers(unfreeze_down_to=unfreeze_down_to)\n",
    "# summary(model.model)\n",
    "# print(f\"trainable: {len(list(model.get_trainable_parameters()))}\")\n",
    "# print(f\"non-trainable: {len(list(model.get_nontrainable_parameters()))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#     model = timm.create_model(model_name=backbone_name, num_classes=1000, pretrained=pretrained)\n",
    "#     if isinstance(pretrained, str) and pretrained != \"imagenet\":\n",
    "#         model = load_model_checkpoint(model, ckpt_path=pretrained)\n",
    "# #         ckpt_pth = glob.glob(hydra.utils.to_absolute_path(pretrained))\n",
    "# #         model = model.load_state_dict(torch.load(ckpt_pth[0]))\n",
    "        \n",
    "#     body = nn.Sequential(*list(model.children())[:-2])\n",
    "\n",
    "    \n",
    "#     feature_size = model.fc.in_features\n",
    "    \n",
    "#     head = OrderedDict()\n",
    "#     global_pool, feature_size = build_global_pool(pool_type=pool_type,\n",
    "#                                                   pool_size=pool_size,\n",
    "#                                                   feature_size=feature_size)\n",
    "#     head[\"global_pool\"] = global_pool\n",
    "#     head[\"flatten\"] = Flatten()\n",
    "    \n",
    "#     classifier_input_feature_size = feature_size*(pool_size*2)        \n",
    "#     if head_type=='linear':\n",
    "#         head[\"classifier\"] = nn.Linear(classifier_input_feature_size, num_classes)\n",
    "#     elif head_type=='custom':\n",
    "#         head[\"classifier\"] = nn.Sequential(nn.Linear(classifier_input_feature_size, hidden_size),\n",
    "#                                 nn.RReLU(lower=0.125, upper=0.3333333333333333, inplace=False),\n",
    "#                                 nn.BatchNorm1d(hidden_size),\n",
    "#                                 nn.Linear(hidden_size, num_classes))\n",
    "        \n",
    "#     head = nn.Sequential(head)\n",
    "\n",
    "\n",
    "#     model = nn.Sequential(OrderedDict({\n",
    "#         \"body\":body,\n",
    "#         \"head\":head\n",
    "#     }))\n",
    "#     return model\n",
    "\n",
    "# def build_model(backbone_name='gluon_seresnext50_32x4d',\n",
    "#                 pretrained: Union[bool, str]=True,\n",
    "#                 num_classes: int=1000,\n",
    "#                 pool_size: int=1,\n",
    "#                 pool_type: str='avg',\n",
    "#                 head_type: str='linear',\n",
    "#                 hidden_size: Optional[int]=512):\n",
    "    \n",
    "#     try:\n",
    "#         model = build_timm_custom(backbone_name=backbone_name,\n",
    "#                                   pretrained=pretrained,\n",
    "#                                   num_classes=num_classes,\n",
    "#                                   pool_size=pool_size,\n",
    "#                                   pool_type=pool_type,\n",
    "#                                   head_type=hidden_size,\n",
    "#                                   hidden_size=hidden_size)\n",
    "\n",
    "#     except:\n",
    "#         print\n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
